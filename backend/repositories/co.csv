code_chunk,file_name,file_path,path_to_code_chunk,parent,prev_sibling,next_sibling,start_point,end_point,has_error,code_node_type,code_identifier,is_chunked,num_tokens,uuid_str
"from collections import defaultdict
from functools import partial
from multiprocessing import Pool

import torch
from torch.utils.data import DataLoader

from data.problem import FixedProblemSet, collate_simple
from data.tokenizer import Label
from utils import Reservoir, Timer


class SortedBatchSampler:
    class Iterator:
        def __init__(self, sorted_lengths, budget):
            self.sorted_lengths = sorted_lengths
            self.budget = budget
            self.idx = 0

        def __next__(self):
            num_elem = len(self.sorted_lengths)
            if self.idx >= num_elem:
                raise StopIteration

            max_length = self.sorted_lengths[self.idx]
            cost_each = max_length ** 2
            batch_size = max(self.budget // cost_each, 16)
            start = self.idx
            end = min(num_elem, start + batch_size)
            self.idx += batch_size
            return range(start, end)

    def __init__(self, sorted_lengths, budget=256 ** 2 * 64):
        self.sorted_lengths = sorted_lengths
        self.budget = budget

    def __iter__(self):
        return self.Iterator(self.sorted_lengths, self.budget)


def solution_length(prob, paradigm):
    prob_cls, args = prob
    x, _, _ = prob_cls.solve(args, paradigm=paradigm)
    return len(x)


class Evaluator:
    def __init__(self, config, paradigm, vocab):
        self.config = config
        self.paradigm = paradigm
        self.vocab = vocab
        self.probs = None
        self.top_probs = []
        self.prob_graph = {}
        self.new_subprobs = []
        self.lengths = {}
        self.sorted_probs = []
        self.sorted_lengths = []
        self.batch_sampler = None
        self.data_loader = None

    def add_probs(self, probs):
        assert self.probs is None
        self.probs = probs

    def extend_prob_graph(self, probs):
        for prob in probs:
            if prob in self.prob_graph:
                continue
            self.new_subprobs.append(prob)
            prob_cls, args = prob
            if self.paradigm == 'rot':
                subprobs = [t[:2] for t in prob_cls.thought(args)]
            else:
                subprobs = []
            self.prob_graph[prob] = subprobs
            if len(subprobs) > 0:
                self.extend_prob_graph(subprobs)

    def update(self):
        self.top_probs.extend(self.probs)
        self.extend_prob_graph(self.probs)
        with Pool(self.config['num_workers']) as pool:
            # Get context lengths of new subproblems
            new_lengths = pool.map(
                partial(solution_length, paradigm=self.paradigm),
                self.new_subprobs)
        for subprob, length in zip(self.new_subprobs, new_lengths):
            self.lengths[subprob] = length
        self.sorted_probs, self.sorted_lengths = zip(*sorted(
            self.lengths.items(),
            key=lambda x: x[1], reverse=True))
        test_set = FixedProblemSet(
            self.sorted_probs, paradigm=self.paradigm, vocab=self.vocab)
        print(f'Total contexts: {len(self.sorted_probs)}')
        self.batch_sampler = SortedBatchSampler(
            self.sorted_lengths, budget=self.config['eval_length_budget'])
        self.data_loader = DataLoader(
            test_set, batch_sampler=self.batch_sampler,
            num_workers=self.config['num_workers'],
            collate_fn=collate_simple)

        self.probs = None
        self.new_subprobs = []

    def evaluate(self, model):
        if self.probs is not None:
            # Lazy initialization
            with Timer('Updating evaluator: {:.3f}s'):
                self.update()

        training = model.training
        model.eval()

        # Evaluate unique subproblems
        node_eval = {}
        subprob_total = defaultdict(int)
        subprob_correct = defaultdict(int)
        wrong_rsvrs = defaultdict(
            lambda: Reservoir(self.config['num_wrong_summary']))
        with torch.no_grad():
            for ((x, y, label),), prob_indices in \
                    zip(self.data_loader, self.batch_sampler):
                # Infer
                x, y = x.to(model.device), y.to(model.device)
                label = label.to(model.device)
                pred = model(x).argmax(dim=-1)
                ignore = label < Label.T
                correct = ((pred == y) | ignore).all(dim=0)
                correct = correct.tolist()

                # Record results
                for batch_idx, (prob_idx, c) in \
                        enumerate(zip(prob_indices, correct)):
                    prob = self.sorted_probs[prob_idx]
                    assert prob not in node_eval
                    node_eval[prob] = c
                    prob_cls, _ = prob
                    subprob_total[prob_cls] += 1
                    if c:
                        subprob_correct[prob_cls] += 1
                    elif wrong_rsvrs[prob_cls].reserve():
                        wrong_rsvrs[prob_cls].add((
                            y[:, batch_idx],
                            pred[:, batch_idx],
                            label[:, batch_idx]
                        ))
                torch.cuda.empty_cache()

        correct_deep, correct_shallow, prob_total = self.aggregate_eval(
            node_eval)

        # Textualize wrong samples
        wrong_samples = {
            prob_cls: [
                compare_pred(y, pred, label, itos=model.itos)
                for y, pred, label in wrong_rsvrs[prob_cls]
            ]
            for prob_cls in prob_total
        }

        model.train(training)

        return {
            'prob_total': prob_total,
            'correct_shallow': correct_shallow,
            'correct_deep': correct_deep,
            'subprob_total': subprob_total,
            'subprob_correct': subprob_correct,
            'accuracy_shallow': {
                prob_cls: correct_shallow[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_deep': {
                prob_cls: correct_deep[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_subprob': {
                prob_cls: subprob_correct[prob_cls] / total
                for prob_cls, total in subprob_total.items()
            },
            'wrong_samples': wrong_samples,
        }

    def aggregate_eval(self, node_eval):
        # Aggregate subproblem evaluations
        subtree_eval = {}
        prob_total = defaultdict(int)
        correct_shallow = defaultdict(int)
        correct_deep = defaultdict(int)
        for prob in self.top_probs:
            prob_cls = prob[0]
            if node_eval[prob]:
                correct_shallow[prob_cls] += 1
            if self.eval_subtree(prob, node_eval, subtree_eval):
                correct_deep[prob_cls] += 1
            prob_total[prob_cls] += 1
        return correct_deep, correct_shallow, prob_total

    def eval_subtree(self, prob, node_eval, subtree_eval):
        if prob in subtree_eval:
            # Already evaluated
            return subtree_eval[prob]

        if len(self.prob_graph[prob]) == 0:
            subtree_eval[prob] = node_eval[prob]
            return subtree_eval[prob]
        if not node_eval[prob]:
            subtree_eval[prob] = False
            return False

        subtree_eval[prob] = all([
            self.eval_subtree(subprob, node_eval, subtree_eval)
            for subprob in self.prob_graph[prob]
        ])
        return subtree_eval[prob]

    def state_dict(self):
        return {
            'config': self.config,
            'paradigm': self.paradigm,
            'probs': self.probs,
            'top_probs': self.top_probs,
            'prob_graph': self.prob_graph,
            'sorted_probs': self.sorted_probs,
            'sorted_lengths': self.sorted_lengths,
            'batch_sampler': self.batch_sampler,
            'data_loader': self.data_loader,
        }

    def load_state_dict(self, state_dict):
        self.config = state_dict['config']
        self.paradigm = state_dict['paradigm']
        self.probs = state_dict['probs']
        self.top_probs = state_dict['top_probs']
        self.prob_graph = state_dict['prob_graph']
        self.sorted_probs = state_dict['sorted_probs']
        self.sorted_lengths = state_dict['sorted_lengths']
        self.batch_sampler = state_dict['batch_sampler']
        self.data_loader = state_dict['data_loader']


def compare_pred(y, pred, label, itos):
    text_y, text_p = '', ''
    for t_y, t_p, t_l in zip(y, pred, label):
        if t_l == Label.PAD:
            continue
        dec_t_y = itos[t_y]
        dec_t_p = itos[t_p]
        if t_l == Label.Q:
            text_y += f'{dec_t_y}'
            text_p += ' ' * len(dec_t_y)
            continue
        if dec_t_y == dec_t_p:
            text_y += dec_t_y
            text_p += dec_t_p
            continue
        max_len = max(len(dec_t_y), len(dec_t_p))
        text_y += f'{dec_t_y:{max_len}}'
        text_p += f'{dec_t_p:{max_len}}'
    return f'{text_y}\n{text_p}'
",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,,NA,Previous sibling does not exist,"from collections import defaultdict
from functools import partial
from multiprocessing import Pool
import torch
from torch.utils.data import DataLoader
from data.problem import FixedProblemSet, collate_simple
from data.tokenizer import Label
from utils import Reservoir, Timer","(0, 0)","(261, 0)",N,module,module,,1972,46b05706-eb63-4aef-856d-69a462b2ff0c
"from collections import defaultdict
from functools import partial
from multiprocessing import Pool
import torch
from torch.utils.data import DataLoader
from data.problem import FixedProblemSet, collate_simple
from data.tokenizer import Label
from utils import Reservoir, Timer",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/,module,Previous sibling does not exist,"class SortedBatchSampler:
    class Iterator:
        def __init__(self, sorted_lengths, budget):
            self.sorted_lengths = sorted_lengths
            self.budget = budget
            self.idx = 0

        def __next__(self):
            num_elem = len(self.sorted_lengths)
            if self.idx >= num_elem:
                raise StopIteration

            max_length = self.sorted_lengths[self.idx]
            cost_each = max_length ** 2
            batch_size = max(self.budget // cost_each, 16)
            start = self.idx
            end = min(num_elem, start + batch_size)
            self.idx += batch_size
            return range(start, end)

    def __init__(self, sorted_lengths, budget=256 ** 2 * 64):
        self.sorted_lengths = sorted_lengths
        self.budget = budget

    def __iter__(self):
        return self.Iterator(self.sorted_lengths, self.budget)","(0, 0)","(9, 34)",N,"import_from_statement,import_from_statement,import_from_statement,import_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement",import_from_statement,,44,488bc744-9f6a-4b24-920c-ab15d9903e82
"class SortedBatchSampler:
    class Iterator:
        def __init__(self, sorted_lengths, budget):
            self.sorted_lengths = sorted_lengths
            self.budget = budget
            self.idx = 0

        def __next__(self):
            num_elem = len(self.sorted_lengths)
            if self.idx >= num_elem:
                raise StopIteration

            max_length = self.sorted_lengths[self.idx]
            cost_each = max_length ** 2
            batch_size = max(self.budget // cost_each, 16)
            start = self.idx
            end = min(num_elem, start + batch_size)
            self.idx += batch_size
            return range(start, end)

    def __init__(self, sorted_lengths, budget=256 ** 2 * 64):
        self.sorted_lengths = sorted_lengths
        self.budget = budget

    def __iter__(self):
        return self.Iterator(self.sorted_lengths, self.budget)",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/,module,"from collections import defaultdict
from functools import partial
from multiprocessing import Pool
import torch
from torch.utils.data import DataLoader
from data.problem import FixedProblemSet, collate_simple
from data.tokenizer import Label
from utils import Reservoir, Timer","def solution_length(prob, paradigm):
    prob_cls, args = prob
    x, _, _ = prob_cls.solve(args, paradigm=paradigm)
    return len(x)","(12, 0)","(37, 62)",N,class_definition,SortedBatchSampler,,193,345947a3-3684-4fc0-a549-904a5bb3f569
"class Iterator:
        def __init__(self, sorted_lengths, budget):
            self.sorted_lengths = sorted_lengths
            self.budget = budget
            self.idx = 0

        def __next__(self):
            num_elem = len(self.sorted_lengths)
            if self.idx >= num_elem:
                raise StopIteration

            max_length = self.sorted_lengths[self.idx]
            cost_each = max_length ** 2
            batch_size = max(self.budget // cost_each, 16)
            start = self.idx
            end = min(num_elem, start + batch_size)
            self.idx += batch_size
            return range(start, end)",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-SortedBatchSampler/,SortedBatchSampler,Previous sibling does not exist,"def __init__(self, sorted_lengths, budget=256 ** 2 * 64):
        self.sorted_lengths = sorted_lengths
        self.budget = budget","(13, 4)","(30, 36)",N,class_definition,Iterator,,133,e5c3aa71-b362-49d5-a5c2-0ff51057d257
"def __init__(self, sorted_lengths, budget):
            self.sorted_lengths = sorted_lengths
            self.budget = budget
            self.idx = 0",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-SortedBatchSampler/class_definition-Iterator/,Iterator,Previous sibling does not exist,"def __next__(self):
            num_elem = len(self.sorted_lengths)
            if self.idx >= num_elem:
                raise StopIteration

            max_length = self.sorted_lengths[self.idx]
            cost_each = max_length ** 2
            batch_size = max(self.budget // cost_each, 16)
            start = self.idx
            end = min(num_elem, start + batch_size)
            self.idx += batch_size
            return range(start, end)","(14, 8)","(17, 24)",N,function_definition,__init__,,32,563bb726-fcf0-4efb-8eba-38673e4f068b
"def __next__(self):
            num_elem = len(self.sorted_lengths)
            if self.idx >= num_elem:
                raise StopIteration

            max_length = self.sorted_lengths[self.idx]
            cost_each = max_length ** 2
            batch_size = max(self.budget // cost_each, 16)
            start = self.idx
            end = min(num_elem, start + batch_size)
            self.idx += batch_size
            return range(start, end)",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-SortedBatchSampler/class_definition-Iterator/,Iterator,"def __init__(self, sorted_lengths, budget):
            self.sorted_lengths = sorted_lengths
            self.budget = budget
            self.idx = 0",Next sibling does not exist,"(19, 8)","(30, 36)",N,function_definition,__next__,,95,a61e78d4-be85-420c-9dbe-716765dd0498
"def __init__(self, sorted_lengths, budget=256 ** 2 * 64):
        self.sorted_lengths = sorted_lengths
        self.budget = budget",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-SortedBatchSampler/,SortedBatchSampler,"class Iterator:
        def __init__(self, sorted_lengths, budget):
            self.sorted_lengths = sorted_lengths
            self.budget = budget
            self.idx = 0

        def __next__(self):
            num_elem = len(self.sorted_lengths)
            if self.idx >= num_elem:
                raise StopIteration

            max_length = self.sorted_lengths[self.idx]
            cost_each = max_length ** 2
            batch_size = max(self.budget // cost_each, 16)
            start = self.idx
            end = min(num_elem, start + batch_size)
            self.idx += batch_size
            return range(start, end)","def __iter__(self):
        return self.Iterator(self.sorted_lengths, self.budget)","(32, 4)","(34, 28)",N,function_definition,__init__,,33,ec83eb59-2caf-4b64-a4df-9fa7f0d7098a
"def __iter__(self):
        return self.Iterator(self.sorted_lengths, self.budget)",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-SortedBatchSampler/,SortedBatchSampler,"def __init__(self, sorted_lengths, budget=256 ** 2 * 64):
        self.sorted_lengths = sorted_lengths
        self.budget = budget",Next sibling does not exist,"(36, 4)","(37, 62)",N,function_definition,__iter__,,18,82753bfe-6295-46e7-9b01-0d711899f4d2
"def solution_length(prob, paradigm):
    prob_cls, args = prob
    x, _, _ = prob_cls.solve(args, paradigm=paradigm)
    return len(x)",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/,module,"class SortedBatchSampler:
    class Iterator:
        def __init__(self, sorted_lengths, budget):
            self.sorted_lengths = sorted_lengths
            self.budget = budget
            self.idx = 0

        def __next__(self):
            num_elem = len(self.sorted_lengths)
            if self.idx >= num_elem:
                raise StopIteration

            max_length = self.sorted_lengths[self.idx]
            cost_each = max_length ** 2
            batch_size = max(self.budget // cost_each, 16)
            start = self.idx
            end = min(num_elem, start + batch_size)
            self.idx += batch_size
            return range(start, end)

    def __init__(self, sorted_lengths, budget=256 ** 2 * 64):
        self.sorted_lengths = sorted_lengths
        self.budget = budget

    def __iter__(self):
        return self.Iterator(self.sorted_lengths, self.budget)","class Evaluator:
    def __init__(self, config, paradigm, vocab):
        self.config = config
        self.paradigm = paradigm
        self.vocab = vocab
        self.probs = None
        self.top_probs = []
        self.prob_graph = {}
        self.new_subprobs = []
        self.lengths = {}
        self.sorted_probs = []
        self.sorted_lengths = []
        self.batch_sampler = None
        self.data_loader = None

    def add_probs(self, probs):
        assert self.probs is None
        self.probs = probs

    def extend_prob_graph(self, probs):
        for prob in probs:
            if prob in self.prob_graph:
                continue
            self.new_subprobs.append(prob)
            prob_cls, args = prob
            if self.paradigm == 'rot':
                subprobs = [t[:2] for t in prob_cls.thought(args)]
            else:
                subprobs = []
            self.prob_graph[prob] = subprobs
            if len(subprobs) > 0:
                self.extend_prob_graph(subprobs)

    def update(self):
        self.top_probs.extend(self.probs)
        self.extend_prob_graph(self.probs)
        with Pool(self.config['num_workers']) as pool:
            # Get context lengths of new subproblems
            new_lengths = pool.map(
                partial(solution_length, paradigm=self.paradigm),
                self.new_subprobs)
        for subprob, length in zip(self.new_subprobs, new_lengths):
            self.lengths[subprob] = length
        self.sorted_probs, self.sorted_lengths = zip(*sorted(
            self.lengths.items(),
            key=lambda x: x[1], reverse=True))
        test_set = FixedProblemSet(
            self.sorted_probs, paradigm=self.paradigm, vocab=self.vocab)
        print(f'Total contexts: {len(self.sorted_probs)}')
        self.batch_sampler = SortedBatchSampler(
            self.sorted_lengths, budget=self.config['eval_length_budget'])
        self.data_loader = DataLoader(
            test_set, batch_sampler=self.batch_sampler,
            num_workers=self.config['num_workers'],
            collate_fn=collate_simple)

        self.probs = None
        self.new_subprobs = []

    def evaluate(self, model):
        if self.probs is not None:
            # Lazy initialization
            with Timer('Updating evaluator: {:.3f}s'):
                self.update()

        training = model.training
        model.eval()

        # Evaluate unique subproblems
        node_eval = {}
        subprob_total = defaultdict(int)
        subprob_correct = defaultdict(int)
        wrong_rsvrs = defaultdict(
            lambda: Reservoir(self.config['num_wrong_summary']))
        with torch.no_grad():
            for ((x, y, label),), prob_indices in \
                    zip(self.data_loader, self.batch_sampler):
                # Infer
                x, y = x.to(model.device), y.to(model.device)
                label = label.to(model.device)
                pred = model(x).argmax(dim=-1)
                ignore = label < Label.T
                correct = ((pred == y) | ignore).all(dim=0)
                correct = correct.tolist()

                # Record results
                for batch_idx, (prob_idx, c) in \
                        enumerate(zip(prob_indices, correct)):
                    prob = self.sorted_probs[prob_idx]
                    assert prob not in node_eval
                    node_eval[prob] = c
                    prob_cls, _ = prob
                    subprob_total[prob_cls] += 1
                    if c:
                        subprob_correct[prob_cls] += 1
                    elif wrong_rsvrs[prob_cls].reserve():
                        wrong_rsvrs[prob_cls].add((
                            y[:, batch_idx],
                            pred[:, batch_idx],
                            label[:, batch_idx]
                        ))
                torch.cuda.empty_cache()

        correct_deep, correct_shallow, prob_total = self.aggregate_eval(
            node_eval)

        # Textualize wrong samples
        wrong_samples = {
            prob_cls: [
                compare_pred(y, pred, label, itos=model.itos)
                for y, pred, label in wrong_rsvrs[prob_cls]
            ]
            for prob_cls in prob_total
        }

        model.train(training)

        return {
            'prob_total': prob_total,
            'correct_shallow': correct_shallow,
            'correct_deep': correct_deep,
            'subprob_total': subprob_total,
            'subprob_correct': subprob_correct,
            'accuracy_shallow': {
                prob_cls: correct_shallow[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_deep': {
                prob_cls: correct_deep[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_subprob': {
                prob_cls: subprob_correct[prob_cls] / total
                for prob_cls, total in subprob_total.items()
            },
            'wrong_samples': wrong_samples,
        }

    def aggregate_eval(self, node_eval):
        # Aggregate subproblem evaluations
        subtree_eval = {}
        prob_total = defaultdict(int)
        correct_shallow = defaultdict(int)
        correct_deep = defaultdict(int)
        for prob in self.top_probs:
            prob_cls = prob[0]
            if node_eval[prob]:
                correct_shallow[prob_cls] += 1
            if self.eval_subtree(prob, node_eval, subtree_eval):
                correct_deep[prob_cls] += 1
            prob_total[prob_cls] += 1
        return correct_deep, correct_shallow, prob_total

    def eval_subtree(self, prob, node_eval, subtree_eval):
        if prob in subtree_eval:
            # Already evaluated
            return subtree_eval[prob]

        if len(self.prob_graph[prob]) == 0:
            subtree_eval[prob] = node_eval[prob]
            return subtree_eval[prob]
        if not node_eval[prob]:
            subtree_eval[prob] = False
            return False

        subtree_eval[prob] = all([
            self.eval_subtree(subprob, node_eval, subtree_eval)
            for subprob in self.prob_graph[prob]
        ])
        return subtree_eval[prob]

    def state_dict(self):
        return {
            'config': self.config,
            'paradigm': self.paradigm,
            'probs': self.probs,
            'top_probs': self.top_probs,
            'prob_graph': self.prob_graph,
            'sorted_probs': self.sorted_probs,
            'sorted_lengths': self.sorted_lengths,
            'batch_sampler': self.batch_sampler,
            'data_loader': self.data_loader,
        }

    def load_state_dict(self, state_dict):
        self.config = state_dict['config']
        self.paradigm = state_dict['paradigm']
        self.probs = state_dict['probs']
        self.top_probs = state_dict['top_probs']
        self.prob_graph = state_dict['prob_graph']
        self.sorted_probs = state_dict['sorted_probs']
        self.sorted_lengths = state_dict['sorted_lengths']
        self.batch_sampler = state_dict['batch_sampler']
        self.data_loader = state_dict['data_loader']","(40, 0)","(43, 17)",N,function_definition,solution_length,,37,94ce1dfa-9c94-4e44-9d9b-6266ed258c96
"class Evaluator:
    def __init__(self, config, paradigm, vocab):
        self.config = config
        self.paradigm = paradigm
        self.vocab = vocab
        self.probs = None
        self.top_probs = []
        self.prob_graph = {}
        self.new_subprobs = []
        self.lengths = {}
        self.sorted_probs = []
        self.sorted_lengths = []
        self.batch_sampler = None
        self.data_loader = None

    def add_probs(self, probs):
        assert self.probs is None
        self.probs = probs

    def extend_prob_graph(self, probs):
        for prob in probs:
            if prob in self.prob_graph:
                continue
            self.new_subprobs.append(prob)
            prob_cls, args = prob
            if self.paradigm == 'rot':
                subprobs = [t[:2] for t in prob_cls.thought(args)]
            else:
                subprobs = []
            self.prob_graph[prob] = subprobs
            if len(subprobs) > 0:
                self.extend_prob_graph(subprobs)

    def update(self):
        self.top_probs.extend(self.probs)
        self.extend_prob_graph(self.probs)
        with Pool(self.config['num_workers']) as pool:
            # Get context lengths of new subproblems
            new_lengths = pool.map(
                partial(solution_length, paradigm=self.paradigm),
                self.new_subprobs)
        for subprob, length in zip(self.new_subprobs, new_lengths):
            self.lengths[subprob] = length
        self.sorted_probs, self.sorted_lengths = zip(*sorted(
            self.lengths.items(),
            key=lambda x: x[1], reverse=True))
        test_set = FixedProblemSet(
            self.sorted_probs, paradigm=self.paradigm, vocab=self.vocab)
        print(f'Total contexts: {len(self.sorted_probs)}')
        self.batch_sampler = SortedBatchSampler(
            self.sorted_lengths, budget=self.config['eval_length_budget'])
        self.data_loader = DataLoader(
            test_set, batch_sampler=self.batch_sampler,
            num_workers=self.config['num_workers'],
            collate_fn=collate_simple)

        self.probs = None
        self.new_subprobs = []

    def evaluate(self, model):
        if self.probs is not None:
            # Lazy initialization
            with Timer('Updating evaluator: {:.3f}s'):
                self.update()

        training = model.training
        model.eval()

        # Evaluate unique subproblems
        node_eval = {}
        subprob_total = defaultdict(int)
        subprob_correct = defaultdict(int)
        wrong_rsvrs = defaultdict(
            lambda: Reservoir(self.config['num_wrong_summary']))
        with torch.no_grad():
            for ((x, y, label),), prob_indices in \
                    zip(self.data_loader, self.batch_sampler):
                # Infer
                x, y = x.to(model.device), y.to(model.device)
                label = label.to(model.device)
                pred = model(x).argmax(dim=-1)
                ignore = label < Label.T
                correct = ((pred == y) | ignore).all(dim=0)
                correct = correct.tolist()

                # Record results
                for batch_idx, (prob_idx, c) in \
                        enumerate(zip(prob_indices, correct)):
                    prob = self.sorted_probs[prob_idx]
                    assert prob not in node_eval
                    node_eval[prob] = c
                    prob_cls, _ = prob
                    subprob_total[prob_cls] += 1
                    if c:
                        subprob_correct[prob_cls] += 1
                    elif wrong_rsvrs[prob_cls].reserve():
                        wrong_rsvrs[prob_cls].add((
                            y[:, batch_idx],
                            pred[:, batch_idx],
                            label[:, batch_idx]
                        ))
                torch.cuda.empty_cache()

        correct_deep, correct_shallow, prob_total = self.aggregate_eval(
            node_eval)

        # Textualize wrong samples
        wrong_samples = {
            prob_cls: [
                compare_pred(y, pred, label, itos=model.itos)
                for y, pred, label in wrong_rsvrs[prob_cls]
            ]
            for prob_cls in prob_total
        }

        model.train(training)

        return {
            'prob_total': prob_total,
            'correct_shallow': correct_shallow,
            'correct_deep': correct_deep,
            'subprob_total': subprob_total,
            'subprob_correct': subprob_correct,
            'accuracy_shallow': {
                prob_cls: correct_shallow[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_deep': {
                prob_cls: correct_deep[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_subprob': {
                prob_cls: subprob_correct[prob_cls] / total
                for prob_cls, total in subprob_total.items()
            },
            'wrong_samples': wrong_samples,
        }

    def aggregate_eval(self, node_eval):
        # Aggregate subproblem evaluations
        subtree_eval = {}
        prob_total = defaultdict(int)
        correct_shallow = defaultdict(int)
        correct_deep = defaultdict(int)
        for prob in self.top_probs:
            prob_cls = prob[0]
            if node_eval[prob]:
                correct_shallow[prob_cls] += 1
            if self.eval_subtree(prob, node_eval, subtree_eval):
                correct_deep[prob_cls] += 1
            prob_total[prob_cls] += 1
        return correct_deep, correct_shallow, prob_total

    def eval_subtree(self, prob, node_eval, subtree_eval):
        if prob in subtree_eval:
            # Already evaluated
            return subtree_eval[prob]

        if len(self.prob_graph[prob]) == 0:
            subtree_eval[prob] = node_eval[prob]
            return subtree_eval[prob]
        if not node_eval[prob]:
            subtree_eval[prob] = False
            return False

        subtree_eval[prob] = all([
            self.eval_subtree(subprob, node_eval, subtree_eval)
            for subprob in self.prob_graph[prob]
        ])
        return subtree_eval[prob]

    def state_dict(self):
        return {
            'config': self.config,
            'paradigm': self.paradigm,
            'probs': self.probs,
            'top_probs': self.top_probs,
            'prob_graph': self.prob_graph,
            'sorted_probs': self.sorted_probs,
            'sorted_lengths': self.sorted_lengths,
            'batch_sampler': self.batch_sampler,
            'data_loader': self.data_loader,
        }

    def load_state_dict(self, state_dict):
        self.config = state_dict['config']
        self.paradigm = state_dict['paradigm']
        self.probs = state_dict['probs']
        self.top_probs = state_dict['top_probs']
        self.prob_graph = state_dict['prob_graph']
        self.sorted_probs = state_dict['sorted_probs']
        self.sorted_lengths = state_dict['sorted_lengths']
        self.batch_sampler = state_dict['batch_sampler']
        self.data_loader = state_dict['data_loader']",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/,module,"def solution_length(prob, paradigm):
    prob_cls, args = prob
    x, _, _ = prob_cls.solve(args, paradigm=paradigm)
    return len(x)","def compare_pred(y, pred, label, itos):
    text_y, text_p = '', ''
    for t_y, t_p, t_l in zip(y, pred, label):
        if t_l == Label.PAD:
            continue
        dec_t_y = itos[t_y]
        dec_t_p = itos[t_p]
        if t_l == Label.Q:
            text_y += f'{dec_t_y}'
            text_p += ' ' * len(dec_t_y)
            continue
        if dec_t_y == dec_t_p:
            text_y += dec_t_y
            text_p += dec_t_p
            continue
        max_len = max(len(dec_t_y), len(dec_t_p))
        text_y += f'{dec_t_y:{max_len}}'
        text_p += f'{dec_t_p:{max_len}}'
    return f'{text_y}\n{text_p}'","(46, 0)","(239, 52)",N,class_definition,Evaluator,,1503,6de97eb1-fccb-4620-816d-93b64b0f17ce
"def __init__(self, config, paradigm, vocab):
        self.config = config
        self.paradigm = paradigm
        self.vocab = vocab
        self.probs = None
        self.top_probs = []
        self.prob_graph = {}
        self.new_subprobs = []
        self.lengths = {}
        self.sorted_probs = []
        self.sorted_lengths = []
        self.batch_sampler = None
        self.data_loader = None",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/,Evaluator,Previous sibling does not exist,"def add_probs(self, probs):
        assert self.probs is None
        self.probs = probs","(47, 4)","(59, 31)",N,function_definition,__init__,,90,cfb6806a-845a-430d-b7be-bc9e882f649a
"def add_probs(self, probs):
        assert self.probs is None
        self.probs = probs",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/,Evaluator,"def __init__(self, config, paradigm, vocab):
        self.config = config
        self.paradigm = paradigm
        self.vocab = vocab
        self.probs = None
        self.top_probs = []
        self.prob_graph = {}
        self.new_subprobs = []
        self.lengths = {}
        self.sorted_probs = []
        self.sorted_lengths = []
        self.batch_sampler = None
        self.data_loader = None","def extend_prob_graph(self, probs):
        for prob in probs:
            if prob in self.prob_graph:
                continue
            self.new_subprobs.append(prob)
            prob_cls, args = prob
            if self.paradigm == 'rot':
                subprobs = [t[:2] for t in prob_cls.thought(args)]
            else:
                subprobs = []
            self.prob_graph[prob] = subprobs
            if len(subprobs) > 0:
                self.extend_prob_graph(subprobs)","(61, 4)","(63, 26)",N,function_definition,add_probs,,21,a29ea7a1-cce2-4550-8b03-9963e7116b8e
"def extend_prob_graph(self, probs):
        for prob in probs:
            if prob in self.prob_graph:
                continue
            self.new_subprobs.append(prob)
            prob_cls, args = prob
            if self.paradigm == 'rot':
                subprobs = [t[:2] for t in prob_cls.thought(args)]
            else:
                subprobs = []
            self.prob_graph[prob] = subprobs
            if len(subprobs) > 0:
                self.extend_prob_graph(subprobs)",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/,Evaluator,"def add_probs(self, probs):
        assert self.probs is None
        self.probs = probs","def update(self):
        self.top_probs.extend(self.probs)
        self.extend_prob_graph(self.probs)
        with Pool(self.config['num_workers']) as pool:
            # Get context lengths of new subproblems
            new_lengths = pool.map(
                partial(solution_length, paradigm=self.paradigm),
                self.new_subprobs)
        for subprob, length in zip(self.new_subprobs, new_lengths):
            self.lengths[subprob] = length
        self.sorted_probs, self.sorted_lengths = zip(*sorted(
            self.lengths.items(),
            key=lambda x: x[1], reverse=True))
        test_set = FixedProblemSet(
            self.sorted_probs, paradigm=self.paradigm, vocab=self.vocab)
        print(f'Total contexts: {len(self.sorted_probs)}')
        self.batch_sampler = SortedBatchSampler(
            self.sorted_lengths, budget=self.config['eval_length_budget'])
        self.data_loader = DataLoader(
            test_set, batch_sampler=self.batch_sampler,
            num_workers=self.config['num_workers'],
            collate_fn=collate_simple)

        self.probs = None
        self.new_subprobs = []","(65, 4)","(77, 48)",N,function_definition,extend_prob_graph,,112,5eb753e1-b07e-4a12-8ee2-923cecb1aad7
"def update(self):
        self.top_probs.extend(self.probs)
        self.extend_prob_graph(self.probs)
        with Pool(self.config['num_workers']) as pool:
            # Get context lengths of new subproblems
            new_lengths = pool.map(
                partial(solution_length, paradigm=self.paradigm),
                self.new_subprobs)
        for subprob, length in zip(self.new_subprobs, new_lengths):
            self.lengths[subprob] = length
        self.sorted_probs, self.sorted_lengths = zip(*sorted(
            self.lengths.items(),
            key=lambda x: x[1], reverse=True))
        test_set = FixedProblemSet(
            self.sorted_probs, paradigm=self.paradigm, vocab=self.vocab)
        print(f'Total contexts: {len(self.sorted_probs)}')
        self.batch_sampler = SortedBatchSampler(
            self.sorted_lengths, budget=self.config['eval_length_budget'])
        self.data_loader = DataLoader(
            test_set, batch_sampler=self.batch_sampler,
            num_workers=self.config['num_workers'],
            collate_fn=collate_simple)

        self.probs = None
        self.new_subprobs = []",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/,Evaluator,"def extend_prob_graph(self, probs):
        for prob in probs:
            if prob in self.prob_graph:
                continue
            self.new_subprobs.append(prob)
            prob_cls, args = prob
            if self.paradigm == 'rot':
                subprobs = [t[:2] for t in prob_cls.thought(args)]
            else:
                subprobs = []
            self.prob_graph[prob] = subprobs
            if len(subprobs) > 0:
                self.extend_prob_graph(subprobs)","def evaluate(self, model):
        if self.probs is not None:
            # Lazy initialization
            with Timer('Updating evaluator: {:.3f}s'):
                self.update()

        training = model.training
        model.eval()

        # Evaluate unique subproblems
        node_eval = {}
        subprob_total = defaultdict(int)
        subprob_correct = defaultdict(int)
        wrong_rsvrs = defaultdict(
            lambda: Reservoir(self.config['num_wrong_summary']))
        with torch.no_grad():
            for ((x, y, label),), prob_indices in \
                    zip(self.data_loader, self.batch_sampler):
                # Infer
                x, y = x.to(model.device), y.to(model.device)
                label = label.to(model.device)
                pred = model(x).argmax(dim=-1)
                ignore = label < Label.T
                correct = ((pred == y) | ignore).all(dim=0)
                correct = correct.tolist()

                # Record results
                for batch_idx, (prob_idx, c) in \
                        enumerate(zip(prob_indices, correct)):
                    prob = self.sorted_probs[prob_idx]
                    assert prob not in node_eval
                    node_eval[prob] = c
                    prob_cls, _ = prob
                    subprob_total[prob_cls] += 1
                    if c:
                        subprob_correct[prob_cls] += 1
                    elif wrong_rsvrs[prob_cls].reserve():
                        wrong_rsvrs[prob_cls].add((
                            y[:, batch_idx],
                            pred[:, batch_idx],
                            label[:, batch_idx]
                        ))
                torch.cuda.empty_cache()

        correct_deep, correct_shallow, prob_total = self.aggregate_eval(
            node_eval)

        # Textualize wrong samples
        wrong_samples = {
            prob_cls: [
                compare_pred(y, pred, label, itos=model.itos)
                for y, pred, label in wrong_rsvrs[prob_cls]
            ]
            for prob_cls in prob_total
        }

        model.train(training)

        return {
            'prob_total': prob_total,
            'correct_shallow': correct_shallow,
            'correct_deep': correct_deep,
            'subprob_total': subprob_total,
            'subprob_correct': subprob_correct,
            'accuracy_shallow': {
                prob_cls: correct_shallow[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_deep': {
                prob_cls: correct_deep[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_subprob': {
                prob_cls: subprob_correct[prob_cls] / total
                for prob_cls, total in subprob_total.items()
            },
            'wrong_samples': wrong_samples,
        }","(79, 4)","(103, 30)",N,function_definition,update,,236,993a23cb-89e5-4929-bc5b-f6f2c728ca8b
"def evaluate(self, model):
        if self.probs is not None:
            # Lazy initialization
            with Timer('Updating evaluator: {:.3f}s'):
                self.update()

        training = model.training
        model.eval()

        # Evaluate unique subproblems
        node_eval = {}
        subprob_total = defaultdict(int)
        subprob_correct = defaultdict(int)
        wrong_rsvrs = defaultdict(
            lambda: Reservoir(self.config['num_wrong_summary']))
        with torch.no_grad():
            for ((x, y, label),), prob_indices in \
                    zip(self.data_loader, self.batch_sampler):
                # Infer
                x, y = x.to(model.device), y.to(model.device)
                label = label.to(model.device)
                pred = model(x).argmax(dim=-1)
                ignore = label < Label.T
                correct = ((pred == y) | ignore).all(dim=0)
                correct = correct.tolist()

                # Record results
                for batch_idx, (prob_idx, c) in \
                        enumerate(zip(prob_indices, correct)):
                    prob = self.sorted_probs[prob_idx]
                    assert prob not in node_eval
                    node_eval[prob] = c
                    prob_cls, _ = prob
                    subprob_total[prob_cls] += 1
                    if c:
                        subprob_correct[prob_cls] += 1
                    elif wrong_rsvrs[prob_cls].reserve():
                        wrong_rsvrs[prob_cls].add((
                            y[:, batch_idx],
                            pred[:, batch_idx],
                            label[:, batch_idx]
                        ))
                torch.cuda.empty_cache()

        correct_deep, correct_shallow, prob_total = self.aggregate_eval(
            node_eval)

        # Textualize wrong samples
        wrong_samples = {
            prob_cls: [
                compare_pred(y, pred, label, itos=model.itos)
                for y, pred, label in wrong_rsvrs[prob_cls]
            ]
            for prob_cls in prob_total
        }

        model.train(training)

        return {
            'prob_total': prob_total,
            'correct_shallow': correct_shallow,
            'correct_deep': correct_deep,
            'subprob_total': subprob_total,
            'subprob_correct': subprob_correct,
            'accuracy_shallow': {
                prob_cls: correct_shallow[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_deep': {
                prob_cls: correct_deep[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_subprob': {
                prob_cls: subprob_correct[prob_cls] / total
                for prob_cls, total in subprob_total.items()
            },
            'wrong_samples': wrong_samples,
        }",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/,Evaluator,"def update(self):
        self.top_probs.extend(self.probs)
        self.extend_prob_graph(self.probs)
        with Pool(self.config['num_workers']) as pool:
            # Get context lengths of new subproblems
            new_lengths = pool.map(
                partial(solution_length, paradigm=self.paradigm),
                self.new_subprobs)
        for subprob, length in zip(self.new_subprobs, new_lengths):
            self.lengths[subprob] = length
        self.sorted_probs, self.sorted_lengths = zip(*sorted(
            self.lengths.items(),
            key=lambda x: x[1], reverse=True))
        test_set = FixedProblemSet(
            self.sorted_probs, paradigm=self.paradigm, vocab=self.vocab)
        print(f'Total contexts: {len(self.sorted_probs)}')
        self.batch_sampler = SortedBatchSampler(
            self.sorted_lengths, budget=self.config['eval_length_budget'])
        self.data_loader = DataLoader(
            test_set, batch_sampler=self.batch_sampler,
            num_workers=self.config['num_workers'],
            collate_fn=collate_simple)

        self.probs = None
        self.new_subprobs = []","if self.probs is not None:
            # Lazy initialization
            with Timer('Updating evaluator: {:.3f}s'):
                self.update()
training = model.training
model.eval()
# Evaluate unique subproblems
node_eval = {}
subprob_total = defaultdict(int)
subprob_correct = defaultdict(int)
wrong_rsvrs = defaultdict(
            lambda: Reservoir(self.config['num_wrong_summary']))
with torch.no_grad():
            for ((x, y, label),), prob_indices in \
                    zip(self.data_loader, self.batch_sampler):
                # Infer
                x, y = x.to(model.device), y.to(model.device)
                label = label.to(model.device)
                pred = model(x).argmax(dim=-1)
                ignore = label < Label.T
                correct = ((pred == y) | ignore).all(dim=0)
                correct = correct.tolist()

                # Record results
                for batch_idx, (prob_idx, c) in \
                        enumerate(zip(prob_indices, correct)):
                    prob = self.sorted_probs[prob_idx]
                    assert prob not in node_eval
                    node_eval[prob] = c
                    prob_cls, _ = prob
                    subprob_total[prob_cls] += 1
                    if c:
                        subprob_correct[prob_cls] += 1
                    elif wrong_rsvrs[prob_cls].reserve():
                        wrong_rsvrs[prob_cls].add((
                            y[:, batch_idx],
                            pred[:, batch_idx],
                            label[:, batch_idx]
                        ))
                torch.cuda.empty_cache()
correct_deep, correct_shallow, prob_total = self.aggregate_eval(
            node_eval)
# Textualize wrong samples
wrong_samples = {
            prob_cls: [
                compare_pred(y, pred, label, itos=model.itos)
                for y, pred, label in wrong_rsvrs[prob_cls]
            ]
            for prob_cls in prob_total
        }
model.train(training)","(105, 4)","(182, 9)",N,function_definition,evaluate,,576,47b65720-a256-4653-8657-1b82ae13d016
"if self.probs is not None:
            # Lazy initialization
            with Timer('Updating evaluator: {:.3f}s'):
                self.update()
training = model.training
model.eval()
# Evaluate unique subproblems
node_eval = {}
subprob_total = defaultdict(int)
subprob_correct = defaultdict(int)
wrong_rsvrs = defaultdict(
            lambda: Reservoir(self.config['num_wrong_summary']))
with torch.no_grad():
            for ((x, y, label),), prob_indices in \
                    zip(self.data_loader, self.batch_sampler):
                # Infer
                x, y = x.to(model.device), y.to(model.device)
                label = label.to(model.device)
                pred = model(x).argmax(dim=-1)
                ignore = label < Label.T
                correct = ((pred == y) | ignore).all(dim=0)
                correct = correct.tolist()

                # Record results
                for batch_idx, (prob_idx, c) in \
                        enumerate(zip(prob_indices, correct)):
                    prob = self.sorted_probs[prob_idx]
                    assert prob not in node_eval
                    node_eval[prob] = c
                    prob_cls, _ = prob
                    subprob_total[prob_cls] += 1
                    if c:
                        subprob_correct[prob_cls] += 1
                    elif wrong_rsvrs[prob_cls].reserve():
                        wrong_rsvrs[prob_cls].add((
                            y[:, batch_idx],
                            pred[:, batch_idx],
                            label[:, batch_idx]
                        ))
                torch.cuda.empty_cache()
correct_deep, correct_shallow, prob_total = self.aggregate_eval(
            node_eval)
# Textualize wrong samples
wrong_samples = {
            prob_cls: [
                compare_pred(y, pred, label, itos=model.itos)
                for y, pred, label in wrong_rsvrs[prob_cls]
            ]
            for prob_cls in prob_total
        }
model.train(training)",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/function_definition-evaluate/,evaluate,Previous sibling does not exist,"return {
            'prob_total': prob_total,
            'correct_shallow': correct_shallow,
            'correct_deep': correct_deep,
            'subprob_total': subprob_total,
            'subprob_correct': subprob_correct,
            'accuracy_shallow': {
                prob_cls: correct_shallow[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_deep': {
                prob_cls: correct_deep[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_subprob': {
                prob_cls: subprob_correct[prob_cls] / total
                for prob_cls, total in subprob_total.items()
            },
            'wrong_samples': wrong_samples,
        }","(106, 8)","(161, 29)",N,"if_statement,expression_statement,expression_statement,comment,expression_statement,expression_statement,expression_statement,expression_statement,with_statement,expression_statement,comment,expression_statement,expression_statement",if_statement,,394,e6e97d1d-9b74-440c-8ec2-abb11ebc93a0
"return {
            'prob_total': prob_total,
            'correct_shallow': correct_shallow,
            'correct_deep': correct_deep,
            'subprob_total': subprob_total,
            'subprob_correct': subprob_correct,
            'accuracy_shallow': {
                prob_cls: correct_shallow[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_deep': {
                prob_cls: correct_deep[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_subprob': {
                prob_cls: subprob_correct[prob_cls] / total
                for prob_cls, total in subprob_total.items()
            },
            'wrong_samples': wrong_samples,
        }",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/function_definition-evaluate/,evaluate,model.train(training),Next sibling does not exist,"(163, 8)","(182, 9)",N,return_statement,return_statement,,159,ede0fb66-eedc-4ce2-988f-b89f710b12e0
"def aggregate_eval(self, node_eval):
        # Aggregate subproblem evaluations
        subtree_eval = {}
        prob_total = defaultdict(int)
        correct_shallow = defaultdict(int)
        correct_deep = defaultdict(int)
        for prob in self.top_probs:
            prob_cls = prob[0]
            if node_eval[prob]:
                correct_shallow[prob_cls] += 1
            if self.eval_subtree(prob, node_eval, subtree_eval):
                correct_deep[prob_cls] += 1
            prob_total[prob_cls] += 1
        return correct_deep, correct_shallow, prob_total",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/,Evaluator,"return {
            'prob_total': prob_total,
            'correct_shallow': correct_shallow,
            'correct_deep': correct_deep,
            'subprob_total': subprob_total,
            'subprob_correct': subprob_correct,
            'accuracy_shallow': {
                prob_cls: correct_shallow[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_deep': {
                prob_cls: correct_deep[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_subprob': {
                prob_cls: subprob_correct[prob_cls] / total
                for prob_cls, total in subprob_total.items()
            },
            'wrong_samples': wrong_samples,
        }","def eval_subtree(self, prob, node_eval, subtree_eval):
        if prob in subtree_eval:
            # Already evaluated
            return subtree_eval[prob]

        if len(self.prob_graph[prob]) == 0:
            subtree_eval[prob] = node_eval[prob]
            return subtree_eval[prob]
        if not node_eval[prob]:
            subtree_eval[prob] = False
            return False

        subtree_eval[prob] = all([
            self.eval_subtree(subprob, node_eval, subtree_eval)
            for subprob in self.prob_graph[prob]
        ])
        return subtree_eval[prob]","(184, 4)","(197, 56)",N,function_definition,aggregate_eval,,124,7cf428ba-d1bc-4c85-ba1a-b4b7b3690c0b
"def eval_subtree(self, prob, node_eval, subtree_eval):
        if prob in subtree_eval:
            # Already evaluated
            return subtree_eval[prob]

        if len(self.prob_graph[prob]) == 0:
            subtree_eval[prob] = node_eval[prob]
            return subtree_eval[prob]
        if not node_eval[prob]:
            subtree_eval[prob] = False
            return False

        subtree_eval[prob] = all([
            self.eval_subtree(subprob, node_eval, subtree_eval)
            for subprob in self.prob_graph[prob]
        ])
        return subtree_eval[prob]",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/,Evaluator,"def aggregate_eval(self, node_eval):
        # Aggregate subproblem evaluations
        subtree_eval = {}
        prob_total = defaultdict(int)
        correct_shallow = defaultdict(int)
        correct_deep = defaultdict(int)
        for prob in self.top_probs:
            prob_cls = prob[0]
            if node_eval[prob]:
                correct_shallow[prob_cls] += 1
            if self.eval_subtree(prob, node_eval, subtree_eval):
                correct_deep[prob_cls] += 1
            prob_total[prob_cls] += 1
        return correct_deep, correct_shallow, prob_total","def state_dict(self):
        return {
            'config': self.config,
            'paradigm': self.paradigm,
            'probs': self.probs,
            'top_probs': self.top_probs,
            'prob_graph': self.prob_graph,
            'sorted_probs': self.sorted_probs,
            'sorted_lengths': self.sorted_lengths,
            'batch_sampler': self.batch_sampler,
            'data_loader': self.data_loader,
        }","(199, 4)","(215, 33)",N,function_definition,eval_subtree,,129,49da4e2a-058c-43c0-8f6e-0ada5a690c99
"def state_dict(self):
        return {
            'config': self.config,
            'paradigm': self.paradigm,
            'probs': self.probs,
            'top_probs': self.top_probs,
            'prob_graph': self.prob_graph,
            'sorted_probs': self.sorted_probs,
            'sorted_lengths': self.sorted_lengths,
            'batch_sampler': self.batch_sampler,
            'data_loader': self.data_loader,
        }",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/,Evaluator,"def eval_subtree(self, prob, node_eval, subtree_eval):
        if prob in subtree_eval:
            # Already evaluated
            return subtree_eval[prob]

        if len(self.prob_graph[prob]) == 0:
            subtree_eval[prob] = node_eval[prob]
            return subtree_eval[prob]
        if not node_eval[prob]:
            subtree_eval[prob] = False
            return False

        subtree_eval[prob] = all([
            self.eval_subtree(subprob, node_eval, subtree_eval)
            for subprob in self.prob_graph[prob]
        ])
        return subtree_eval[prob]","def load_state_dict(self, state_dict):
        self.config = state_dict['config']
        self.paradigm = state_dict['paradigm']
        self.probs = state_dict['probs']
        self.top_probs = state_dict['top_probs']
        self.prob_graph = state_dict['prob_graph']
        self.sorted_probs = state_dict['sorted_probs']
        self.sorted_lengths = state_dict['sorted_lengths']
        self.batch_sampler = state_dict['batch_sampler']
        self.data_loader = state_dict['data_loader']","(217, 4)","(228, 9)",N,function_definition,state_dict,,91,fa9e41d5-fcaa-46d9-b207-96b6cd70cea1
"def load_state_dict(self, state_dict):
        self.config = state_dict['config']
        self.paradigm = state_dict['paradigm']
        self.probs = state_dict['probs']
        self.top_probs = state_dict['top_probs']
        self.prob_graph = state_dict['prob_graph']
        self.sorted_probs = state_dict['sorted_probs']
        self.sorted_lengths = state_dict['sorted_lengths']
        self.batch_sampler = state_dict['batch_sampler']
        self.data_loader = state_dict['data_loader']",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/class_definition-Evaluator/,Evaluator,"def state_dict(self):
        return {
            'config': self.config,
            'paradigm': self.paradigm,
            'probs': self.probs,
            'top_probs': self.top_probs,
            'prob_graph': self.prob_graph,
            'sorted_probs': self.sorted_probs,
            'sorted_lengths': self.sorted_lengths,
            'batch_sampler': self.batch_sampler,
            'data_loader': self.data_loader,
        }",Next sibling does not exist,"(230, 4)","(239, 52)",N,function_definition,load_state_dict,,108,8802fb0d-5c16-4d51-b0ed-6c0087d88393
"def compare_pred(y, pred, label, itos):
    text_y, text_p = '', ''
    for t_y, t_p, t_l in zip(y, pred, label):
        if t_l == Label.PAD:
            continue
        dec_t_y = itos[t_y]
        dec_t_p = itos[t_p]
        if t_l == Label.Q:
            text_y += f'{dec_t_y}'
            text_p += ' ' * len(dec_t_y)
            continue
        if dec_t_y == dec_t_p:
            text_y += dec_t_y
            text_p += dec_t_p
            continue
        max_len = max(len(dec_t_y), len(dec_t_p))
        text_y += f'{dec_t_y:{max_len}}'
        text_p += f'{dec_t_p:{max_len}}'
    return f'{text_y}\n{text_p}'",eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\eval.py,module/,module,"class Evaluator:
    def __init__(self, config, paradigm, vocab):
        self.config = config
        self.paradigm = paradigm
        self.vocab = vocab
        self.probs = None
        self.top_probs = []
        self.prob_graph = {}
        self.new_subprobs = []
        self.lengths = {}
        self.sorted_probs = []
        self.sorted_lengths = []
        self.batch_sampler = None
        self.data_loader = None

    def add_probs(self, probs):
        assert self.probs is None
        self.probs = probs

    def extend_prob_graph(self, probs):
        for prob in probs:
            if prob in self.prob_graph:
                continue
            self.new_subprobs.append(prob)
            prob_cls, args = prob
            if self.paradigm == 'rot':
                subprobs = [t[:2] for t in prob_cls.thought(args)]
            else:
                subprobs = []
            self.prob_graph[prob] = subprobs
            if len(subprobs) > 0:
                self.extend_prob_graph(subprobs)

    def update(self):
        self.top_probs.extend(self.probs)
        self.extend_prob_graph(self.probs)
        with Pool(self.config['num_workers']) as pool:
            # Get context lengths of new subproblems
            new_lengths = pool.map(
                partial(solution_length, paradigm=self.paradigm),
                self.new_subprobs)
        for subprob, length in zip(self.new_subprobs, new_lengths):
            self.lengths[subprob] = length
        self.sorted_probs, self.sorted_lengths = zip(*sorted(
            self.lengths.items(),
            key=lambda x: x[1], reverse=True))
        test_set = FixedProblemSet(
            self.sorted_probs, paradigm=self.paradigm, vocab=self.vocab)
        print(f'Total contexts: {len(self.sorted_probs)}')
        self.batch_sampler = SortedBatchSampler(
            self.sorted_lengths, budget=self.config['eval_length_budget'])
        self.data_loader = DataLoader(
            test_set, batch_sampler=self.batch_sampler,
            num_workers=self.config['num_workers'],
            collate_fn=collate_simple)

        self.probs = None
        self.new_subprobs = []

    def evaluate(self, model):
        if self.probs is not None:
            # Lazy initialization
            with Timer('Updating evaluator: {:.3f}s'):
                self.update()

        training = model.training
        model.eval()

        # Evaluate unique subproblems
        node_eval = {}
        subprob_total = defaultdict(int)
        subprob_correct = defaultdict(int)
        wrong_rsvrs = defaultdict(
            lambda: Reservoir(self.config['num_wrong_summary']))
        with torch.no_grad():
            for ((x, y, label),), prob_indices in \
                    zip(self.data_loader, self.batch_sampler):
                # Infer
                x, y = x.to(model.device), y.to(model.device)
                label = label.to(model.device)
                pred = model(x).argmax(dim=-1)
                ignore = label < Label.T
                correct = ((pred == y) | ignore).all(dim=0)
                correct = correct.tolist()

                # Record results
                for batch_idx, (prob_idx, c) in \
                        enumerate(zip(prob_indices, correct)):
                    prob = self.sorted_probs[prob_idx]
                    assert prob not in node_eval
                    node_eval[prob] = c
                    prob_cls, _ = prob
                    subprob_total[prob_cls] += 1
                    if c:
                        subprob_correct[prob_cls] += 1
                    elif wrong_rsvrs[prob_cls].reserve():
                        wrong_rsvrs[prob_cls].add((
                            y[:, batch_idx],
                            pred[:, batch_idx],
                            label[:, batch_idx]
                        ))
                torch.cuda.empty_cache()

        correct_deep, correct_shallow, prob_total = self.aggregate_eval(
            node_eval)

        # Textualize wrong samples
        wrong_samples = {
            prob_cls: [
                compare_pred(y, pred, label, itos=model.itos)
                for y, pred, label in wrong_rsvrs[prob_cls]
            ]
            for prob_cls in prob_total
        }

        model.train(training)

        return {
            'prob_total': prob_total,
            'correct_shallow': correct_shallow,
            'correct_deep': correct_deep,
            'subprob_total': subprob_total,
            'subprob_correct': subprob_correct,
            'accuracy_shallow': {
                prob_cls: correct_shallow[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_deep': {
                prob_cls: correct_deep[prob_cls] / total
                for prob_cls, total in prob_total.items()
            },
            'accuracy_subprob': {
                prob_cls: subprob_correct[prob_cls] / total
                for prob_cls, total in subprob_total.items()
            },
            'wrong_samples': wrong_samples,
        }

    def aggregate_eval(self, node_eval):
        # Aggregate subproblem evaluations
        subtree_eval = {}
        prob_total = defaultdict(int)
        correct_shallow = defaultdict(int)
        correct_deep = defaultdict(int)
        for prob in self.top_probs:
            prob_cls = prob[0]
            if node_eval[prob]:
                correct_shallow[prob_cls] += 1
            if self.eval_subtree(prob, node_eval, subtree_eval):
                correct_deep[prob_cls] += 1
            prob_total[prob_cls] += 1
        return correct_deep, correct_shallow, prob_total

    def eval_subtree(self, prob, node_eval, subtree_eval):
        if prob in subtree_eval:
            # Already evaluated
            return subtree_eval[prob]

        if len(self.prob_graph[prob]) == 0:
            subtree_eval[prob] = node_eval[prob]
            return subtree_eval[prob]
        if not node_eval[prob]:
            subtree_eval[prob] = False
            return False

        subtree_eval[prob] = all([
            self.eval_subtree(subprob, node_eval, subtree_eval)
            for subprob in self.prob_graph[prob]
        ])
        return subtree_eval[prob]

    def state_dict(self):
        return {
            'config': self.config,
            'paradigm': self.paradigm,
            'probs': self.probs,
            'top_probs': self.top_probs,
            'prob_graph': self.prob_graph,
            'sorted_probs': self.sorted_probs,
            'sorted_lengths': self.sorted_lengths,
            'batch_sampler': self.batch_sampler,
            'data_loader': self.data_loader,
        }

    def load_state_dict(self, state_dict):
        self.config = state_dict['config']
        self.paradigm = state_dict['paradigm']
        self.probs = state_dict['probs']
        self.top_probs = state_dict['top_probs']
        self.prob_graph = state_dict['prob_graph']
        self.sorted_probs = state_dict['sorted_probs']
        self.sorted_lengths = state_dict['sorted_lengths']
        self.batch_sampler = state_dict['batch_sampler']
        self.data_loader = state_dict['data_loader']",Next sibling does not exist,"(242, 0)","(260, 32)",N,function_definition,compare_pred,,187,10ce931b-4770-432e-acfb-86a5633ce0ca
"#!/usr/bin/env python
# coding: utf-8

import json
import os
import os.path as path
import random
import time
from collections import namedtuple
from datetime import datetime
from glob import glob
from functools import partial
from multiprocessing import Pool
from concurrent.futures import ThreadPoolExecutor

import openai
import pandas as pd
import torch
import yaml
from tqdm.auto import tqdm
from transformers import GPT2Tokenizer
from ratelimit import limits, sleep_and_retry

from data import PROBLEM
from data.problem import build_vocab, ProblemSet, collate_by_len
from eval import Evaluator
from gpt_fine_tune import GPTDataGenerator

openai.api_key = os.getenv('OPENAI_API_KEY')



gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')


def count_tokens(gpt_data):
    count = 0
    for datum in tqdm(gpt_data):
        count += len(gpt2_tokenizer(datum['prompt'])['input_ids'])
        count += len(gpt2_tokenizer(datum['completion'])['input_ids'])
    return count


def bill(count, training: bool, verbose=False):
    if training:
        prices = {
            'Ada': 0.0004,
            'Babbage': 0.0006,
            'Curie': 0.003,
            'Davinci': 0.03
        }
    else:
        prices = {
            'Ada': 0.0016,
            'Babbage': 0.0024,
            'Curie': 0.012,
            'Davinci': 0.12
        }
    costs = {
        model: count / 1000 * unit_price
        for model, unit_price in prices.items()
    }
    if verbose:
        print(f'{count:,} tokens')
        for model, cost in costs.items():
            print(f'{model}: ${cost:.2f}')
    return costs


def openai_to_dict(obj):
    if isinstance(obj, dict):
        return {
            key: openai_to_dict(value)
            for key, value in obj.items()
        }
    elif isinstance(obj, list):
        return [openai_to_dict(elem) for elem in obj]
    else:
        return obj


def human_format(num):
    num = float('{:.3g}'.format(num))
    magnitude = 0
    while abs(num) >= 1000:
        magnitude += 1
        num /= 1000.0
    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'),
                         ['', 'K', 'M', 'B', 'T'][magnitude])




Experiment = namedtuple('Experiment',
                        ['prob_name', 'prob_size', 'model', 'paradigm'])


def get_exp_name(exp):
    return f'{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'


def get_exp_dir(exp):
    return f'gpt3/{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'


def get_exp_episode(exp):
    episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
    with open(episode_path, 'r') as f:
        episode = yaml.load(f, Loader=yaml.FullLoader)
    return episode


def get_exp_vocab(exp):
    episode = get_exp_episode(exp)
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    return build_vocab(prob_classes, paradigm=exp.paradigm)


@sleep_and_retry
@limits(calls=1, period=0.025)
def save_inference(args, model_id):
    example, save_path = args
    if path.isfile(save_path):
        return True
    max_tokens = len(gpt2_tokenizer(example['completion'])['input_ids']) + 1
    for retry in range(10):
        try:
            result = openai.Completion.create(
                model=model_id,
                prompt=example['prompt'],
                max_tokens=max_tokens,
                temperature=0
            )
            with open(save_path, 'w') as f:
                json.dump(result, f, indent=2)
            return True
        except openai.error.RateLimitError as e:
            # print(e)
            time.sleep(5)

    print('Maximum retry exceed. Failed to evaluate an example.')
    return False


def evaluate(exp):
    processes = 32
    exp_dir = get_exp_dir(exp)
    infer_dir = path.join(exp_dir, 'inferences')
    eval_result_path = path.join(exp_dir, 'eval_result.yaml')
    if path.isfile(eval_result_path):
        # Already done
        return

    evaluator_path = path.join(exp_dir, 'evaluator.pt')
    fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
    if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return

    dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
    generator = GPTDataGenerator(exp)
    evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
    evaluator.load_state_dict(torch.load(evaluator_path))
    with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
    model_id = fine_tune_complete['fine_tuned_model']

    os.makedirs(infer_dir, mode=0o700, exist_ok=True)

    eval_data = []
    infer_args = []
    skip_count = 0
    for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))

    print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
    print(f'Model ID: {model_id}')
    with ThreadPoolExecutor(max_workers=16) as pool:
        successes = list(tqdm(
            pool.map(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))
    if not all(successes):
        print('Found failed API calls. Retry evaluation later...')
        return

    # Aggregate results
    corrects = []
    wrongs = []
    for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)

    node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
    correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
    with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
    print(f'Evaluation result written to {eval_result_path}')


def main():
    while True:
        try:
            for exp_dir in glob('gpt3/*'):
                fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
                eval_result_path = path.join(exp_dir, 'eval_result.yaml')
                if path.isfile(fine_tune_complete_path) and not path.isfile(eval_result_path):
                    prob_name, prob_size, paradigm = path.basename(exp_dir).split('-')
                    exp = Experiment(prob_name, prob_size, 'gpt3', paradigm)
                    evaluate(exp)
        except Exception as e:
            print(e)
        time.sleep(30)


if __name__ == '__main__':
    main()
",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,,NA,Previous sibling does not exist,"#!/usr/bin/env python
# coding: utf-8
import json
import os
import os.path as path
import random
import time
from collections import namedtuple
from datetime import datetime
from glob import glob
from functools import partial
from multiprocessing import Pool
from concurrent.futures import ThreadPoolExecutor
import openai
import pandas as pd
import torch
import yaml
from tqdm.auto import tqdm
from transformers import GPT2Tokenizer
from ratelimit import limits, sleep_and_retry
from data import PROBLEM
from data.problem import build_vocab, ProblemSet, collate_by_len
from eval import Evaluator
from gpt_fine_tune import GPTDataGenerator
openai.api_key = os.getenv('OPENAI_API_KEY')
gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')","(0, 0)","(249, 0)",N,module,module,,1810,f7898520-3632-493b-a67f-61a16f143ecd
"#!/usr/bin/env python
# coding: utf-8
import json
import os
import os.path as path
import random
import time
from collections import namedtuple
from datetime import datetime
from glob import glob
from functools import partial
from multiprocessing import Pool
from concurrent.futures import ThreadPoolExecutor
import openai
import pandas as pd
import torch
import yaml
from tqdm.auto import tqdm
from transformers import GPT2Tokenizer
from ratelimit import limits, sleep_and_retry
from data import PROBLEM
from data.problem import build_vocab, ProblemSet, collate_by_len
from eval import Evaluator
from gpt_fine_tune import GPTDataGenerator
openai.api_key = os.getenv('OPENAI_API_KEY')
gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,Previous sibling does not exist,"def count_tokens(gpt_data):
    count = 0
    for datum in tqdm(gpt_data):
        count += len(gpt2_tokenizer(datum['prompt'])['input_ids'])
        count += len(gpt2_tokenizer(datum['completion'])['input_ids'])
    return count","(0, 0)","(32, 54)",N,"comment,comment,import_statement,import_statement,import_statement,import_statement,import_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_statement,import_statement,import_statement,import_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,expression_statement,expression_statement",comment,,151,8b2d2861-eb60-4329-8f85-4db050ef80c9
"def count_tokens(gpt_data):
    count = 0
    for datum in tqdm(gpt_data):
        count += len(gpt2_tokenizer(datum['prompt'])['input_ids'])
        count += len(gpt2_tokenizer(datum['completion'])['input_ids'])
    return count",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"#!/usr/bin/env python
# coding: utf-8
import json
import os
import os.path as path
import random
import time
from collections import namedtuple
from datetime import datetime
from glob import glob
from functools import partial
from multiprocessing import Pool
from concurrent.futures import ThreadPoolExecutor
import openai
import pandas as pd
import torch
import yaml
from tqdm.auto import tqdm
from transformers import GPT2Tokenizer
from ratelimit import limits, sleep_and_retry
from data import PROBLEM
from data.problem import build_vocab, ProblemSet, collate_by_len
from eval import Evaluator
from gpt_fine_tune import GPTDataGenerator
openai.api_key = os.getenv('OPENAI_API_KEY')
gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')","def bill(count, training: bool, verbose=False):
    if training:
        prices = {
            'Ada': 0.0004,
            'Babbage': 0.0006,
            'Curie': 0.003,
            'Davinci': 0.03
        }
    else:
        prices = {
            'Ada': 0.0016,
            'Babbage': 0.0024,
            'Curie': 0.012,
            'Davinci': 0.12
        }
    costs = {
        model: count / 1000 * unit_price
        for model, unit_price in prices.items()
    }
    if verbose:
        print(f'{count:,} tokens')
        for model, cost in costs.items():
            print(f'{model}: ${cost:.2f}')
    return costs","(35, 0)","(40, 16)",N,function_definition,count_tokens,,61,b20c7d1d-0d26-4a6c-b7ef-1518ebd3798f
"def bill(count, training: bool, verbose=False):
    if training:
        prices = {
            'Ada': 0.0004,
            'Babbage': 0.0006,
            'Curie': 0.003,
            'Davinci': 0.03
        }
    else:
        prices = {
            'Ada': 0.0016,
            'Babbage': 0.0024,
            'Curie': 0.012,
            'Davinci': 0.12
        }
    costs = {
        model: count / 1000 * unit_price
        for model, unit_price in prices.items()
    }
    if verbose:
        print(f'{count:,} tokens')
        for model, cost in costs.items():
            print(f'{model}: ${cost:.2f}')
    return costs",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"def count_tokens(gpt_data):
    count = 0
    for datum in tqdm(gpt_data):
        count += len(gpt2_tokenizer(datum['prompt'])['input_ids'])
        count += len(gpt2_tokenizer(datum['completion'])['input_ids'])
    return count","def openai_to_dict(obj):
    if isinstance(obj, dict):
        return {
            key: openai_to_dict(value)
            for key, value in obj.items()
        }
    elif isinstance(obj, list):
        return [openai_to_dict(elem) for elem in obj]
    else:
        return obj","(43, 0)","(66, 16)",N,function_definition,bill,,179,140e0874-f8b2-4a2f-a25e-6587b6cd5533
"def openai_to_dict(obj):
    if isinstance(obj, dict):
        return {
            key: openai_to_dict(value)
            for key, value in obj.items()
        }
    elif isinstance(obj, list):
        return [openai_to_dict(elem) for elem in obj]
    else:
        return obj",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"def bill(count, training: bool, verbose=False):
    if training:
        prices = {
            'Ada': 0.0004,
            'Babbage': 0.0006,
            'Curie': 0.003,
            'Davinci': 0.03
        }
    else:
        prices = {
            'Ada': 0.0016,
            'Babbage': 0.0024,
            'Curie': 0.012,
            'Davinci': 0.12
        }
    costs = {
        model: count / 1000 * unit_price
        for model, unit_price in prices.items()
    }
    if verbose:
        print(f'{count:,} tokens')
        for model, cost in costs.items():
            print(f'{model}: ${cost:.2f}')
    return costs","def human_format(num):
    num = float('{:.3g}'.format(num))
    magnitude = 0
    while abs(num) >= 1000:
        magnitude += 1
        num /= 1000.0
    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'),
                         ['', 'K', 'M', 'B', 'T'][magnitude])","(69, 0)","(78, 18)",N,function_definition,openai_to_dict,,64,963f215d-d3b0-48e3-b13c-a17517dfe173
"def human_format(num):
    num = float('{:.3g}'.format(num))
    magnitude = 0
    while abs(num) >= 1000:
        magnitude += 1
        num /= 1000.0
    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'),
                         ['', 'K', 'M', 'B', 'T'][magnitude])",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"def openai_to_dict(obj):
    if isinstance(obj, dict):
        return {
            key: openai_to_dict(value)
            for key, value in obj.items()
        }
    elif isinstance(obj, list):
        return [openai_to_dict(elem) for elem in obj]
    else:
        return obj","Experiment = namedtuple('Experiment',
                        ['prob_name', 'prob_size', 'model', 'paradigm'])","(81, 0)","(88, 61)",N,function_definition,human_format,,83,a15c122f-e126-4573-9ddc-6293af675e43
"Experiment = namedtuple('Experiment',
                        ['prob_name', 'prob_size', 'model', 'paradigm'])",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"def human_format(num):
    num = float('{:.3g}'.format(num))
    magnitude = 0
    while abs(num) >= 1000:
        magnitude += 1
        num /= 1000.0
    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'),
                         ['', 'K', 'M', 'B', 'T'][magnitude])","def get_exp_name(exp):
    return f'{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'","(93, 0)","(94, 72)",N,expression_statement,expression_statement,,23,afced0a9-7326-4d48-ba8a-088c1bcee338
"def get_exp_name(exp):
    return f'{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"Experiment = namedtuple('Experiment',
                        ['prob_name', 'prob_size', 'model', 'paradigm'])","def get_exp_dir(exp):
    return f'gpt3/{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'","(97, 0)","(98, 60)",N,function_definition,get_exp_name,,23,16d1c481-8759-455c-bdfb-0424a04163c0
"def get_exp_dir(exp):
    return f'gpt3/{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"def get_exp_name(exp):
    return f'{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'","def get_exp_episode(exp):
    episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
    with open(episode_path, 'r') as f:
        episode = yaml.load(f, Loader=yaml.FullLoader)
    return episode","(101, 0)","(102, 65)",N,function_definition,get_exp_dir,,27,f480c023-08e4-4ee3-b17e-acd2025aad2a
"def get_exp_episode(exp):
    episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
    with open(episode_path, 'r') as f:
        episode = yaml.load(f, Loader=yaml.FullLoader)
    return episode",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"def get_exp_dir(exp):
    return f'gpt3/{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'","def get_exp_vocab(exp):
    episode = get_exp_episode(exp)
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    return build_vocab(prob_classes, paradigm=exp.paradigm)","(105, 0)","(109, 18)",N,function_definition,get_exp_episode,,54,2ae036fa-2bf2-4578-aa55-c375e45a61cd
"def get_exp_vocab(exp):
    episode = get_exp_episode(exp)
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    return build_vocab(prob_classes, paradigm=exp.paradigm)",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"def get_exp_episode(exp):
    episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
    with open(episode_path, 'r') as f:
        episode = yaml.load(f, Loader=yaml.FullLoader)
    return episode","@sleep_and_retry
@limits(calls=1, period=0.025)
def save_inference(args, model_id):
    example, save_path = args
    if path.isfile(save_path):
        return True
    max_tokens = len(gpt2_tokenizer(example['completion'])['input_ids']) + 1
    for retry in range(10):
        try:
            result = openai.Completion.create(
                model=model_id,
                prompt=example['prompt'],
                max_tokens=max_tokens,
                temperature=0
            )
            with open(save_path, 'w') as f:
                json.dump(result, f, indent=2)
            return True
        except openai.error.RateLimitError as e:
            # print(e)
            time.sleep(5)

    print('Maximum retry exceed. Failed to evaluate an example.')
    return False","(112, 0)","(115, 59)",N,function_definition,get_exp_vocab,,47,5a866ae8-b893-4b98-89cc-aea4c84b97ea
"@sleep_and_retry
@limits(calls=1, period=0.025)
def save_inference(args, model_id):
    example, save_path = args
    if path.isfile(save_path):
        return True
    max_tokens = len(gpt2_tokenizer(example['completion'])['input_ids']) + 1
    for retry in range(10):
        try:
            result = openai.Completion.create(
                model=model_id,
                prompt=example['prompt'],
                max_tokens=max_tokens,
                temperature=0
            )
            with open(save_path, 'w') as f:
                json.dump(result, f, indent=2)
            return True
        except openai.error.RateLimitError as e:
            # print(e)
            time.sleep(5)

    print('Maximum retry exceed. Failed to evaluate an example.')
    return False",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"def get_exp_vocab(exp):
    episode = get_exp_episode(exp)
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    return build_vocab(prob_classes, paradigm=exp.paradigm)","def evaluate(exp):
    processes = 32
    exp_dir = get_exp_dir(exp)
    infer_dir = path.join(exp_dir, 'inferences')
    eval_result_path = path.join(exp_dir, 'eval_result.yaml')
    if path.isfile(eval_result_path):
        # Already done
        return

    evaluator_path = path.join(exp_dir, 'evaluator.pt')
    fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
    if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return

    dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
    generator = GPTDataGenerator(exp)
    evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
    evaluator.load_state_dict(torch.load(evaluator_path))
    with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
    model_id = fine_tune_complete['fine_tuned_model']

    os.makedirs(infer_dir, mode=0o700, exist_ok=True)

    eval_data = []
    infer_args = []
    skip_count = 0
    for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))

    print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
    print(f'Model ID: {model_id}')
    with ThreadPoolExecutor(max_workers=16) as pool:
        successes = list(tqdm(
            pool.map(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))
    if not all(successes):
        print('Found failed API calls. Retry evaluation later...')
        return

    # Aggregate results
    corrects = []
    wrongs = []
    for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)

    node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
    correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
    with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
    print(f'Evaluation result written to {eval_result_path}')","(118, 0)","(141, 16)",N,function_definition,"def save_inference(args, model_id):
    example, save_path = args
    if path.isfile(save_path):
        return True
    max_tokens = len(gpt2_tokenizer(example['completion'])['input_ids']) + 1
    for retry in range(10):
        try:
            result = openai.Completion.create(
                model=model_id,
                prompt=example['prompt'],
                max_tokens=max_tokens,
                temperature=0
            )
            with open(save_path, 'w') as f:
                json.dump(result, f, indent=2)
            return True
        except openai.error.RateLimitError as e:
            # print(e)
            time.sleep(5)

    print('Maximum retry exceed. Failed to evaluate an example.')
    return False",,179,0d6c819a-2a66-4eac-91a9-ea8e66e264d1
"def evaluate(exp):
    processes = 32
    exp_dir = get_exp_dir(exp)
    infer_dir = path.join(exp_dir, 'inferences')
    eval_result_path = path.join(exp_dir, 'eval_result.yaml')
    if path.isfile(eval_result_path):
        # Already done
        return

    evaluator_path = path.join(exp_dir, 'evaluator.pt')
    fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
    if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return

    dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
    generator = GPTDataGenerator(exp)
    evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
    evaluator.load_state_dict(torch.load(evaluator_path))
    with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
    model_id = fine_tune_complete['fine_tuned_model']

    os.makedirs(infer_dir, mode=0o700, exist_ok=True)

    eval_data = []
    infer_args = []
    skip_count = 0
    for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))

    print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
    print(f'Model ID: {model_id}')
    with ThreadPoolExecutor(max_workers=16) as pool:
        successes = list(tqdm(
            pool.map(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))
    if not all(successes):
        print('Found failed API calls. Retry evaluation later...')
        return

    # Aggregate results
    corrects = []
    wrongs = []
    for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)

    node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
    correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
    with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
    print(f'Evaluation result written to {eval_result_path}')",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"@sleep_and_retry
@limits(calls=1, period=0.025)
def save_inference(args, model_id):
    example, save_path = args
    if path.isfile(save_path):
        return True
    max_tokens = len(gpt2_tokenizer(example['completion'])['input_ids']) + 1
    for retry in range(10):
        try:
            result = openai.Completion.create(
                model=model_id,
                prompt=example['prompt'],
                max_tokens=max_tokens,
                temperature=0
            )
            with open(save_path, 'w') as f:
                json.dump(result, f, indent=2)
            return True
        except openai.error.RateLimitError as e:
            # print(e)
            time.sleep(5)

    print('Maximum retry exceed. Failed to evaluate an example.')
    return False","processes = 32
exp_dir = get_exp_dir(exp)
infer_dir = path.join(exp_dir, 'inferences')
eval_result_path = path.join(exp_dir, 'eval_result.yaml')
if path.isfile(eval_result_path):
        # Already done
        return
evaluator_path = path.join(exp_dir, 'evaluator.pt')
fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return
dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
generator = GPTDataGenerator(exp)
evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
evaluator.load_state_dict(torch.load(evaluator_path))
with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
model_id = fine_tune_complete['fine_tuned_model']
os.makedirs(infer_dir, mode=0o700, exist_ok=True)
eval_data = []
infer_args = []
skip_count = 0
for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))
print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
print(f'Model ID: {model_id}')
with ThreadPoolExecutor(max_workers=16) as pool:
        successes = list(tqdm(
            pool.map(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))
if not all(successes):
        print('Found failed API calls. Retry evaluation later...')
        return
# Aggregate results
corrects = []
wrongs = []","(144, 0)","(229, 61)",N,function_definition,evaluate,,746,7ee14fd2-3a38-45a1-9267-a5342809ab2d
"processes = 32
exp_dir = get_exp_dir(exp)
infer_dir = path.join(exp_dir, 'inferences')
eval_result_path = path.join(exp_dir, 'eval_result.yaml')
if path.isfile(eval_result_path):
        # Already done
        return
evaluator_path = path.join(exp_dir, 'evaluator.pt')
fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return
dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
generator = GPTDataGenerator(exp)
evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
evaluator.load_state_dict(torch.load(evaluator_path))
with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
model_id = fine_tune_complete['fine_tuned_model']
os.makedirs(infer_dir, mode=0o700, exist_ok=True)
eval_data = []
infer_args = []
skip_count = 0
for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))
print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
print(f'Model ID: {model_id}')
with ThreadPoolExecutor(max_workers=16) as pool:
        successes = list(tqdm(
            pool.map(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))
if not all(successes):
        print('Found failed API calls. Retry evaluation later...')
        return
# Aggregate results
corrects = []
wrongs = []",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/function_definition-evaluate/,evaluate,Previous sibling does not exist,"for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)
node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
print(f'Evaluation result written to {eval_result_path}')","(145, 4)","(198, 15)",N,"expression_statement,expression_statement,expression_statement,expression_statement,if_statement,expression_statement,expression_statement,if_statement,expression_statement,expression_statement,expression_statement,expression_statement,with_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,for_statement,expression_statement,expression_statement,with_statement,if_statement,comment,expression_statement,expression_statement",expression_statement,,474,ebb597fe-7bd8-427f-a6ce-e90262d97988
"for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)
node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
print(f'Evaluation result written to {eval_result_path}')",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/function_definition-evaluate/,evaluate,wrongs = [],Next sibling does not exist,"(199, 4)","(229, 61)",N,"for_statement,expression_statement,expression_statement,with_statement,expression_statement",for_statement,,235,51d62e06-27ea-4625-9f1d-bc91cb10b7c1
"def main():
    while True:
        try:
            for exp_dir in glob('gpt3/*'):
                fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
                eval_result_path = path.join(exp_dir, 'eval_result.yaml')
                if path.isfile(fine_tune_complete_path) and not path.isfile(eval_result_path):
                    prob_name, prob_size, paradigm = path.basename(exp_dir).split('-')
                    exp = Experiment(prob_name, prob_size, 'gpt3', paradigm)
                    evaluate(exp)
        except Exception as e:
            print(e)
        time.sleep(30)",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)
node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
print(f'Evaluation result written to {eval_result_path}')","if __name__ == '__main__':
    main()","(232, 0)","(244, 22)",N,function_definition,main,,129,2a53fe0a-ccec-426d-9574-58cebd4b0059
"if __name__ == '__main__':
    main()",gpt_eval.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_eval.py,module/,module,"def main():
    while True:
        try:
            for exp_dir in glob('gpt3/*'):
                fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
                eval_result_path = path.join(exp_dir, 'eval_result.yaml')
                if path.isfile(fine_tune_complete_path) and not path.isfile(eval_result_path):
                    prob_name, prob_size, paradigm = path.basename(exp_dir).split('-')
                    exp = Experiment(prob_name, prob_size, 'gpt3', paradigm)
                    evaluate(exp)
        except Exception as e:
            print(e)
        time.sleep(30)",Next sibling does not exist,"(247, 0)","(248, 10)",N,if_statement,if_statement,,11,194dcd8a-0fe3-4e68-b66a-fa224f36ba54
"#!/usr/bin/env python
# coding: utf-8



import json
import os
import os.path as path
import random
import time
from collections import namedtuple
from datetime import datetime
from functools import partial
from multiprocessing import Pool

import openai
import pandas as pd
import torch
import yaml
from tqdm.auto import tqdm
from transformers import GPT2Tokenizer

from data import PROBLEM
from data.problem import build_vocab, ProblemSet, collate_by_len
from eval import Evaluator

openai.api_key = os.getenv('OPENAI_API_KEY')



gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')


def count_tokens(gpt_data):
    count = 0
    for datum in gpt_data:
        count += len(gpt2_tokenizer(datum['prompt'])['input_ids'])
        count += len(gpt2_tokenizer(datum['completion'])['input_ids'])
    return count


def bill(count, training: bool, verbose=False):
    if training:
        prices = {
            'Ada': 0.0004,
            'Babbage': 0.0006,
            'Curie': 0.003,
            'Davinci': 0.03
        }
    else:
        prices = {
            'Ada': 0.0016,
            'Babbage': 0.0024,
            'Curie': 0.012,
            'Davinci': 0.12
        }
    costs = {
        model: count / 1000 * unit_price
        for model, unit_price in prices.items()
    }
    if verbose:
        print(f'{count:,} tokens')
        for model, cost in costs.items():
            print(f'{model}: ${cost:.2f}')
    return costs


def openai_to_dict(obj):
    if isinstance(obj, dict):
        return {
            key: openai_to_dict(value)
            for key, value in obj.items()
        }
    elif isinstance(obj, list):
        return [openai_to_dict(elem) for elem in obj]
    else:
        return obj


def human_format(num):
    num = float('{:.3g}'.format(num))
    magnitude = 0
    while abs(num) >= 1000:
        magnitude += 1
        num /= 1000.0
    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'),
                         ['', 'K', 'M', 'B', 'T'][magnitude])


Experiment = namedtuple('Experiment',
                        ['prob_name', 'prob_size', 'model', 'paradigm'])


def get_exp_name(exp):
    return f'{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'


def get_exp_dir(exp):
    return f'gpt3/{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'


def get_exp_episode(exp):
    episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
    with open(episode_path, 'r') as f:
        episode = yaml.load(f, Loader=yaml.FullLoader)
    return episode


def get_exp_vocab(exp):
    episode = get_exp_episode(exp)
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    return build_vocab(prob_classes, paradigm=exp.paradigm)




class GPTDataGenerator:
    def __init__(self, exp):
        self.episode = get_exp_episode(exp)
        self.paradigm = exp.paradigm

        # Build vocab
        self.vocab = get_exp_vocab(exp)
        self.itos = self.vocab.get_itos()
        self.gpt_itos = [
            self.to_gpt_token(token)
            for token in self.vocab.get_itos()
        ]

        # Build problems
        self.problems = [
            PROBLEM[prob_spec['name']](exp.paradigm, self.vocab,
                                       prob_spec['config'])
            for prob_spec in self.episode
        ]
        print(', '.join([f'{problem}' for problem in self.problems]))
        self.problem_set = ProblemSet(self.problems, paradigm=exp.paradigm,
                                      vocab=self.vocab)

        # Train loader
        self.train_loader = self.problem_set.get_data_loader(
            batch_size=1, num_workers=0,
            collate_fn=collate_by_len)

    def generate(self, num, sample_ratio=1.0):
        train_loader_iter = iter(self.train_loader)
        data = []
        while len(data) < num:
            (x, y, l), = next(train_loader_iter)
            examples = self.xy_to_gpt_data(x, y)
            for example in examples:
                if len(data) >= num:
                    break
                if random.random() < sample_ratio:
                    data.append(example)
        random.shuffle(data)
        return data

    def generate_at(self, num, path, sample_ratio=1.0):
        data = self.generate(num, sample_ratio=sample_ratio)
        pd.DataFrame(data).to_json(path, orient='records', lines=True)

    @staticmethod
    def to_gpt_token(token):
        if token == '':
            token = '/'
        elif token == '':
            token = 'by'
        elif token.startswith('<'):
            token = token[1:-1].lower()
        return ' ' + token
        # return ' ' + token[1:-1].lower() if token.startswith('<') else token

    def decode_tokens(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.itos[token] for token in x]

    def decode_tokens_gpt(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.gpt_itos[token] for token in x]

    def xy_to_gpt_data(self, x, y):
        x_dec = self.decode_tokens_gpt(x)
        y_dec = self.decode_tokens_gpt(y)

        prompts = []
        completions = []
        prompt_end = 0
        for i, (x_t, y_t) in enumerate(zip(x_dec, y_dec)):
            match x_t, y_t:
                case (_, ' think') | (_, ' stop'):
                    completions.append(y_dec[prompt_end:i + 1])
                case (_, ' go') | (_, ' tail') | (' stop', _) | (' =', _):
                    prompts.append(x_dec[:i + 1])
                    prompt_end = i

        prompts = [''.join(prompt) for prompt in prompts]
        completions = [''.join(completion) for completion in completions]
        assert len(prompts) == len(completions)
        data = [
            {
                'prompt': prompt,
                'completion': completion if completion.startswith(
                    ' ') else ' ' + completion
            }
            for prompt, completion in zip(prompts, completions)
        ]
        return data



experiments = [
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='wt'),
]

# Generate Training Data

processes = 32
train_examples = 256 * 10_000
chunk_size = 2560
num_jobs = train_examples // chunk_size
eval_probs = 1000
dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
with Pool(processes=processes) as pool:
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
        os.makedirs(exp_dir, 0o700, exist_ok=True)

        # Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)

        # Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))

            eval_tokens = sum(list(
                tqdm(pool.imap(count_tokens, eval_data), total=len(eval_data))))
            with open(eval_info_path, 'w') as f:
                yaml.dump({
                    'tokens': eval_tokens,
                    'prices': bill(eval_tokens, training=False)
                }, f)


def upload_training_data(exp):
    exp_dir = get_exp_dir(exp)
    exp_name = get_exp_name(exp)
    train_data_path = path.join(exp_dir, 'train.jsonl')
    train_info_path = path.join(exp_dir, 'train_info.yaml')
    train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
    if path.isfile(train_data_path) and path.isfile(
            train_info_path) and not path.isfile(train_uploaded_path):
        print(f'Uploading {train_data_path}')
        with open(train_data_path, 'r') as f:
            uploaded_file = openai.File.create(
                file=open(train_data_path),
                purpose='fine-tune',
                user_provided_filename=exp_name
            )
        print(f'Uploaded as {uploaded_file[""id""]}')
        with open(train_uploaded_path, 'w') as f:
            yaml.dump(openai_to_dict(uploaded_file), f)


def delete_completed_training_data():
    for fine_tune in openai.FineTune.list()['data']:
        for training_file in fine_tune['training_files']:
            if fine_tune['status'] == 'succeeded' and training_file[
                'status'] != 'deleted':
                result = openai.File.delete(training_file['id'])
                if result['deleted']:
                    print(
                        f'Training file of {training_file[""filename""]} deleted')


def request_fine_tuning(exp):
    exp_dir = get_exp_dir(exp)
    exp_name = get_exp_name(exp)
    train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
    fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
    if path.isfile(train_uploaded_path) and not path.isfile(fine_tune_path):
        print(f'Request fine-tuning of {exp_name}')
        with open(train_uploaded_path, 'r') as f:
            training_file_id = yaml.load(f, Loader=yaml.FullLoader)['id']
        fine_tune = openai.FineTune.create(
            training_file=training_file_id,
            model='ada',
            n_epochs=1,
            batch_size=256,
            prompt_loss_weight=0,
            suffix=exp_name
        )
        with open(fine_tune_path, 'w') as f:
            yaml.dump(openai_to_dict(fine_tune), f)


def check_fine_tune(exp):
    exp_dir = get_exp_dir(exp)
    fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
    if not path.isfile(fine_tune_path):
        print('No fine-tuning record found. Request fine-tuning first.')
        return

    with open(fine_tune_path, 'r') as f:
        fine_tune_id = yaml.load(f, Loader=yaml.FullLoader)['id']
    fine_tune = openai.FineTune.retrieve(id=fine_tune_id)
    if fine_tune['status'] == 'succeeded':
        print(f'Fine-tune completed: {fine_tune[""id""]}')
        with open(path.join(exp_dir, 'fine_tune_complete.yaml'), 'w') as f:
            yaml.dump(openai_to_dict(fine_tune), f)
    return fine_tune


def save_inference(args, model_id):
    example, save_path = args
    if path.isfile(save_path):
        return
    max_tokens = len(gpt2_tokenizer(example['completion'])['input_ids']) + 1
    for retry in range(10):
        try:
            result = openai.Completion.create(
                model=model_id,
                prompt=example['prompt'],
                max_tokens=max_tokens,
                temperature=0
            )
            with open(save_path, 'w') as f:
                json.dump(result, f, indent=2)
            break
        except openai.error.RateLimitError:
            time.sleep(5)
    else:
        print('Maximum retry exceed. Failed to evaluate an example.')


def evaluate(exp):
    processes = 32
    exp_dir = get_exp_dir(exp)
    infer_dir = path.join(exp_dir, 'inferences')
    eval_result_path = path.join(exp_dir, 'eval_result.yaml')
    if path.isfile(eval_result_path):
        # Already done
        return

    evaluator_path = path.join(exp_dir, 'evaluator.pt')
    fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
    if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return

    dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
    generator = GPTDataGenerator(exp)
    evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
    evaluator.load_state_dict(torch.load(evaluator_path))
    with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
    model_id = fine_tune_complete['fine_tuned_model']

    os.makedirs(infer_dir, mode=0o700, exist_ok=True)

    eval_data = []
    infer_args = []
    skip_count = 0
    for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))

    print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
    print(f'Model ID: {model_id}')
    with Pool(16) as pool:
        list(tqdm(
            pool.imap(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))

    # Aggregate results
    corrects = []
    wrongs = []
    for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)

    node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
    correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
    with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
    print(f'Evaluation result written to {eval_result_path}')


def progress():
    fine_tune_queue = []
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        exp_name = get_exp_name(exp)

        train_info_path = path.join(exp_dir, 'train_info.yaml')
        train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
        fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
        fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')

        if path.isfile(train_info_path) and not path.isfile(
                train_uploaded_path) and len(fine_tune_queue) < 2:
            print(datetime.now())
            delete_completed_training_data()
            upload_training_data(exp)
        if path.isfile(train_uploaded_path) and not path.isfile(fine_tune_path):
            print(datetime.now())
            request_fine_tuning(exp)
        if path.isfile(fine_tune_path) and not path.isfile(
                fine_tune_complete_path):
            fine_tune = check_fine_tune(exp)
            if fine_tune['status'] == 'succeeded':
                print(datetime.now())
                print(f'{exp_name} fine-tuning completed')
            else:
                fine_tune_queue.append(exp)


def main():
    while True:
        try:
            progress()
        except Exception as e:
            print(e)
        time.sleep(60)


if __name__ == '__main__':
    main()
",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,,NA,Previous sibling does not exist,"#!/usr/bin/env python
# coding: utf-8
import json
import os
import os.path as path
import random
import time
from collections import namedtuple
from datetime import datetime
from functools import partial
from multiprocessing import Pool
import openai
import pandas as pd
import torch
import yaml
from tqdm.auto import tqdm
from transformers import GPT2Tokenizer
from data import PROBLEM
from data.problem import build_vocab, ProblemSet, collate_by_len
from eval import Evaluator
openai.api_key = os.getenv('OPENAI_API_KEY')
gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')","(0, 0)","(537, 0)",N,module,module,,4721,19abec0d-54df-4115-95df-9eff667a2144
"#!/usr/bin/env python
# coding: utf-8
import json
import os
import os.path as path
import random
import time
from collections import namedtuple
from datetime import datetime
from functools import partial
from multiprocessing import Pool
import openai
import pandas as pd
import torch
import yaml
from tqdm.auto import tqdm
from transformers import GPT2Tokenizer
from data import PROBLEM
from data.problem import build_vocab, ProblemSet, collate_by_len
from eval import Evaluator
openai.api_key = os.getenv('OPENAI_API_KEY')
gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,Previous sibling does not exist,"def count_tokens(gpt_data):
    count = 0
    for datum in gpt_data:
        count += len(gpt2_tokenizer(datum['prompt'])['input_ids'])
        count += len(gpt2_tokenizer(datum['completion'])['input_ids'])
    return count","(0, 0)","(30, 54)",N,"comment,comment,import_statement,import_statement,import_statement,import_statement,import_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_statement,import_statement,import_statement,import_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,expression_statement,expression_statement",comment,,118,d8856189-c66f-4b6b-9749-d108d8de0cc2
"def count_tokens(gpt_data):
    count = 0
    for datum in gpt_data:
        count += len(gpt2_tokenizer(datum['prompt'])['input_ids'])
        count += len(gpt2_tokenizer(datum['completion'])['input_ids'])
    return count",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"#!/usr/bin/env python
# coding: utf-8
import json
import os
import os.path as path
import random
import time
from collections import namedtuple
from datetime import datetime
from functools import partial
from multiprocessing import Pool
import openai
import pandas as pd
import torch
import yaml
from tqdm.auto import tqdm
from transformers import GPT2Tokenizer
from data import PROBLEM
from data.problem import build_vocab, ProblemSet, collate_by_len
from eval import Evaluator
openai.api_key = os.getenv('OPENAI_API_KEY')
gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')","def bill(count, training: bool, verbose=False):
    if training:
        prices = {
            'Ada': 0.0004,
            'Babbage': 0.0006,
            'Curie': 0.003,
            'Davinci': 0.03
        }
    else:
        prices = {
            'Ada': 0.0016,
            'Babbage': 0.0024,
            'Curie': 0.012,
            'Davinci': 0.12
        }
    costs = {
        model: count / 1000 * unit_price
        for model, unit_price in prices.items()
    }
    if verbose:
        print(f'{count:,} tokens')
        for model, cost in costs.items():
            print(f'{model}: ${cost:.2f}')
    return costs","(33, 0)","(38, 16)",N,function_definition,count_tokens,,60,f34c63a8-4957-43b6-b0fb-7f7664125d1a
"def bill(count, training: bool, verbose=False):
    if training:
        prices = {
            'Ada': 0.0004,
            'Babbage': 0.0006,
            'Curie': 0.003,
            'Davinci': 0.03
        }
    else:
        prices = {
            'Ada': 0.0016,
            'Babbage': 0.0024,
            'Curie': 0.012,
            'Davinci': 0.12
        }
    costs = {
        model: count / 1000 * unit_price
        for model, unit_price in prices.items()
    }
    if verbose:
        print(f'{count:,} tokens')
        for model, cost in costs.items():
            print(f'{model}: ${cost:.2f}')
    return costs",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def count_tokens(gpt_data):
    count = 0
    for datum in gpt_data:
        count += len(gpt2_tokenizer(datum['prompt'])['input_ids'])
        count += len(gpt2_tokenizer(datum['completion'])['input_ids'])
    return count","def openai_to_dict(obj):
    if isinstance(obj, dict):
        return {
            key: openai_to_dict(value)
            for key, value in obj.items()
        }
    elif isinstance(obj, list):
        return [openai_to_dict(elem) for elem in obj]
    else:
        return obj","(41, 0)","(64, 16)",N,function_definition,bill,,179,49dc2164-df56-4c90-86e8-48aae9fc3541
"def openai_to_dict(obj):
    if isinstance(obj, dict):
        return {
            key: openai_to_dict(value)
            for key, value in obj.items()
        }
    elif isinstance(obj, list):
        return [openai_to_dict(elem) for elem in obj]
    else:
        return obj",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def bill(count, training: bool, verbose=False):
    if training:
        prices = {
            'Ada': 0.0004,
            'Babbage': 0.0006,
            'Curie': 0.003,
            'Davinci': 0.03
        }
    else:
        prices = {
            'Ada': 0.0016,
            'Babbage': 0.0024,
            'Curie': 0.012,
            'Davinci': 0.12
        }
    costs = {
        model: count / 1000 * unit_price
        for model, unit_price in prices.items()
    }
    if verbose:
        print(f'{count:,} tokens')
        for model, cost in costs.items():
            print(f'{model}: ${cost:.2f}')
    return costs","def human_format(num):
    num = float('{:.3g}'.format(num))
    magnitude = 0
    while abs(num) >= 1000:
        magnitude += 1
        num /= 1000.0
    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'),
                         ['', 'K', 'M', 'B', 'T'][magnitude])","(67, 0)","(76, 18)",N,function_definition,openai_to_dict,,64,08b9e5ed-9292-4852-9366-530320fe85f0
"def human_format(num):
    num = float('{:.3g}'.format(num))
    magnitude = 0
    while abs(num) >= 1000:
        magnitude += 1
        num /= 1000.0
    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'),
                         ['', 'K', 'M', 'B', 'T'][magnitude])",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def openai_to_dict(obj):
    if isinstance(obj, dict):
        return {
            key: openai_to_dict(value)
            for key, value in obj.items()
        }
    elif isinstance(obj, list):
        return [openai_to_dict(elem) for elem in obj]
    else:
        return obj","Experiment = namedtuple('Experiment',
                        ['prob_name', 'prob_size', 'model', 'paradigm'])","(79, 0)","(86, 61)",N,function_definition,human_format,,83,62598dde-9948-491b-8ef8-8ed03eda0b3d
"Experiment = namedtuple('Experiment',
                        ['prob_name', 'prob_size', 'model', 'paradigm'])",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def human_format(num):
    num = float('{:.3g}'.format(num))
    magnitude = 0
    while abs(num) >= 1000:
        magnitude += 1
        num /= 1000.0
    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'),
                         ['', 'K', 'M', 'B', 'T'][magnitude])","def get_exp_name(exp):
    return f'{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'","(89, 0)","(90, 72)",N,expression_statement,expression_statement,,23,5d04a473-49f4-4382-b586-6f64a921385c
"def get_exp_name(exp):
    return f'{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"Experiment = namedtuple('Experiment',
                        ['prob_name', 'prob_size', 'model', 'paradigm'])","def get_exp_dir(exp):
    return f'gpt3/{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'","(93, 0)","(94, 60)",N,function_definition,get_exp_name,,23,c7d497d2-f869-44ba-bcab-dc64452628ec
"def get_exp_dir(exp):
    return f'gpt3/{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def get_exp_name(exp):
    return f'{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'","def get_exp_episode(exp):
    episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
    with open(episode_path, 'r') as f:
        episode = yaml.load(f, Loader=yaml.FullLoader)
    return episode","(97, 0)","(98, 65)",N,function_definition,get_exp_dir,,27,ba3a1cb3-26df-4ef2-ac97-950164cbe91d
"def get_exp_episode(exp):
    episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
    with open(episode_path, 'r') as f:
        episode = yaml.load(f, Loader=yaml.FullLoader)
    return episode",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def get_exp_dir(exp):
    return f'gpt3/{exp.prob_name}-{exp.prob_size}-{exp.paradigm}'","def get_exp_vocab(exp):
    episode = get_exp_episode(exp)
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    return build_vocab(prob_classes, paradigm=exp.paradigm)","(101, 0)","(105, 18)",N,function_definition,get_exp_episode,,54,bfdbf8c2-8c41-4838-a8a7-3b0512b1adcd
"def get_exp_vocab(exp):
    episode = get_exp_episode(exp)
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    return build_vocab(prob_classes, paradigm=exp.paradigm)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def get_exp_episode(exp):
    episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
    with open(episode_path, 'r') as f:
        episode = yaml.load(f, Loader=yaml.FullLoader)
    return episode","class GPTDataGenerator:
    def __init__(self, exp):
        self.episode = get_exp_episode(exp)
        self.paradigm = exp.paradigm

        # Build vocab
        self.vocab = get_exp_vocab(exp)
        self.itos = self.vocab.get_itos()
        self.gpt_itos = [
            self.to_gpt_token(token)
            for token in self.vocab.get_itos()
        ]

        # Build problems
        self.problems = [
            PROBLEM[prob_spec['name']](exp.paradigm, self.vocab,
                                       prob_spec['config'])
            for prob_spec in self.episode
        ]
        print(', '.join([f'{problem}' for problem in self.problems]))
        self.problem_set = ProblemSet(self.problems, paradigm=exp.paradigm,
                                      vocab=self.vocab)

        # Train loader
        self.train_loader = self.problem_set.get_data_loader(
            batch_size=1, num_workers=0,
            collate_fn=collate_by_len)

    def generate(self, num, sample_ratio=1.0):
        train_loader_iter = iter(self.train_loader)
        data = []
        while len(data) < num:
            (x, y, l), = next(train_loader_iter)
            examples = self.xy_to_gpt_data(x, y)
            for example in examples:
                if len(data) >= num:
                    break
                if random.random() < sample_ratio:
                    data.append(example)
        random.shuffle(data)
        return data

    def generate_at(self, num, path, sample_ratio=1.0):
        data = self.generate(num, sample_ratio=sample_ratio)
        pd.DataFrame(data).to_json(path, orient='records', lines=True)

    @staticmethod
    def to_gpt_token(token):
        if token == '':
            token = '/'
        elif token == '':
            token = 'by'
        elif token.startswith('<'):
            token = token[1:-1].lower()
        return ' ' + token
        # return ' ' + token[1:-1].lower() if token.startswith('<') else token

    def decode_tokens(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.itos[token] for token in x]

    def decode_tokens_gpt(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.gpt_itos[token] for token in x]

    def xy_to_gpt_data(self, x, y):
        x_dec = self.decode_tokens_gpt(x)
        y_dec = self.decode_tokens_gpt(y)

        prompts = []
        completions = []
        prompt_end = 0
        for i, (x_t, y_t) in enumerate(zip(x_dec, y_dec)):
            match x_t, y_t:
                case (_, ' think') | (_, ' stop'):
                    completions.append(y_dec[prompt_end:i + 1])
                case (_, ' go') | (_, ' tail') | (' stop', _) | (' =', _):
                    prompts.append(x_dec[:i + 1])
                    prompt_end = i

        prompts = [''.join(prompt) for prompt in prompts]
        completions = [''.join(completion) for completion in completions]
        assert len(prompts) == len(completions)
        data = [
            {
                'prompt': prompt,
                'completion': completion if completion.startswith(
                    ' ') else ' ' + completion
            }
            for prompt, completion in zip(prompts, completions)
        ]
        return data","(108, 0)","(111, 59)",N,function_definition,get_exp_vocab,,47,ff8eb07e-f479-4a56-9af3-185c67e41c33
"class GPTDataGenerator:
    def __init__(self, exp):
        self.episode = get_exp_episode(exp)
        self.paradigm = exp.paradigm

        # Build vocab
        self.vocab = get_exp_vocab(exp)
        self.itos = self.vocab.get_itos()
        self.gpt_itos = [
            self.to_gpt_token(token)
            for token in self.vocab.get_itos()
        ]

        # Build problems
        self.problems = [
            PROBLEM[prob_spec['name']](exp.paradigm, self.vocab,
                                       prob_spec['config'])
            for prob_spec in self.episode
        ]
        print(', '.join([f'{problem}' for problem in self.problems]))
        self.problem_set = ProblemSet(self.problems, paradigm=exp.paradigm,
                                      vocab=self.vocab)

        # Train loader
        self.train_loader = self.problem_set.get_data_loader(
            batch_size=1, num_workers=0,
            collate_fn=collate_by_len)

    def generate(self, num, sample_ratio=1.0):
        train_loader_iter = iter(self.train_loader)
        data = []
        while len(data) < num:
            (x, y, l), = next(train_loader_iter)
            examples = self.xy_to_gpt_data(x, y)
            for example in examples:
                if len(data) >= num:
                    break
                if random.random() < sample_ratio:
                    data.append(example)
        random.shuffle(data)
        return data

    def generate_at(self, num, path, sample_ratio=1.0):
        data = self.generate(num, sample_ratio=sample_ratio)
        pd.DataFrame(data).to_json(path, orient='records', lines=True)

    @staticmethod
    def to_gpt_token(token):
        if token == '':
            token = '/'
        elif token == '':
            token = 'by'
        elif token.startswith('<'):
            token = token[1:-1].lower()
        return ' ' + token
        # return ' ' + token[1:-1].lower() if token.startswith('<') else token

    def decode_tokens(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.itos[token] for token in x]

    def decode_tokens_gpt(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.gpt_itos[token] for token in x]

    def xy_to_gpt_data(self, x, y):
        x_dec = self.decode_tokens_gpt(x)
        y_dec = self.decode_tokens_gpt(y)

        prompts = []
        completions = []
        prompt_end = 0
        for i, (x_t, y_t) in enumerate(zip(x_dec, y_dec)):
            match x_t, y_t:
                case (_, ' think') | (_, ' stop'):
                    completions.append(y_dec[prompt_end:i + 1])
                case (_, ' go') | (_, ' tail') | (' stop', _) | (' =', _):
                    prompts.append(x_dec[:i + 1])
                    prompt_end = i

        prompts = [''.join(prompt) for prompt in prompts]
        completions = [''.join(completion) for completion in completions]
        assert len(prompts) == len(completions)
        data = [
            {
                'prompt': prompt,
                'completion': completion if completion.startswith(
                    ' ') else ' ' + completion
            }
            for prompt, completion in zip(prompts, completions)
        ]
        return data",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def get_exp_vocab(exp):
    episode = get_exp_episode(exp)
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    return build_vocab(prob_classes, paradigm=exp.paradigm)","experiments = [
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='wt'),
]","(116, 0)","(209, 19)",N,class_definition,GPTDataGenerator,,756,ace0ac10-04bd-469b-88bc-77c90cf09450
"def __init__(self, exp):
        self.episode = get_exp_episode(exp)
        self.paradigm = exp.paradigm

        # Build vocab
        self.vocab = get_exp_vocab(exp)
        self.itos = self.vocab.get_itos()
        self.gpt_itos = [
            self.to_gpt_token(token)
            for token in self.vocab.get_itos()
        ]

        # Build problems
        self.problems = [
            PROBLEM[prob_spec['name']](exp.paradigm, self.vocab,
                                       prob_spec['config'])
            for prob_spec in self.episode
        ]
        print(', '.join([f'{problem}' for problem in self.problems]))
        self.problem_set = ProblemSet(self.problems, paradigm=exp.paradigm,
                                      vocab=self.vocab)

        # Train loader
        self.train_loader = self.problem_set.get_data_loader(
            batch_size=1, num_workers=0,
            collate_fn=collate_by_len)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/class_definition-GPTDataGenerator/,GPTDataGenerator,Previous sibling does not exist,"def generate(self, num, sample_ratio=1.0):
        train_loader_iter = iter(self.train_loader)
        data = []
        while len(data) < num:
            (x, y, l), = next(train_loader_iter)
            examples = self.xy_to_gpt_data(x, y)
            for example in examples:
                if len(data) >= num:
                    break
                if random.random() < sample_ratio:
                    data.append(example)
        random.shuffle(data)
        return data","(117, 4)","(142, 38)",N,function_definition,__init__,,206,2b7e7c07-9c84-43bb-a3a0-905f2b3a32d7
"def generate(self, num, sample_ratio=1.0):
        train_loader_iter = iter(self.train_loader)
        data = []
        while len(data) < num:
            (x, y, l), = next(train_loader_iter)
            examples = self.xy_to_gpt_data(x, y)
            for example in examples:
                if len(data) >= num:
                    break
                if random.random() < sample_ratio:
                    data.append(example)
        random.shuffle(data)
        return data",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/class_definition-GPTDataGenerator/,GPTDataGenerator,"def __init__(self, exp):
        self.episode = get_exp_episode(exp)
        self.paradigm = exp.paradigm

        # Build vocab
        self.vocab = get_exp_vocab(exp)
        self.itos = self.vocab.get_itos()
        self.gpt_itos = [
            self.to_gpt_token(token)
            for token in self.vocab.get_itos()
        ]

        # Build problems
        self.problems = [
            PROBLEM[prob_spec['name']](exp.paradigm, self.vocab,
                                       prob_spec['config'])
            for prob_spec in self.episode
        ]
        print(', '.join([f'{problem}' for problem in self.problems]))
        self.problem_set = ProblemSet(self.problems, paradigm=exp.paradigm,
                                      vocab=self.vocab)

        # Train loader
        self.train_loader = self.problem_set.get_data_loader(
            batch_size=1, num_workers=0,
            collate_fn=collate_by_len)","def generate_at(self, num, path, sample_ratio=1.0):
        data = self.generate(num, sample_ratio=sample_ratio)
        pd.DataFrame(data).to_json(path, orient='records', lines=True)","(144, 4)","(156, 19)",N,function_definition,generate,,101,9302ff1a-4ee6-4a70-8170-d734d7337a72
"def generate_at(self, num, path, sample_ratio=1.0):
        data = self.generate(num, sample_ratio=sample_ratio)
        pd.DataFrame(data).to_json(path, orient='records', lines=True)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/class_definition-GPTDataGenerator/,GPTDataGenerator,"def generate(self, num, sample_ratio=1.0):
        train_loader_iter = iter(self.train_loader)
        data = []
        while len(data) < num:
            (x, y, l), = next(train_loader_iter)
            examples = self.xy_to_gpt_data(x, y)
            for example in examples:
                if len(data) >= num:
                    break
                if random.random() < sample_ratio:
                    data.append(example)
        random.shuffle(data)
        return data","@staticmethod
    def to_gpt_token(token):
        if token == '':
            token = '/'
        elif token == '':
            token = 'by'
        elif token.startswith('<'):
            token = token[1:-1].lower()
        return ' ' + token
        # return ' ' + token[1:-1].lower() if token.startswith('<') else token","(158, 4)","(160, 70)",N,function_definition,generate_at,,45,902af1b8-516d-44a6-a108-4035b9c1f95c
"@staticmethod
    def to_gpt_token(token):
        if token == '':
            token = '/'
        elif token == '':
            token = 'by'
        elif token.startswith('<'):
            token = token[1:-1].lower()
        return ' ' + token
        # return ' ' + token[1:-1].lower() if token.startswith('<') else token",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/class_definition-GPTDataGenerator/,GPTDataGenerator,"def generate_at(self, num, path, sample_ratio=1.0):
        data = self.generate(num, sample_ratio=sample_ratio)
        pd.DataFrame(data).to_json(path, orient='records', lines=True)","def decode_tokens(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.itos[token] for token in x]","(162, 4)","(171, 78)",N,function_definition,"def to_gpt_token(token):
        if token == '':
            token = '/'
        elif token == '':
            token = 'by'
        elif token.startswith('<'):
            token = token[1:-1].lower()
        return ' ' + token
        # return ' ' + token[1:-1].lower() if token.startswith('<') else token",,81,20f2a0dd-3faf-4ce0-8bb2-114a47fd715d
"def decode_tokens(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.itos[token] for token in x]",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/class_definition-GPTDataGenerator/,GPTDataGenerator,"@staticmethod
    def to_gpt_token(token):
        if token == '':
            token = '/'
        elif token == '':
            token = 'by'
        elif token.startswith('<'):
            token = token[1:-1].lower()
        return ' ' + token
        # return ' ' + token[1:-1].lower() if token.startswith('<') else token","def decode_tokens_gpt(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.gpt_itos[token] for token in x]","(173, 4)","(176, 48)",N,function_definition,decode_tokens,,36,a8e45dac-f890-4ce5-bbc8-196e2d05e227
"def decode_tokens_gpt(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.gpt_itos[token] for token in x]",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/class_definition-GPTDataGenerator/,GPTDataGenerator,"def decode_tokens(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.itos[token] for token in x]","def xy_to_gpt_data(self, x, y):
        x_dec = self.decode_tokens_gpt(x)
        y_dec = self.decode_tokens_gpt(y)

        prompts = []
        completions = []
        prompt_end = 0
        for i, (x_t, y_t) in enumerate(zip(x_dec, y_dec)):
            match x_t, y_t:
                case (_, ' think') | (_, ' stop'):
                    completions.append(y_dec[prompt_end:i + 1])
                case (_, ' go') | (_, ' tail') | (' stop', _) | (' =', _):
                    prompts.append(x_dec[:i + 1])
                    prompt_end = i

        prompts = [''.join(prompt) for prompt in prompts]
        completions = [''.join(completion) for completion in completions]
        assert len(prompts) == len(completions)
        data = [
            {
                'prompt': prompt,
                'completion': completion if completion.startswith(
                    ' ') else ' ' + completion
            }
            for prompt, completion in zip(prompts, completions)
        ]
        return data","(178, 4)","(181, 52)",N,function_definition,decode_tokens_gpt,,40,0d495e90-0e71-4768-b752-dd08aab7884b
"def xy_to_gpt_data(self, x, y):
        x_dec = self.decode_tokens_gpt(x)
        y_dec = self.decode_tokens_gpt(y)

        prompts = []
        completions = []
        prompt_end = 0
        for i, (x_t, y_t) in enumerate(zip(x_dec, y_dec)):
            match x_t, y_t:
                case (_, ' think') | (_, ' stop'):
                    completions.append(y_dec[prompt_end:i + 1])
                case (_, ' go') | (_, ' tail') | (' stop', _) | (' =', _):
                    prompts.append(x_dec[:i + 1])
                    prompt_end = i

        prompts = [''.join(prompt) for prompt in prompts]
        completions = [''.join(completion) for completion in completions]
        assert len(prompts) == len(completions)
        data = [
            {
                'prompt': prompt,
                'completion': completion if completion.startswith(
                    ' ') else ' ' + completion
            }
            for prompt, completion in zip(prompts, completions)
        ]
        return data",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/class_definition-GPTDataGenerator/,GPTDataGenerator,"def decode_tokens_gpt(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.gpt_itos[token] for token in x]",Next sibling does not exist,"(183, 4)","(209, 19)",N,function_definition,xy_to_gpt_data,,232,5b5e1aa6-2a1e-4f34-863f-4191c984f7fa
"experiments = [
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='rot'),",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"class GPTDataGenerator:
    def __init__(self, exp):
        self.episode = get_exp_episode(exp)
        self.paradigm = exp.paradigm

        # Build vocab
        self.vocab = get_exp_vocab(exp)
        self.itos = self.vocab.get_itos()
        self.gpt_itos = [
            self.to_gpt_token(token)
            for token in self.vocab.get_itos()
        ]

        # Build problems
        self.problems = [
            PROBLEM[prob_spec['name']](exp.paradigm, self.vocab,
                                       prob_spec['config'])
            for prob_spec in self.episode
        ]
        print(', '.join([f'{problem}' for problem in self.problems]))
        self.problem_set = ProblemSet(self.problems, paradigm=exp.paradigm,
                                      vocab=self.vocab)

        # Train loader
        self.train_loader = self.problem_set.get_data_loader(
            batch_size=1, num_workers=0,
            collate_fn=collate_by_len)

    def generate(self, num, sample_ratio=1.0):
        train_loader_iter = iter(self.train_loader)
        data = []
        while len(data) < num:
            (x, y, l), = next(train_loader_iter)
            examples = self.xy_to_gpt_data(x, y)
            for example in examples:
                if len(data) >= num:
                    break
                if random.random() < sample_ratio:
                    data.append(example)
        random.shuffle(data)
        return data

    def generate_at(self, num, path, sample_ratio=1.0):
        data = self.generate(num, sample_ratio=sample_ratio)
        pd.DataFrame(data).to_json(path, orient='records', lines=True)

    @staticmethod
    def to_gpt_token(token):
        if token == '':
            token = '/'
        elif token == '':
            token = 'by'
        elif token.startswith('<'):
            token = token[1:-1].lower()
        return ' ' + token
        # return ' ' + token[1:-1].lower() if token.startswith('<') else token

    def decode_tokens(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.itos[token] for token in x]

    def decode_tokens_gpt(self, x):
        if isinstance(x, torch.Tensor):
            x = x.view(-1)
        return [self.gpt_itos[token] for token in x]

    def xy_to_gpt_data(self, x, y):
        x_dec = self.decode_tokens_gpt(x)
        y_dec = self.decode_tokens_gpt(y)

        prompts = []
        completions = []
        prompt_end = 0
        for i, (x_t, y_t) in enumerate(zip(x_dec, y_dec)):
            match x_t, y_t:
                case (_, ' think') | (_, ' stop'):
                    completions.append(y_dec[prompt_end:i + 1])
                case (_, ' go') | (_, ' tail') | (' stop', _) | (' =', _):
                    prompts.append(x_dec[:i + 1])
                    prompt_end = i

        prompts = [''.join(prompt) for prompt in prompts]
        completions = [''.join(completion) for completion in completions]
        assert len(prompts) == len(completions)
        data = [
            {
                'prompt': prompt,
                'completion': completion if completion.startswith(
                    ' ') else ' ' + completion
            }
            for prompt, completion in zip(prompts, completions)
        ]
        return data","Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='rot'),","(213, 0)","(250, 1)",N,expression_statement,expression_statement,"experiments = [
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='wt'),
]",1177,1f3b981b-040f-4d94-8f39-aff4927bf638
"Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='rot'),",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"experiments = [
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='rot'),","Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='wt'),
]
# Generate Training Data
processes = 32
train_examples = 256 * 10_000
chunk_size = 2560
num_jobs = train_examples // chunk_size
eval_probs = 1000
dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}","(213, 0)","(250, 1)",N,expression_statement,expression_statement,"experiments = [
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='wt'),
]",1214,01778379-4eca-420b-8784-5bcaf782397a
"Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='wt'),
]
# Generate Training Data
processes = 32
train_examples = 256 * 10_000
chunk_size = 2560
num_jobs = train_examples // chunk_size
eval_probs = 1000
dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='rot'),","with Pool(processes=processes) as pool:
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
        os.makedirs(exp_dir, 0o700, exist_ok=True)

        # Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)

        # Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))

            eval_tokens = sum(list(
                tqdm(pool.imap(count_tokens, eval_data), total=len(eval_data))))
            with open(eval_info_path, 'w') as f:
                yaml.dump({
                    'tokens': eval_tokens,
                    'prices': bill(eval_tokens, training=False)
                }, f)","(213, 0)","(259, 69)",N,"expression_statement,comment,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,"experiments = [
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Add', prob_size=48, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Div', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Knapsack', prob_size=6, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=20, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LCS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=24, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='rot'),
    Experiment(prob_name='LPS', prob_size=40, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=3, model='gpt3', paradigm='wt'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='rot'),
    Experiment(prob_name='MCM', prob_size=4, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=16, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='wt'),
]",435,12172e8c-df0a-47b2-970c-fb43185c9558
"with Pool(processes=processes) as pool:
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
        os.makedirs(exp_dir, 0o700, exist_ok=True)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"Experiment(prob_name='Mul', prob_size=8, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=32, model='gpt3', paradigm='wt'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='rot'),
    Experiment(prob_name='Sub', prob_size=48, model='gpt3', paradigm='wt'),
]
# Generate Training Data
processes = 32
train_examples = 256 * 10_000
chunk_size = 2560
num_jobs = train_examples // chunk_size
eval_probs = 1000
dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}","# Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)","(260, 0)","(318, 21)",N,with_statement,with_statement,"with Pool(processes=processes) as pool:
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
        os.makedirs(exp_dir, 0o700, exist_ok=True)

        # Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)

        # Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))

            eval_tokens = sum(list(
                tqdm(pool.imap(count_tokens, eval_data), total=len(eval_data))))
            with open(eval_info_path, 'w') as f:
                yaml.dump({
                    'tokens': eval_tokens,
                    'prices': bill(eval_tokens, training=False)
                }, f)",225,df5779ac-64c8-4844-8e54-27d4351d8223
"# Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"with Pool(processes=processes) as pool:
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
        os.makedirs(exp_dir, 0o700, exist_ok=True)","# Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))","(260, 0)","(318, 21)",N,with_statement,with_statement,"with Pool(processes=processes) as pool:
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
        os.makedirs(exp_dir, 0o700, exist_ok=True)

        # Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)

        # Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))

            eval_tokens = sum(list(
                tqdm(pool.imap(count_tokens, eval_data), total=len(eval_data))))
            with open(eval_info_path, 'w') as f:
                yaml.dump({
                    'tokens': eval_tokens,
                    'prices': bill(eval_tokens, training=False)
                }, f)",1143,23a4d345-eb36-4d8a-8aca-31eeb35e85cb
"# Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"# Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)","eval_tokens = sum(list(
                tqdm(pool.imap(count_tokens, eval_data), total=len(eval_data))))
            with open(eval_info_path, 'w') as f:
                yaml.dump({
                    'tokens': eval_tokens,
                    'prices': bill(eval_tokens, training=False)
                }, f)","(260, 0)","(318, 21)",N,with_statement,with_statement,"with Pool(processes=processes) as pool:
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
        os.makedirs(exp_dir, 0o700, exist_ok=True)

        # Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)

        # Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))

            eval_tokens = sum(list(
                tqdm(pool.imap(count_tokens, eval_data), total=len(eval_data))))
            with open(eval_info_path, 'w') as f:
                yaml.dump({
                    'tokens': eval_tokens,
                    'prices': bill(eval_tokens, training=False)
                }, f)",1056,de10d80d-9af9-4f56-9789-8d9f8a443cba
"eval_tokens = sum(list(
                tqdm(pool.imap(count_tokens, eval_data), total=len(eval_data))))
            with open(eval_info_path, 'w') as f:
                yaml.dump({
                    'tokens': eval_tokens,
                    'prices': bill(eval_tokens, training=False)
                }, f)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"# Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))","def upload_training_data(exp):
    exp_dir = get_exp_dir(exp)
    exp_name = get_exp_name(exp)
    train_data_path = path.join(exp_dir, 'train.jsonl')
    train_info_path = path.join(exp_dir, 'train_info.yaml')
    train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
    if path.isfile(train_data_path) and path.isfile(
            train_info_path) and not path.isfile(train_uploaded_path):
        print(f'Uploading {train_data_path}')
        with open(train_data_path, 'r') as f:
            uploaded_file = openai.File.create(
                file=open(train_data_path),
                purpose='fine-tune',
                user_provided_filename=exp_name
            )
        print(f'Uploaded as {uploaded_file[""id""]}')
        with open(train_uploaded_path, 'w') as f:
            yaml.dump(openai_to_dict(uploaded_file), f)","(260, 0)","(318, 21)",N,with_statement,with_statement,"with Pool(processes=processes) as pool:
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
        os.makedirs(exp_dir, 0o700, exist_ok=True)

        # Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)

        # Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))

            eval_tokens = sum(list(
                tqdm(pool.imap(count_tokens, eval_data), total=len(eval_data))))
            with open(eval_info_path, 'w') as f:
                yaml.dump({
                    'tokens': eval_tokens,
                    'prices': bill(eval_tokens, training=False)
                }, f)",310,a62ea833-4ff9-47d9-98e3-92cc822b5aa6
"def upload_training_data(exp):
    exp_dir = get_exp_dir(exp)
    exp_name = get_exp_name(exp)
    train_data_path = path.join(exp_dir, 'train.jsonl')
    train_info_path = path.join(exp_dir, 'train_info.yaml')
    train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
    if path.isfile(train_data_path) and path.isfile(
            train_info_path) and not path.isfile(train_uploaded_path):
        print(f'Uploading {train_data_path}')
        with open(train_data_path, 'r') as f:
            uploaded_file = openai.File.create(
                file=open(train_data_path),
                purpose='fine-tune',
                user_provided_filename=exp_name
            )
        print(f'Uploaded as {uploaded_file[""id""]}')
        with open(train_uploaded_path, 'w') as f:
            yaml.dump(openai_to_dict(uploaded_file), f)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"with Pool(processes=processes) as pool:
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        episode_path = f'episodes/{exp.prob_name}-{exp.prob_size}.yaml'
        os.makedirs(exp_dir, 0o700, exist_ok=True)

        # Create training data
        train_data_path = path.join(exp_dir, 'train.jsonl')
        train_info_path = path.join(exp_dir, 'train_info.yaml')
        generator = GPTDataGenerator(exp)
        if not path.isfile(train_info_path):
            print(f'Creating {train_data_path}')
            gen_result = list(tqdm(pool.imap(
                partial(generator.generate, sample_ratio=0.3),
                [chunk_size] * num_jobs
            ), total=num_jobs))
            print('Computing training cost...')
            train_tokens = sum(list(tqdm(pool.imap(count_tokens, gen_result),
                                         total=len(gen_result))))
            gen_concat = []
            for data in gen_result:
                gen_concat.extend(data)
            random.shuffle(gen_concat)
            pd.DataFrame(gen_concat).to_json(train_data_path, orient='records',
                                             lines=True)
            with open(train_info_path, 'w') as f:
                yaml.dump({
                    'tokens': train_tokens,
                    'prices': bill(train_tokens, training=True)
                }, f)

        # Create evaluation data
        evaluator = Evaluator(dummy_config, generator.paradigm, generator.vocab)
        evaluator_path = path.join(exp_dir, 'evaluator.pt')
        eval_info_path = path.join(exp_dir, 'eval_info.yaml')
        if not path.isfile(evaluator_path):
            print(f'Creating evaluator at {evaluator_path}')
            top_probs = []
            for problem in generator.problems:
                for args in sorted(problem.get_unique_args(eval_probs)):
                    top_probs.append((problem.__class__, args))
            evaluator.add_probs(top_probs)
            evaluator.update()
            torch.save(evaluator.state_dict(), evaluator_path)

            print(f'Computing evaluation cost...')
            eval_data = []
            for prob_cls, args in tqdm(evaluator.sorted_probs):
                x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
                eval_data.append(generator.xy_to_gpt_data(generator.vocab(x),
                                                          generator.vocab(y)))

            eval_tokens = sum(list(
                tqdm(pool.imap(count_tokens, eval_data), total=len(eval_data))))
            with open(eval_info_path, 'w') as f:
                yaml.dump({
                    'tokens': eval_tokens,
                    'prices': bill(eval_tokens, training=False)
                }, f)","def delete_completed_training_data():
    for fine_tune in openai.FineTune.list()['data']:
        for training_file in fine_tune['training_files']:
            if fine_tune['status'] == 'succeeded' and training_file[
                'status'] != 'deleted':
                result = openai.File.delete(training_file['id'])
                if result['deleted']:
                    print(
                        f'Training file of {training_file[""filename""]} deleted')","(321, 0)","(338, 55)",N,function_definition,upload_training_data,,191,fcc9872b-bb1b-469b-9144-63f944fcb568
"def delete_completed_training_data():
    for fine_tune in openai.FineTune.list()['data']:
        for training_file in fine_tune['training_files']:
            if fine_tune['status'] == 'succeeded' and training_file[
                'status'] != 'deleted':
                result = openai.File.delete(training_file['id'])
                if result['deleted']:
                    print(
                        f'Training file of {training_file[""filename""]} deleted')",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def upload_training_data(exp):
    exp_dir = get_exp_dir(exp)
    exp_name = get_exp_name(exp)
    train_data_path = path.join(exp_dir, 'train.jsonl')
    train_info_path = path.join(exp_dir, 'train_info.yaml')
    train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
    if path.isfile(train_data_path) and path.isfile(
            train_info_path) and not path.isfile(train_uploaded_path):
        print(f'Uploading {train_data_path}')
        with open(train_data_path, 'r') as f:
            uploaded_file = openai.File.create(
                file=open(train_data_path),
                purpose='fine-tune',
                user_provided_filename=exp_name
            )
        print(f'Uploaded as {uploaded_file[""id""]}')
        with open(train_uploaded_path, 'w') as f:
            yaml.dump(openai_to_dict(uploaded_file), f)","def request_fine_tuning(exp):
    exp_dir = get_exp_dir(exp)
    exp_name = get_exp_name(exp)
    train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
    fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
    if path.isfile(train_uploaded_path) and not path.isfile(fine_tune_path):
        print(f'Request fine-tuning of {exp_name}')
        with open(train_uploaded_path, 'r') as f:
            training_file_id = yaml.load(f, Loader=yaml.FullLoader)['id']
        fine_tune = openai.FineTune.create(
            training_file=training_file_id,
            model='ada',
            n_epochs=1,
            batch_size=256,
            prompt_loss_weight=0,
            suffix=exp_name
        )
        with open(fine_tune_path, 'w') as f:
            yaml.dump(openai_to_dict(fine_tune), f)","(341, 0)","(349, 80)",N,function_definition,delete_completed_training_data,,95,b663de87-b90f-4822-98a2-99fe2997d3b2
"def request_fine_tuning(exp):
    exp_dir = get_exp_dir(exp)
    exp_name = get_exp_name(exp)
    train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
    fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
    if path.isfile(train_uploaded_path) and not path.isfile(fine_tune_path):
        print(f'Request fine-tuning of {exp_name}')
        with open(train_uploaded_path, 'r') as f:
            training_file_id = yaml.load(f, Loader=yaml.FullLoader)['id']
        fine_tune = openai.FineTune.create(
            training_file=training_file_id,
            model='ada',
            n_epochs=1,
            batch_size=256,
            prompt_loss_weight=0,
            suffix=exp_name
        )
        with open(fine_tune_path, 'w') as f:
            yaml.dump(openai_to_dict(fine_tune), f)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def delete_completed_training_data():
    for fine_tune in openai.FineTune.list()['data']:
        for training_file in fine_tune['training_files']:
            if fine_tune['status'] == 'succeeded' and training_file[
                'status'] != 'deleted':
                result = openai.File.delete(training_file['id'])
                if result['deleted']:
                    print(
                        f'Training file of {training_file[""filename""]} deleted')","def check_fine_tune(exp):
    exp_dir = get_exp_dir(exp)
    fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
    if not path.isfile(fine_tune_path):
        print('No fine-tuning record found. Request fine-tuning first.')
        return

    with open(fine_tune_path, 'r') as f:
        fine_tune_id = yaml.load(f, Loader=yaml.FullLoader)['id']
    fine_tune = openai.FineTune.retrieve(id=fine_tune_id)
    if fine_tune['status'] == 'succeeded':
        print(f'Fine-tune completed: {fine_tune[""id""]}')
        with open(path.join(exp_dir, 'fine_tune_complete.yaml'), 'w') as f:
            yaml.dump(openai_to_dict(fine_tune), f)
    return fine_tune","(352, 0)","(370, 51)",N,function_definition,request_fine_tuning,,201,06709bbe-57e0-4ab0-93d2-5b70f75e06e5
"def check_fine_tune(exp):
    exp_dir = get_exp_dir(exp)
    fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
    if not path.isfile(fine_tune_path):
        print('No fine-tuning record found. Request fine-tuning first.')
        return

    with open(fine_tune_path, 'r') as f:
        fine_tune_id = yaml.load(f, Loader=yaml.FullLoader)['id']
    fine_tune = openai.FineTune.retrieve(id=fine_tune_id)
    if fine_tune['status'] == 'succeeded':
        print(f'Fine-tune completed: {fine_tune[""id""]}')
        with open(path.join(exp_dir, 'fine_tune_complete.yaml'), 'w') as f:
            yaml.dump(openai_to_dict(fine_tune), f)
    return fine_tune",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def request_fine_tuning(exp):
    exp_dir = get_exp_dir(exp)
    exp_name = get_exp_name(exp)
    train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
    fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
    if path.isfile(train_uploaded_path) and not path.isfile(fine_tune_path):
        print(f'Request fine-tuning of {exp_name}')
        with open(train_uploaded_path, 'r') as f:
            training_file_id = yaml.load(f, Loader=yaml.FullLoader)['id']
        fine_tune = openai.FineTune.create(
            training_file=training_file_id,
            model='ada',
            n_epochs=1,
            batch_size=256,
            prompt_loss_weight=0,
            suffix=exp_name
        )
        with open(fine_tune_path, 'w') as f:
            yaml.dump(openai_to_dict(fine_tune), f)","def save_inference(args, model_id):
    example, save_path = args
    if path.isfile(save_path):
        return
    max_tokens = len(gpt2_tokenizer(example['completion'])['input_ids']) + 1
    for retry in range(10):
        try:
            result = openai.Completion.create(
                model=model_id,
                prompt=example['prompt'],
                max_tokens=max_tokens,
                temperature=0
            )
            with open(save_path, 'w') as f:
                json.dump(result, f, indent=2)
            break
        except openai.error.RateLimitError:
            time.sleep(5)
    else:
        print('Maximum retry exceed. Failed to evaluate an example.')","(373, 0)","(387, 20)",N,function_definition,check_fine_tune,,186,9263c5c6-caeb-48ab-a83d-1c77e9e1cc0a
"def save_inference(args, model_id):
    example, save_path = args
    if path.isfile(save_path):
        return
    max_tokens = len(gpt2_tokenizer(example['completion'])['input_ids']) + 1
    for retry in range(10):
        try:
            result = openai.Completion.create(
                model=model_id,
                prompt=example['prompt'],
                max_tokens=max_tokens,
                temperature=0
            )
            with open(save_path, 'w') as f:
                json.dump(result, f, indent=2)
            break
        except openai.error.RateLimitError:
            time.sleep(5)
    else:
        print('Maximum retry exceed. Failed to evaluate an example.')",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def check_fine_tune(exp):
    exp_dir = get_exp_dir(exp)
    fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
    if not path.isfile(fine_tune_path):
        print('No fine-tuning record found. Request fine-tuning first.')
        return

    with open(fine_tune_path, 'r') as f:
        fine_tune_id = yaml.load(f, Loader=yaml.FullLoader)['id']
    fine_tune = openai.FineTune.retrieve(id=fine_tune_id)
    if fine_tune['status'] == 'succeeded':
        print(f'Fine-tune completed: {fine_tune[""id""]}')
        with open(path.join(exp_dir, 'fine_tune_complete.yaml'), 'w') as f:
            yaml.dump(openai_to_dict(fine_tune), f)
    return fine_tune","def evaluate(exp):
    processes = 32
    exp_dir = get_exp_dir(exp)
    infer_dir = path.join(exp_dir, 'inferences')
    eval_result_path = path.join(exp_dir, 'eval_result.yaml')
    if path.isfile(eval_result_path):
        # Already done
        return

    evaluator_path = path.join(exp_dir, 'evaluator.pt')
    fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
    if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return

    dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
    generator = GPTDataGenerator(exp)
    evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
    evaluator.load_state_dict(torch.load(evaluator_path))
    with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
    model_id = fine_tune_complete['fine_tuned_model']

    os.makedirs(infer_dir, mode=0o700, exist_ok=True)

    eval_data = []
    infer_args = []
    skip_count = 0
    for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))

    print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
    print(f'Model ID: {model_id}')
    with Pool(16) as pool:
        list(tqdm(
            pool.imap(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))

    # Aggregate results
    corrects = []
    wrongs = []
    for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)

    node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
    correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
    with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
    print(f'Evaluation result written to {eval_result_path}')","(390, 0)","(409, 69)",N,function_definition,save_inference,,152,d093dd94-17db-466c-94b5-b07d9dbc051b
"def evaluate(exp):
    processes = 32
    exp_dir = get_exp_dir(exp)
    infer_dir = path.join(exp_dir, 'inferences')
    eval_result_path = path.join(exp_dir, 'eval_result.yaml')
    if path.isfile(eval_result_path):
        # Already done
        return

    evaluator_path = path.join(exp_dir, 'evaluator.pt')
    fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
    if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return

    dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
    generator = GPTDataGenerator(exp)
    evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
    evaluator.load_state_dict(torch.load(evaluator_path))
    with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
    model_id = fine_tune_complete['fine_tuned_model']

    os.makedirs(infer_dir, mode=0o700, exist_ok=True)

    eval_data = []
    infer_args = []
    skip_count = 0
    for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))

    print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
    print(f'Model ID: {model_id}')
    with Pool(16) as pool:
        list(tqdm(
            pool.imap(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))

    # Aggregate results
    corrects = []
    wrongs = []
    for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)

    node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
    correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
    with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
    print(f'Evaluation result written to {eval_result_path}')",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def save_inference(args, model_id):
    example, save_path = args
    if path.isfile(save_path):
        return
    max_tokens = len(gpt2_tokenizer(example['completion'])['input_ids']) + 1
    for retry in range(10):
        try:
            result = openai.Completion.create(
                model=model_id,
                prompt=example['prompt'],
                max_tokens=max_tokens,
                temperature=0
            )
            with open(save_path, 'w') as f:
                json.dump(result, f, indent=2)
            break
        except openai.error.RateLimitError:
            time.sleep(5)
    else:
        print('Maximum retry exceed. Failed to evaluate an example.')","processes = 32
exp_dir = get_exp_dir(exp)
infer_dir = path.join(exp_dir, 'inferences')
eval_result_path = path.join(exp_dir, 'eval_result.yaml')
if path.isfile(eval_result_path):
        # Already done
        return
evaluator_path = path.join(exp_dir, 'evaluator.pt')
fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return
dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
generator = GPTDataGenerator(exp)
evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
evaluator.load_state_dict(torch.load(evaluator_path))
with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
model_id = fine_tune_complete['fine_tuned_model']
os.makedirs(infer_dir, mode=0o700, exist_ok=True)
eval_data = []
infer_args = []
skip_count = 0
for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))
print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
print(f'Model ID: {model_id}')
with Pool(16) as pool:
        list(tqdm(
            pool.imap(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))
# Aggregate results
corrects = []
wrongs = []","(412, 0)","(494, 61)",N,function_definition,evaluate,,720,cdb9a08e-3236-45be-b658-09019156c9ec
"processes = 32
exp_dir = get_exp_dir(exp)
infer_dir = path.join(exp_dir, 'inferences')
eval_result_path = path.join(exp_dir, 'eval_result.yaml')
if path.isfile(eval_result_path):
        # Already done
        return
evaluator_path = path.join(exp_dir, 'evaluator.pt')
fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')
if not path.isfile(evaluator_path) or not path.isfile(
            fine_tune_complete_path):
        print('Dependencies not met.')
        return
dummy_config = {'eval_length_budget': 1000, 'num_workers': processes}
generator = GPTDataGenerator(exp)
evaluator = Evaluator(dummy_config, exp.paradigm, vocab=get_exp_vocab(exp))
evaluator.load_state_dict(torch.load(evaluator_path))
with open(fine_tune_complete_path, 'r') as f:
        fine_tune_complete = yaml.load(f, Loader=yaml.FullLoader)
model_id = fine_tune_complete['fine_tuned_model']
os.makedirs(infer_dir, mode=0o700, exist_ok=True)
eval_data = []
infer_args = []
skip_count = 0
for i, (prob_cls, args) in enumerate(tqdm(evaluator.sorted_probs)):
        x, y, _ = prob_cls.solve(args, paradigm=generator.paradigm)
        datum = generator.xy_to_gpt_data(generator.vocab(x), generator.vocab(y))
        eval_data.append(datum)
        for j, example in enumerate(datum):
            save_path = path.join(infer_dir, f'{i}-{j}.json')
            if path.isfile(save_path):
                # Already done
                skip_count += 1
                continue
            infer_args.append((example, save_path))
print(
        f'Calling API for {len(infer_args)} examples, skipping already finished {skip_count} examples.')
print(f'Model ID: {model_id}')
with Pool(16) as pool:
        list(tqdm(
            pool.imap(partial(save_inference, model_id=model_id), infer_args),
            total=len(infer_args)))
# Aggregate results
corrects = []
wrongs = []",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/function_definition-evaluate/,evaluate,Previous sibling does not exist,"for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)
node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
print(f'Evaluation result written to {eval_result_path}')","(413, 4)","(463, 15)",N,"expression_statement,expression_statement,expression_statement,expression_statement,if_statement,expression_statement,expression_statement,if_statement,expression_statement,expression_statement,expression_statement,expression_statement,with_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,for_statement,expression_statement,expression_statement,with_statement,comment,expression_statement,expression_statement",expression_statement,,450,ef964a00-1888-432d-a596-79d53d8bbdfc
"for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)
node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
print(f'Evaluation result written to {eval_result_path}')",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/function_definition-evaluate/,evaluate,wrongs = [],Next sibling does not exist,"(464, 4)","(494, 61)",N,"for_statement,expression_statement,expression_statement,with_statement,expression_statement",for_statement,,235,6ed44fe3-c2c4-4e0b-ab81-f02ea9774a6c
"def progress():
    fine_tune_queue = []
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        exp_name = get_exp_name(exp)

        train_info_path = path.join(exp_dir, 'train_info.yaml')
        train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
        fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
        fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')

        if path.isfile(train_info_path) and not path.isfile(
                train_uploaded_path) and len(fine_tune_queue) < 2:
            print(datetime.now())
            delete_completed_training_data()
            upload_training_data(exp)
        if path.isfile(train_uploaded_path) and not path.isfile(fine_tune_path):
            print(datetime.now())
            request_fine_tuning(exp)
        if path.isfile(fine_tune_path) and not path.isfile(
                fine_tune_complete_path):
            fine_tune = check_fine_tune(exp)
            if fine_tune['status'] == 'succeeded':
                print(datetime.now())
                print(f'{exp_name} fine-tuning completed')
            else:
                fine_tune_queue.append(exp)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"for i, datum in enumerate(tqdm(eval_data)):
        correct = True
        for j, example in enumerate(datum):
            result_path = path.join(infer_dir, f'{i}-{j}.json')
            with open(result_path, 'r') as f:
                result = json.load(f)
            if not result['choices'][0]['text'].startswith(
                    example['completion']):
                correct = False
                wrongs.append((
                    example['prompt'],
                    example['completion'],
                    result['choices'][0]['text'],
                    result['choices'][0]['finish_reason']
                ))
        corrects.append(correct)
node_eval = {
        prob: correct
        for prob, correct in zip(evaluator.sorted_probs, corrects)
    }
correct_deep, correct_shallow, prob_total = evaluator.aggregate_eval(
        node_eval)
with open(eval_result_path, 'w') as f:
        eval_result = {
            'correct': sum(correct_deep.values()),
            'total': sum(prob_total.values()),
        }
        print(eval_result)
        yaml.dump(eval_result, f)
print(f'Evaluation result written to {eval_result_path}')","def main():
    while True:
        try:
            progress()
        except Exception as e:
            print(e)
        time.sleep(60)","(497, 0)","(523, 43)",N,function_definition,progress,,253,57753de6-876d-40b4-a00e-1358d1bb12ba
"def main():
    while True:
        try:
            progress()
        except Exception as e:
            print(e)
        time.sleep(60)",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def progress():
    fine_tune_queue = []
    for exp in experiments:
        exp_dir = get_exp_dir(exp)
        exp_name = get_exp_name(exp)

        train_info_path = path.join(exp_dir, 'train_info.yaml')
        train_uploaded_path = path.join(exp_dir, 'train_uploaded.yaml')
        fine_tune_path = path.join(exp_dir, 'fine_tune.yaml')
        fine_tune_complete_path = path.join(exp_dir, 'fine_tune_complete.yaml')

        if path.isfile(train_info_path) and not path.isfile(
                train_uploaded_path) and len(fine_tune_queue) < 2:
            print(datetime.now())
            delete_completed_training_data()
            upload_training_data(exp)
        if path.isfile(train_uploaded_path) and not path.isfile(fine_tune_path):
            print(datetime.now())
            request_fine_tuning(exp)
        if path.isfile(fine_tune_path) and not path.isfile(
                fine_tune_complete_path):
            fine_tune = check_fine_tune(exp)
            if fine_tune['status'] == 'succeeded':
                print(datetime.now())
                print(f'{exp_name} fine-tuning completed')
            else:
                fine_tune_queue.append(exp)","if __name__ == '__main__':
    main()","(526, 0)","(532, 22)",N,function_definition,main,,29,1f2fcb59-32c3-4422-a33d-b4aadd6daf17
"if __name__ == '__main__':
    main()",gpt_fine_tune.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\gpt_fine_tune.py,module/,module,"def main():
    while True:
        try:
            progress()
        except Exception as e:
            print(e)
        time.sleep(60)",Next sibling does not exist,"(535, 0)","(536, 10)",N,if_statement,if_statement,,11,1659e97a-5730-42ed-a43f-54b0cff8f288
"import os
import os.path as path
import socket
import sys
from argparse import ArgumentParser
from datetime import datetime
from functools import partial
from glob import glob

import torch
import torch.nn as nn
import yaml
from tensorboard.backend.event_processing.event_accumulator import \
    EventAccumulator
from torch.utils.tensorboard import SummaryWriter

from data import PROBLEM, ProblemSet
from data.problem import build_vocab, collate_by_len
from data.tokenizer import Label
from eval import Evaluator
from models import MODEL
from utils import Timer

sys.setrecursionlimit(100_000)

parser = ArgumentParser()
parser.add_argument('--paradigm', '-p', choices=['wt', 'cot', 'rot'],
                    required=True)
parser.add_argument('--config', '-c')
parser.add_argument('--episode', '-e')
parser.add_argument('--log-dir', '-l')
parser.add_argument('--override', '-o', default='')
parser.add_argument('--resume', action='store_true')

torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True


def main():
    print(f'Running on {socket.gethostname()} | {torch.cuda.get_device_name()}')
    start_time = datetime.now()
    print(f'Training started at {start_time}')
    args = parser.parse_args()
    paradigm = args.paradigm

    # Load config
    config = yaml.load(open(args.config), Loader=yaml.FullLoader)
    episode = yaml.load(open(args.episode), Loader=yaml.FullLoader)
    config['episode'] = episode
    config['paradigm'] = paradigm

    # Override options
    for option in args.override.split('|'):
        if not option:
            continue
        address, value = option.split('=')
        keys = address.split('.')
        here = config
        for key in keys[:-1]:
            if key not in here:
                here[key] = {}
            here = here[key]
        if keys[-1] not in here:
            print(f'Warning: {address} is not defined in config file.')
        here[keys[-1]] = yaml.load(value, Loader=yaml.FullLoader)

    # Prevent overwriting
    config['log_dir'] = args.log_dir
    config_save_path = path.join(config['log_dir'], 'config.yaml')
    try:
        # Try to open config file to bypass NFS cache
        with open(config_save_path, 'r') as f:
            f.read(1)
            config_exists = True
    except FileNotFoundError:
        config_exists = False

    if config_exists and not args.resume:
        print(f'WARNING: {args.log_dir} already exists. Skipping...')
        exit(0)

    # Save config
    os.makedirs(config['log_dir'], mode=0o755, exist_ok=True)
    episode_save_path = path.join(config['log_dir'], 'episode.yaml')
    yaml.dump(config, open(config_save_path, 'w'))
    yaml.dump(episode, open(episode_save_path, 'w'))
    print('Config & episode saved to {}'.format(config['log_dir']))

    # Build vocab
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    vocab = build_vocab(prob_classes, paradigm=paradigm)

    # Build model
    model = MODEL[config['model']](config, vocab)
    start_step = 0

    # Training components
    criterion = nn.CrossEntropyLoss(reduction='none')
    writer = SummaryWriter(config['log_dir'], flush_secs=15)
    scaler = torch.cuda.amp.GradScaler(
        init_scale=2. ** 40, growth_interval=1_000_000_000_000)  # constant

    # Resume checkpoint
    if config_exists and args.resume:
        ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
        if len(ckpt_paths) > 0:
            ckpt_path = ckpt_paths[-1]
            ckpt = torch.load(ckpt_path)
            model.load_state_dict(ckpt['model'])
            model.optim.load_state_dict(ckpt['optim'])
            model.lr_sched.load_state_dict(ckpt['lr_sched'])
            scaler.load_state_dict(ckpt['grad_scaler'])
            start_step = ckpt['step']
            print(f'Loaded checkpoint at {ckpt_path}')
    model.optim.zero_grad(set_to_none=True)

    # Build problems
    problems = [
        PROBLEM[prob_spec['name']](paradigm, vocab, prob_spec['config'])
        for prob_spec in episode
    ]
    print(', '.join([f'{problem}' for problem in problems]))
    problem_set = ProblemSet(problems, paradigm=paradigm, vocab=vocab)

    # Evaluator
    evaluator = Evaluator(config, paradigm, vocab)
    top_probs = []
    for problem in problems:
        for args in problem.get_unique_args(config['eval_data_size']):
            top_probs.append((problem.__class__, args))
    evaluator.add_probs(top_probs)

    # Evaluate the last checkpoint if needed
    step = start_step
    if step > 0 and step % config['eval_interval'] == 0:
        # Check if the last evaluation succeeded
        summary_path = sorted(glob(
            path.join(config['log_dir'], 'events.out.tfevents.*')))[-1]
        ea = EventAccumulator(summary_path)
        ea.Reload()

        # Evaluate the last checkpoint
        acc_tag = 'accuracy_deep/all'
        if acc_tag not in ea.Tags()['scalars'] or \
                ea.Scalars(acc_tag)[-1].step < step:
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

    # Train loader
    train_loader = problem_set.get_data_loader(
        config['batch_size'], num_workers=config['num_workers'],
        collate_fn=partial(collate_by_len, budget=config['length_budget']))
    train_loader_iter = iter(train_loader)

    # Main training loop
    for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break

    writer.flush()
    end_time = datetime.now()
    print()
    print(f'Training ended at {end_time}')
    print(f'Elapsed time: {end_time - start_time}')

    with open(path.join(config['log_dir'], 'completed.yaml'), 'a') as f:
        yaml.dump({
            'step': step,
            'end_time': end_time,
        }, f)


def write_summary(evaluation, step, writer):
    # Add scalar summaries
    for metric in [
        'prob_total', 'accuracy_shallow', 'accuracy_deep',
        'subprob_total', 'accuracy_subprob'
    ]:
        for prob_cls, score in evaluation[metric].items():
            writer.add_scalar(f'{metric}/{prob_cls.name}', score, step)

    # Summarize wrong samples
    for prob_cls in evaluation['prob_total']:
        wrong = '\n\n'.join(evaluation['wrong_samples'][prob_cls])
        writer.add_text(
            f'wrong/{prob_cls.name}',
            f'```\n{wrong}\n```', step)

    # Add average accuracies
    for acc_type in ['shallow', 'deep']:
        correct_all = sum(evaluation[f'correct_{acc_type}'].values())
        total_all = sum(evaluation['prob_total'].values())
        writer.add_scalar(
            f'accuracy_{acc_type}/all',
            correct_all / total_all,
            step)

    subprob_correct_all = sum(evaluation['subprob_correct'].values())
    subprob_total_all = sum(evaluation['subprob_total'].values())
    writer.add_scalar(
        'accuracy_subprob/all',
        subprob_correct_all / subprob_total_all,
        step)


if __name__ == '__main__':
    main()
",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,,NA,Previous sibling does not exist,"import os
import os.path as path
import socket
import sys
from argparse import ArgumentParser
from datetime import datetime
from functools import partial
from glob import glob
import torch
import torch.nn as nn
import yaml
from tensorboard.backend.event_processing.event_accumulator import \
    EventAccumulator
from torch.utils.tensorboard import SummaryWriter
from data import PROBLEM, ProblemSet
from data.problem import build_vocab, collate_by_len
from data.tokenizer import Label
from eval import Evaluator
from models import MODEL
from utils import Timer
sys.setrecursionlimit(100_000)
parser = ArgumentParser()
parser.add_argument('--paradigm', '-p', choices=['wt', 'cot', 'rot'],
                    required=True)
parser.add_argument('--config', '-c')
parser.add_argument('--episode', '-e')
parser.add_argument('--log-dir', '-l')
parser.add_argument('--override', '-o', default='')
parser.add_argument('--resume', action='store_true')
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True","(0, 0)","(305, 0)",N,module,module,,2602,9525690d-2ca2-492e-8e90-2ac530dfb134
"import os
import os.path as path
import socket
import sys
from argparse import ArgumentParser
from datetime import datetime
from functools import partial
from glob import glob
import torch
import torch.nn as nn
import yaml
from tensorboard.backend.event_processing.event_accumulator import \
    EventAccumulator
from torch.utils.tensorboard import SummaryWriter
from data import PROBLEM, ProblemSet
from data.problem import build_vocab, collate_by_len
from data.tokenizer import Label
from eval import Evaluator
from models import MODEL
from utils import Timer
sys.setrecursionlimit(100_000)
parser = ArgumentParser()
parser.add_argument('--paradigm', '-p', choices=['wt', 'cot', 'rot'],
                    required=True)
parser.add_argument('--config', '-c')
parser.add_argument('--episode', '-e')
parser.add_argument('--log-dir', '-l')
parser.add_argument('--override', '-o', default='')
parser.add_argument('--resume', action='store_true')
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/,module,Previous sibling does not exist,"def main():
    print(f'Running on {socket.gethostname()} | {torch.cuda.get_device_name()}')
    start_time = datetime.now()
    print(f'Training started at {start_time}')
    args = parser.parse_args()
    paradigm = args.paradigm

    # Load config
    config = yaml.load(open(args.config), Loader=yaml.FullLoader)
    episode = yaml.load(open(args.episode), Loader=yaml.FullLoader)
    config['episode'] = episode
    config['paradigm'] = paradigm

    # Override options
    for option in args.override.split('|'):
        if not option:
            continue
        address, value = option.split('=')
        keys = address.split('.')
        here = config
        for key in keys[:-1]:
            if key not in here:
                here[key] = {}
            here = here[key]
        if keys[-1] not in here:
            print(f'Warning: {address} is not defined in config file.')
        here[keys[-1]] = yaml.load(value, Loader=yaml.FullLoader)

    # Prevent overwriting
    config['log_dir'] = args.log_dir
    config_save_path = path.join(config['log_dir'], 'config.yaml')
    try:
        # Try to open config file to bypass NFS cache
        with open(config_save_path, 'r') as f:
            f.read(1)
            config_exists = True
    except FileNotFoundError:
        config_exists = False

    if config_exists and not args.resume:
        print(f'WARNING: {args.log_dir} already exists. Skipping...')
        exit(0)

    # Save config
    os.makedirs(config['log_dir'], mode=0o755, exist_ok=True)
    episode_save_path = path.join(config['log_dir'], 'episode.yaml')
    yaml.dump(config, open(config_save_path, 'w'))
    yaml.dump(episode, open(episode_save_path, 'w'))
    print('Config & episode saved to {}'.format(config['log_dir']))

    # Build vocab
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    vocab = build_vocab(prob_classes, paradigm=paradigm)

    # Build model
    model = MODEL[config['model']](config, vocab)
    start_step = 0

    # Training components
    criterion = nn.CrossEntropyLoss(reduction='none')
    writer = SummaryWriter(config['log_dir'], flush_secs=15)
    scaler = torch.cuda.amp.GradScaler(
        init_scale=2. ** 40, growth_interval=1_000_000_000_000)  # constant

    # Resume checkpoint
    if config_exists and args.resume:
        ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
        if len(ckpt_paths) > 0:
            ckpt_path = ckpt_paths[-1]
            ckpt = torch.load(ckpt_path)
            model.load_state_dict(ckpt['model'])
            model.optim.load_state_dict(ckpt['optim'])
            model.lr_sched.load_state_dict(ckpt['lr_sched'])
            scaler.load_state_dict(ckpt['grad_scaler'])
            start_step = ckpt['step']
            print(f'Loaded checkpoint at {ckpt_path}')
    model.optim.zero_grad(set_to_none=True)

    # Build problems
    problems = [
        PROBLEM[prob_spec['name']](paradigm, vocab, prob_spec['config'])
        for prob_spec in episode
    ]
    print(', '.join([f'{problem}' for problem in problems]))
    problem_set = ProblemSet(problems, paradigm=paradigm, vocab=vocab)

    # Evaluator
    evaluator = Evaluator(config, paradigm, vocab)
    top_probs = []
    for problem in problems:
        for args in problem.get_unique_args(config['eval_data_size']):
            top_probs.append((problem.__class__, args))
    evaluator.add_probs(top_probs)

    # Evaluate the last checkpoint if needed
    step = start_step
    if step > 0 and step % config['eval_interval'] == 0:
        # Check if the last evaluation succeeded
        summary_path = sorted(glob(
            path.join(config['log_dir'], 'events.out.tfevents.*')))[-1]
        ea = EventAccumulator(summary_path)
        ea.Reload()

        # Evaluate the last checkpoint
        acc_tag = 'accuracy_deep/all'
        if acc_tag not in ea.Tags()['scalars'] or \
                ea.Scalars(acc_tag)[-1].step < step:
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

    # Train loader
    train_loader = problem_set.get_data_loader(
        config['batch_size'], num_workers=config['num_workers'],
        collate_fn=partial(collate_by_len, budget=config['length_budget']))
    train_loader_iter = iter(train_loader)

    # Main training loop
    for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break

    writer.flush()
    end_time = datetime.now()
    print()
    print(f'Training ended at {end_time}')
    print(f'Elapsed time: {end_time - start_time}')

    with open(path.join(config['log_dir'], 'completed.yaml'), 'a') as f:
        yaml.dump({
            'step': step,
            'end_time': end_time,
        }, f)","(0, 0)","(35, 38)",N,"import_statement,import_statement,import_statement,import_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_statement,import_statement,import_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement",import_statement,,208,7b6d2731-1866-49a6-a018-1593b170ccff
"def main():
    print(f'Running on {socket.gethostname()} | {torch.cuda.get_device_name()}')
    start_time = datetime.now()
    print(f'Training started at {start_time}')
    args = parser.parse_args()
    paradigm = args.paradigm

    # Load config
    config = yaml.load(open(args.config), Loader=yaml.FullLoader)
    episode = yaml.load(open(args.episode), Loader=yaml.FullLoader)
    config['episode'] = episode
    config['paradigm'] = paradigm

    # Override options
    for option in args.override.split('|'):
        if not option:
            continue
        address, value = option.split('=')
        keys = address.split('.')
        here = config
        for key in keys[:-1]:
            if key not in here:
                here[key] = {}
            here = here[key]
        if keys[-1] not in here:
            print(f'Warning: {address} is not defined in config file.')
        here[keys[-1]] = yaml.load(value, Loader=yaml.FullLoader)

    # Prevent overwriting
    config['log_dir'] = args.log_dir
    config_save_path = path.join(config['log_dir'], 'config.yaml')
    try:
        # Try to open config file to bypass NFS cache
        with open(config_save_path, 'r') as f:
            f.read(1)
            config_exists = True
    except FileNotFoundError:
        config_exists = False

    if config_exists and not args.resume:
        print(f'WARNING: {args.log_dir} already exists. Skipping...')
        exit(0)

    # Save config
    os.makedirs(config['log_dir'], mode=0o755, exist_ok=True)
    episode_save_path = path.join(config['log_dir'], 'episode.yaml')
    yaml.dump(config, open(config_save_path, 'w'))
    yaml.dump(episode, open(episode_save_path, 'w'))
    print('Config & episode saved to {}'.format(config['log_dir']))

    # Build vocab
    prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
    vocab = build_vocab(prob_classes, paradigm=paradigm)

    # Build model
    model = MODEL[config['model']](config, vocab)
    start_step = 0

    # Training components
    criterion = nn.CrossEntropyLoss(reduction='none')
    writer = SummaryWriter(config['log_dir'], flush_secs=15)
    scaler = torch.cuda.amp.GradScaler(
        init_scale=2. ** 40, growth_interval=1_000_000_000_000)  # constant

    # Resume checkpoint
    if config_exists and args.resume:
        ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
        if len(ckpt_paths) > 0:
            ckpt_path = ckpt_paths[-1]
            ckpt = torch.load(ckpt_path)
            model.load_state_dict(ckpt['model'])
            model.optim.load_state_dict(ckpt['optim'])
            model.lr_sched.load_state_dict(ckpt['lr_sched'])
            scaler.load_state_dict(ckpt['grad_scaler'])
            start_step = ckpt['step']
            print(f'Loaded checkpoint at {ckpt_path}')
    model.optim.zero_grad(set_to_none=True)

    # Build problems
    problems = [
        PROBLEM[prob_spec['name']](paradigm, vocab, prob_spec['config'])
        for prob_spec in episode
    ]
    print(', '.join([f'{problem}' for problem in problems]))
    problem_set = ProblemSet(problems, paradigm=paradigm, vocab=vocab)

    # Evaluator
    evaluator = Evaluator(config, paradigm, vocab)
    top_probs = []
    for problem in problems:
        for args in problem.get_unique_args(config['eval_data_size']):
            top_probs.append((problem.__class__, args))
    evaluator.add_probs(top_probs)

    # Evaluate the last checkpoint if needed
    step = start_step
    if step > 0 and step % config['eval_interval'] == 0:
        # Check if the last evaluation succeeded
        summary_path = sorted(glob(
            path.join(config['log_dir'], 'events.out.tfevents.*')))[-1]
        ea = EventAccumulator(summary_path)
        ea.Reload()

        # Evaluate the last checkpoint
        acc_tag = 'accuracy_deep/all'
        if acc_tag not in ea.Tags()['scalars'] or \
                ea.Scalars(acc_tag)[-1].step < step:
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

    # Train loader
    train_loader = problem_set.get_data_loader(
        config['batch_size'], num_workers=config['num_workers'],
        collate_fn=partial(collate_by_len, budget=config['length_budget']))
    train_loader_iter = iter(train_loader)

    # Main training loop
    for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break

    writer.flush()
    end_time = datetime.now()
    print()
    print(f'Training ended at {end_time}')
    print(f'Elapsed time: {end_time - start_time}')

    with open(path.join(config['log_dir'], 'completed.yaml'), 'a') as f:
        yaml.dump({
            'step': step,
            'end_time': end_time,
        }, f)",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/,module,"import os
import os.path as path
import socket
import sys
from argparse import ArgumentParser
from datetime import datetime
from functools import partial
from glob import glob
import torch
import torch.nn as nn
import yaml
from tensorboard.backend.event_processing.event_accumulator import \
    EventAccumulator
from torch.utils.tensorboard import SummaryWriter
from data import PROBLEM, ProblemSet
from data.problem import build_vocab, collate_by_len
from data.tokenizer import Label
from eval import Evaluator
from models import MODEL
from utils import Timer
sys.setrecursionlimit(100_000)
parser = ArgumentParser()
parser.add_argument('--paradigm', '-p', choices=['wt', 'cot', 'rot'],
                    required=True)
parser.add_argument('--config', '-c')
parser.add_argument('--episode', '-e')
parser.add_argument('--log-dir', '-l')
parser.add_argument('--override', '-o', default='')
parser.add_argument('--resume', action='store_true')
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True","print(f'Running on {socket.gethostname()} | {torch.cuda.get_device_name()}')
start_time = datetime.now()
print(f'Training started at {start_time}')
args = parser.parse_args()
paradigm = args.paradigm
# Load config
config = yaml.load(open(args.config), Loader=yaml.FullLoader)
episode = yaml.load(open(args.episode), Loader=yaml.FullLoader)
config['episode'] = episode
config['paradigm'] = paradigm
# Override options
for option in args.override.split('|'):
        if not option:
            continue
        address, value = option.split('=')
        keys = address.split('.')
        here = config
        for key in keys[:-1]:
            if key not in here:
                here[key] = {}
            here = here[key]
        if keys[-1] not in here:
            print(f'Warning: {address} is not defined in config file.')
        here[keys[-1]] = yaml.load(value, Loader=yaml.FullLoader)
# Prevent overwriting
config['log_dir'] = args.log_dir
config_save_path = path.join(config['log_dir'], 'config.yaml')
try:
        # Try to open config file to bypass NFS cache
        with open(config_save_path, 'r') as f:
            f.read(1)
            config_exists = True
    except FileNotFoundError:
        config_exists = False
if config_exists and not args.resume:
        print(f'WARNING: {args.log_dir} already exists. Skipping...')
        exit(0)
# Save config
os.makedirs(config['log_dir'], mode=0o755, exist_ok=True)
episode_save_path = path.join(config['log_dir'], 'episode.yaml')
yaml.dump(config, open(config_save_path, 'w'))
yaml.dump(episode, open(episode_save_path, 'w'))
print('Config & episode saved to {}'.format(config['log_dir']))
# Build vocab
prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
vocab = build_vocab(prob_classes, paradigm=paradigm)
# Build model
model = MODEL[config['model']](config, vocab)
start_step = 0
# Training components
criterion = nn.CrossEntropyLoss(reduction='none')
writer = SummaryWriter(config['log_dir'], flush_secs=15)","(38, 0)","(267, 13)",N,function_definition,main,,2089,89804670-6d56-430d-859e-2f983a3d072a
"print(f'Running on {socket.gethostname()} | {torch.cuda.get_device_name()}')
start_time = datetime.now()
print(f'Training started at {start_time}')
args = parser.parse_args()
paradigm = args.paradigm
# Load config
config = yaml.load(open(args.config), Loader=yaml.FullLoader)
episode = yaml.load(open(args.episode), Loader=yaml.FullLoader)
config['episode'] = episode
config['paradigm'] = paradigm
# Override options
for option in args.override.split('|'):
        if not option:
            continue
        address, value = option.split('=')
        keys = address.split('.')
        here = config
        for key in keys[:-1]:
            if key not in here:
                here[key] = {}
            here = here[key]
        if keys[-1] not in here:
            print(f'Warning: {address} is not defined in config file.')
        here[keys[-1]] = yaml.load(value, Loader=yaml.FullLoader)
# Prevent overwriting
config['log_dir'] = args.log_dir
config_save_path = path.join(config['log_dir'], 'config.yaml')
try:
        # Try to open config file to bypass NFS cache
        with open(config_save_path, 'r') as f:
            f.read(1)
            config_exists = True
    except FileNotFoundError:
        config_exists = False
if config_exists and not args.resume:
        print(f'WARNING: {args.log_dir} already exists. Skipping...')
        exit(0)
# Save config
os.makedirs(config['log_dir'], mode=0o755, exist_ok=True)
episode_save_path = path.join(config['log_dir'], 'episode.yaml')
yaml.dump(config, open(config_save_path, 'w'))
yaml.dump(episode, open(episode_save_path, 'w'))
print('Config & episode saved to {}'.format(config['log_dir']))
# Build vocab
prob_classes = [PROBLEM[prob_spec['name']] for prob_spec in episode]
vocab = build_vocab(prob_classes, paradigm=paradigm)
# Build model
model = MODEL[config['model']](config, vocab)
start_step = 0
# Training components
criterion = nn.CrossEntropyLoss(reduction='none')
writer = SummaryWriter(config['log_dir'], flush_secs=15)",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/function_definition-main/,main,Previous sibling does not exist,"scaler = torch.cuda.amp.GradScaler(
        init_scale=2. ** 40, growth_interval=1_000_000_000_000)
# constant
# Resume checkpoint
if config_exists and args.resume:
        ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
        if len(ckpt_paths) > 0:
            ckpt_path = ckpt_paths[-1]
            ckpt = torch.load(ckpt_path)
            model.load_state_dict(ckpt['model'])
            model.optim.load_state_dict(ckpt['optim'])
            model.lr_sched.load_state_dict(ckpt['lr_sched'])
            scaler.load_state_dict(ckpt['grad_scaler'])
            start_step = ckpt['step']
            print(f'Loaded checkpoint at {ckpt_path}')
model.optim.zero_grad(set_to_none=True)
# Build problems
problems = [
        PROBLEM[prob_spec['name']](paradigm, vocab, prob_spec['config'])
        for prob_spec in episode
    ]
print(', '.join([f'{problem}' for problem in problems]))
problem_set = ProblemSet(problems, paradigm=paradigm, vocab=vocab)
# Evaluator
evaluator = Evaluator(config, paradigm, vocab)
top_probs = []
for problem in problems:
        for args in problem.get_unique_args(config['eval_data_size']):
            top_probs.append((problem.__class__, args))
evaluator.add_probs(top_probs)
# Evaluate the last checkpoint if needed
step = start_step
if step > 0 and step % config['eval_interval'] == 0:
        # Check if the last evaluation succeeded
        summary_path = sorted(glob(
            path.join(config['log_dir'], 'events.out.tfevents.*')))[-1]
        ea = EventAccumulator(summary_path)
        ea.Reload()

        # Evaluate the last checkpoint
        acc_tag = 'accuracy_deep/all'
        if acc_tag not in ea.Tags()['scalars'] or \
                ea.Scalars(acc_tag)[-1].step < step:
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)
# Train loader","(39, 4)","(98, 60)",N,"expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,comment,expression_statement,expression_statement,expression_statement,expression_statement,comment,for_statement,comment,expression_statement,expression_statement,try_statement,if_statement,comment,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,comment,expression_statement,expression_statement,comment,expression_statement,expression_statement,comment,expression_statement,expression_statement",expression_statement,,469,14a83ede-3209-4355-9671-ff0111770693
"scaler = torch.cuda.amp.GradScaler(
        init_scale=2. ** 40, growth_interval=1_000_000_000_000)
# constant
# Resume checkpoint
if config_exists and args.resume:
        ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
        if len(ckpt_paths) > 0:
            ckpt_path = ckpt_paths[-1]
            ckpt = torch.load(ckpt_path)
            model.load_state_dict(ckpt['model'])
            model.optim.load_state_dict(ckpt['optim'])
            model.lr_sched.load_state_dict(ckpt['lr_sched'])
            scaler.load_state_dict(ckpt['grad_scaler'])
            start_step = ckpt['step']
            print(f'Loaded checkpoint at {ckpt_path}')
model.optim.zero_grad(set_to_none=True)
# Build problems
problems = [
        PROBLEM[prob_spec['name']](paradigm, vocab, prob_spec['config'])
        for prob_spec in episode
    ]
print(', '.join([f'{problem}' for problem in problems]))
problem_set = ProblemSet(problems, paradigm=paradigm, vocab=vocab)
# Evaluator
evaluator = Evaluator(config, paradigm, vocab)
top_probs = []
for problem in problems:
        for args in problem.get_unique_args(config['eval_data_size']):
            top_probs.append((problem.__class__, args))
evaluator.add_probs(top_probs)
# Evaluate the last checkpoint if needed
step = start_step
if step > 0 and step % config['eval_interval'] == 0:
        # Check if the last evaluation succeeded
        summary_path = sorted(glob(
            path.join(config['log_dir'], 'events.out.tfevents.*')))[-1]
        ea = EventAccumulator(summary_path)
        ea.Reload()

        # Evaluate the last checkpoint
        acc_tag = 'accuracy_deep/all'
        if acc_tag not in ea.Tags()['scalars'] or \
                ea.Scalars(acc_tag)[-1].step < step:
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)
# Train loader",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/function_definition-main/,main,"writer = SummaryWriter(config['log_dir'], flush_secs=15)","train_loader = problem_set.get_data_loader(
        config['batch_size'], num_workers=config['num_workers'],
        collate_fn=partial(collate_by_len, budget=config['length_budget']))
train_loader_iter = iter(train_loader)
# Main training loop","(99, 4)","(152, 18)",N,"expression_statement,comment,comment,if_statement,expression_statement,comment,expression_statement,expression_statement,expression_statement,comment,expression_statement,expression_statement,for_statement,expression_statement,comment,expression_statement,if_statement,comment",expression_statement,,464,fde81906-f8f2-4474-b637-1eba72175e8f
"train_loader = problem_set.get_data_loader(
        config['batch_size'], num_workers=config['num_workers'],
        collate_fn=partial(collate_by_len, budget=config['length_budget']))
train_loader_iter = iter(train_loader)
# Main training loop",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/function_definition-main/,main,# Train loader,"for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break","(153, 4)","(158, 24)",N,"expression_statement,expression_statement,comment",expression_statement,,51,343f17f9-be0c-4abf-a869-725a9b4bdd8d
"for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/function_definition-main/,main,"train_loader = problem_set.get_data_loader(
        config['batch_size'], num_workers=config['num_workers'],
        collate_fn=partial(collate_by_len, budget=config['length_budget']))
train_loader_iter = iter(train_loader)
# Main training loop","if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)","(159, 4)","(255, 21)",N,for_statement,for_statement,"for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break",1096,814aaffe-4eee-4b03-b09a-de72792ea5a4
"if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/function_definition-main/,main,"for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)","# Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)","(159, 4)","(255, 21)",N,for_statement,for_statement,"for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break",238,9c6de64c-ed6d-4966-bf41-59f4aff57b73
"# Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/function_definition-main/,main,"if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)","# Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)","(159, 4)","(255, 21)",N,for_statement,for_statement,"for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break",1181,17d26944-17c5-4c2a-8bf3-a730dafee0ae
"# Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/function_definition-main/,main,"# Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)","new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break","(159, 4)","(255, 21)",N,for_statement,for_statement,"for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break",809,dcd9d749-eec8-473d-abfd-17dd39a6d4c7
"new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/function_definition-main/,main,"# Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)","writer.flush()
end_time = datetime.now()
print()
print(f'Training ended at {end_time}')
print(f'Elapsed time: {end_time - start_time}')
with open(path.join(config['log_dir'], 'completed.yaml'), 'a') as f:
        yaml.dump({
            'step': step,
            'end_time': end_time,
        }, f)","(159, 4)","(255, 21)",N,for_statement,for_statement,"for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break",1028,0ceb99a6-d817-4d76-be17-c9ca037c4a4b
"writer.flush()
end_time = datetime.now()
print()
print(f'Training ended at {end_time}')
print(f'Elapsed time: {end_time - start_time}')
with open(path.join(config['log_dir'], 'completed.yaml'), 'a') as f:
        yaml.dump({
            'step': step,
            'end_time': end_time,
        }, f)",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/function_definition-main/,main,"for step in range(start_step + 1, config['max_train_steps'] + 1):
        splits = next(train_loader_iter)
        train_masks = [
            (label.to(model.device) >= Label.T).type(torch.float)
            for _, _, label in splits
        ]
        train_tokens = sum([mask.sum() for mask in train_masks])
        loss_total = 0.0
        for i, ((x, y, label), train_mask) in \
                enumerate(zip(splits, train_masks)):
            x, y = x.to(model.device), y.to(model.device)

            with torch.autocast(device_type='cuda', dtype=torch.float16,
                                enabled=config['amp']):
                output = model(x)
                loss = criterion(
                    output.view(-1, output.shape[-1]), y.view(-1)
                ) * train_mask.view(-1)
                loss = loss.sum() / train_tokens
            loss_total += loss.detach()
            scaler.scale(loss).backward(retain_graph=i < len(splits) - 1)

        scaler.step(model.optim)
        scaler.update()
        model.lr_sched.step()
        model.optim.zero_grad(set_to_none=True)

        if step % config['summary_interval'] == 0:
            writer.add_scalar('loss/train', loss_total, step)
            writer.add_scalar('lr', model.lr_sched.get_last_lr()[0], step)
            writer.add_scalar('splits', len(splits), step)

            # Sequence length summary
            trailing_pads_all = []
            lengths_all = []
            for _, _, label in splits:
                not_pad = (label > Label.PAD).type(torch.int)
                reverse_cumsum = \
                    not_pad + not_pad.sum(0, keepdims=True) \
                    - torch.cumsum(not_pad, 0)
                trailing_pads = (reverse_cumsum == 0).type(torch.float).sum(0)
                lengths = label.shape[0] - trailing_pads
                trailing_pads_all.append(trailing_pads)
                lengths_all.append(lengths)
            trailing_pads = torch.cat(trailing_pads_all)
            lengths = torch.cat(lengths_all)
            writer.add_scalar('trailing_pads/total', trailing_pads.sum(), step)
            writer.add_scalar('trailing_pads/mean', trailing_pads.mean(), step)
            writer.add_scalar('lengths/max', lengths.max(), step)
            writer.add_scalar('lengths/mean', lengths.mean(), step)
            writer.add_scalar('lengths/median', lengths.median(), step)
            writer.add_scalar('lengths/min', lengths.min(), step)
            writer.add_scalar('grad_scaler/scale', scaler.get_scale(), step)

            # Compute remaining time
            now = datetime.now()
            elapsed_time = now - start_time
            elapsed_steps = step - start_step
            total_steps = config['max_train_steps'] - start_step
            est_total = elapsed_time * total_steps / elapsed_steps
            # Remove microseconds for brevity
            elapsed_time = str(elapsed_time).split('.')[0]
            est_total = str(est_total).split('.')[0]
            print(f'\r[Step {step}] [{elapsed_time} / {est_total}] '
                  f'Loss: {loss_total:.8f}', end='')

        if step % config['ckpt_interval'] == 0:
            # Remove old checkpoints
            ckpt_paths = sorted(glob(path.join(config['log_dir'], 'ckpt-*.pt')))
            for ckpt_path in ckpt_paths[:-4]:
                os.remove(ckpt_path)

            new_ckpt_path = path.join(config['log_dir'], f'ckpt-{step:06}.pt')
            torch.save({
                'step': step,
                'config': config,
                'paradigm': paradigm,
                'model': model.state_dict(),
                'optim': model.optim.state_dict(),
                'lr_sched': model.lr_sched.state_dict(),
                'grad_scaler': scaler.state_dict(),
            }, new_ckpt_path)

        if step % config['eval_interval'] == 0:
            print()
            with Timer('Evaluation time: {:.3f}s'):
                torch.cuda.empty_cache()
                evaluation = evaluator.evaluate(model)
                torch.cuda.empty_cache()

            write_summary(evaluation, step, writer)

            subprob_correct_all = sum(evaluation['subprob_correct'].values())
            subprob_total_all = sum(evaluation['subprob_total'].values())
            if subprob_correct_all == subprob_total_all:
                print('==== Perfect score reached ====')
                break",Next sibling does not exist,"(257, 4)","(267, 13)",N,"expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,with_statement",expression_statement,,76,c7da839e-65f9-4a7f-b858-6f99dcf2d5fd
"def write_summary(evaluation, step, writer):
    # Add scalar summaries
    for metric in [
        'prob_total', 'accuracy_shallow', 'accuracy_deep',
        'subprob_total', 'accuracy_subprob'
    ]:
        for prob_cls, score in evaluation[metric].items():
            writer.add_scalar(f'{metric}/{prob_cls.name}', score, step)

    # Summarize wrong samples
    for prob_cls in evaluation['prob_total']:
        wrong = '\n\n'.join(evaluation['wrong_samples'][prob_cls])
        writer.add_text(
            f'wrong/{prob_cls.name}',
            f'```\n{wrong}\n```', step)

    # Add average accuracies
    for acc_type in ['shallow', 'deep']:
        correct_all = sum(evaluation[f'correct_{acc_type}'].values())
        total_all = sum(evaluation['prob_total'].values())
        writer.add_scalar(
            f'accuracy_{acc_type}/all',
            correct_all / total_all,
            step)

    subprob_correct_all = sum(evaluation['subprob_correct'].values())
    subprob_total_all = sum(evaluation['subprob_total'].values())
    writer.add_scalar(
        'accuracy_subprob/all',
        subprob_correct_all / subprob_total_all,
        step)",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/,module,"writer.flush()
end_time = datetime.now()
print()
print(f'Training ended at {end_time}')
print(f'Elapsed time: {end_time - start_time}')
with open(path.join(config['log_dir'], 'completed.yaml'), 'a') as f:
        yaml.dump({
            'step': step,
            'end_time': end_time,
        }, f)","if __name__ == '__main__':
    main()","(270, 0)","(300, 13)",N,function_definition,write_summary,,273,39a9737a-a0dc-425a-9049-83bdc11e1db5
"if __name__ == '__main__':
    main()",train.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\train.py,module/,module,"def write_summary(evaluation, step, writer):
    # Add scalar summaries
    for metric in [
        'prob_total', 'accuracy_shallow', 'accuracy_deep',
        'subprob_total', 'accuracy_subprob'
    ]:
        for prob_cls, score in evaluation[metric].items():
            writer.add_scalar(f'{metric}/{prob_cls.name}', score, step)

    # Summarize wrong samples
    for prob_cls in evaluation['prob_total']:
        wrong = '\n\n'.join(evaluation['wrong_samples'][prob_cls])
        writer.add_text(
            f'wrong/{prob_cls.name}',
            f'```\n{wrong}\n```', step)

    # Add average accuracies
    for acc_type in ['shallow', 'deep']:
        correct_all = sum(evaluation[f'correct_{acc_type}'].values())
        total_all = sum(evaluation['prob_total'].values())
        writer.add_scalar(
            f'accuracy_{acc_type}/all',
            correct_all / total_all,
            step)

    subprob_correct_all = sum(evaluation['subprob_correct'].values())
    subprob_total_all = sum(evaluation['subprob_total'].values())
    writer.add_scalar(
        'accuracy_subprob/all',
        subprob_correct_all / subprob_total_all,
        step)",Next sibling does not exist,"(303, 0)","(304, 10)",N,if_statement,if_statement,,11,a5ee5431-7686-48b0-94d5-8b3425960463
"import random
import time


class Reservoir(list):
    def __init__(self, size):
        super().__init__()
        self.size = size
        self.total = 0
        self._evict = None

    def reserve(self) -> bool:
        self.total += 1
        if len(self) < self.size:
            return True
        self._evict = random.randrange(0, self.total)
        return self._evict < self.size

    def add(self, x) -> None:
        if len(self) < self.size:
            self.append(x)
        else:
            self[self._evict] = x
            self._evict = None

    def inflow(self, x) -> None:
        if self.reserve():
            self.add(x)


class Timer:
    def __init__(self, text):
        self.text = text

    def __enter__(self):
        self._start = time.perf_counter()
        return self

    def __exit__(self, *args):
        elapsed_time = time.perf_counter() - self._start
        print(self.text.format(elapsed_time))
",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,,NA,Previous sibling does not exist,"import random
import time","(0, 0)","(41, 0)",N,module,module,,236,714ab0c0-3d44-4bb3-ab7f-1f3498dcbdc7
"import random
import time",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/,module,Previous sibling does not exist,"class Reservoir(list):
    def __init__(self, size):
        super().__init__()
        self.size = size
        self.total = 0
        self._evict = None

    def reserve(self) -> bool:
        self.total += 1
        if len(self) < self.size:
            return True
        self._evict = random.randrange(0, self.total)
        return self._evict < self.size

    def add(self, x) -> None:
        if len(self) < self.size:
            self.append(x)
        else:
            self[self._evict] = x
            self._evict = None

    def inflow(self, x) -> None:
        if self.reserve():
            self.add(x)","(0, 0)","(1, 11)",N,"import_statement,import_statement",import_statement,,4,605833ac-60a1-440d-b483-0e7f4a6fb525
"class Reservoir(list):
    def __init__(self, size):
        super().__init__()
        self.size = size
        self.total = 0
        self._evict = None

    def reserve(self) -> bool:
        self.total += 1
        if len(self) < self.size:
            return True
        self._evict = random.randrange(0, self.total)
        return self._evict < self.size

    def add(self, x) -> None:
        if len(self) < self.size:
            self.append(x)
        else:
            self[self._evict] = x
            self._evict = None

    def inflow(self, x) -> None:
        if self.reserve():
            self.add(x)",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/,module,"import random
import time","class Timer:
    def __init__(self, text):
        self.text = text

    def __enter__(self):
        self._start = time.perf_counter()
        return self

    def __exit__(self, *args):
        elapsed_time = time.perf_counter() - self._start
        print(self.text.format(elapsed_time))","(4, 0)","(27, 23)",N,class_definition,Reservoir,,158,4aa8ef0c-1ec4-492e-8bac-4b926773a4aa
"def __init__(self, size):
        super().__init__()
        self.size = size
        self.total = 0
        self._evict = None",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/class_definition-Reservoir/,Reservoir,Previous sibling does not exist,"def reserve(self) -> bool:
        self.total += 1
        if len(self) < self.size:
            return True
        self._evict = random.randrange(0, self.total)
        return self._evict < self.size","(5, 4)","(9, 26)",N,function_definition,__init__,,33,83cf8dcf-3968-4286-a640-73856969ff9e
"def reserve(self) -> bool:
        self.total += 1
        if len(self) < self.size:
            return True
        self._evict = random.randrange(0, self.total)
        return self._evict < self.size",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/class_definition-Reservoir/,Reservoir,"def __init__(self, size):
        super().__init__()
        self.size = size
        self.total = 0
        self._evict = None","def add(self, x) -> None:
        if len(self) < self.size:
            self.append(x)
        else:
            self[self._evict] = x
            self._evict = None","(11, 4)","(16, 38)",N,function_definition,reserve,,50,23b2655d-ab2c-4427-aa52-03d65ac2ff9d
"def add(self, x) -> None:
        if len(self) < self.size:
            self.append(x)
        else:
            self[self._evict] = x
            self._evict = None",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/class_definition-Reservoir/,Reservoir,"def reserve(self) -> bool:
        self.total += 1
        if len(self) < self.size:
            return True
        self._evict = random.randrange(0, self.total)
        return self._evict < self.size","def inflow(self, x) -> None:
        if self.reserve():
            self.add(x)","(18, 4)","(23, 30)",N,function_definition,add,,43,898197fc-b2b1-41cf-a6aa-a2c8041f20f4
"def inflow(self, x) -> None:
        if self.reserve():
            self.add(x)",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/class_definition-Reservoir/,Reservoir,"def add(self, x) -> None:
        if len(self) < self.size:
            self.append(x)
        else:
            self[self._evict] = x
            self._evict = None",Next sibling does not exist,"(25, 4)","(27, 23)",N,function_definition,inflow,,20,dfdc93a4-ef66-493f-a7ec-aeaab86df866
"class Timer:
    def __init__(self, text):
        self.text = text

    def __enter__(self):
        self._start = time.perf_counter()
        return self

    def __exit__(self, *args):
        elapsed_time = time.perf_counter() - self._start
        print(self.text.format(elapsed_time))",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/,module,"class Reservoir(list):
    def __init__(self, size):
        super().__init__()
        self.size = size
        self.total = 0
        self._evict = None

    def reserve(self) -> bool:
        self.total += 1
        if len(self) < self.size:
            return True
        self._evict = random.randrange(0, self.total)
        return self._evict < self.size

    def add(self, x) -> None:
        if len(self) < self.size:
            self.append(x)
        else:
            self[self._evict] = x
            self._evict = None

    def inflow(self, x) -> None:
        if self.reserve():
            self.add(x)",Next sibling does not exist,"(30, 0)","(40, 45)",N,class_definition,Timer,,72,cc4f051b-b521-4b09-b1be-2c245f194cbc
"def __init__(self, text):
        self.text = text",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/class_definition-Timer/,Timer,Previous sibling does not exist,"def __enter__(self):
        self._start = time.perf_counter()
        return self","(31, 4)","(32, 24)",N,function_definition,__init__,,13,df33a683-ab89-4a3f-acab-50b44dd82e42
"def __enter__(self):
        self._start = time.perf_counter()
        return self",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/class_definition-Timer/,Timer,"def __init__(self, text):
        self.text = text","def __exit__(self, *args):
        elapsed_time = time.perf_counter() - self._start
        print(self.text.format(elapsed_time))","(34, 4)","(36, 19)",N,function_definition,__enter__,,19,58138516-5bd4-4b8e-a6b4-73ad5c011bf4
"def __exit__(self, *args):
        elapsed_time = time.perf_counter() - self._start
        print(self.text.format(elapsed_time))",utils.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\utils.py,module/class_definition-Timer/,Timer,"def __enter__(self):
        self._start = time.perf_counter()
        return self",Next sibling does not exist,"(38, 4)","(40, 45)",N,function_definition,__exit__,,32,72df3d9c-453b-461a-9c6d-99397f3cfd12
"import math
import random

from .problem import Problem, T


class Compare(Problem):
    """"""Compare two numbers
    E.g.,
        <GO>123<VS>234=<LT><STOP>
        <GO>84<VS>2=<GT><STOP>
        <GO>74<VS>74=<EQ><STOP>
        <GO>73847<VS>7243=<GT><STOP>
        <GO>73847<VS>73413=
            <GO>7<VS>7=<EQ><STOP>
            <GO>3847<VS>3413=<GT><STOP>
            <GT><STOP>
    """"""

    name = 'Compare'
    dependencies = {}
    symbols = ['<VS>', '<GT>', '<LT>', '<EQ>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        smaller = random.randrange(0, max_num)
        larger = random.randrange(0, max_num)
        if random.random() < 0.5:
            return smaller, larger
        else:
            return larger, smaller

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<VS>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        if left > right:
            return '<GT><STOP>'
        elif left < right:
            return '<LT><STOP>'
        else:
            return '<EQ><STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        thoughts = []
        digit_l, digit_r = len(str(left)), len(str(right))
        if digit_l == digit_r:
            # Compare first digit
            l_first, r_first = int(str(left)[0]), int(str(right)[0])
            thoughts.append(T(Compare, (l_first, r_first)))
            if l_first == r_first:
                # Compare the rest
                l_rest = int(str(left)[1:])
                r_rest = int(str(right)[1:])
                thoughts.append(T(Compare, (l_rest, r_rest)))

        return thoughts


class Add(Problem):
    """"""Addition of two positive integers
    E.g.,
        # Without carry
        <GO>31+28=
            <GO>1+8=9<STOP>
            <GO>3+2=5<STOP>
            59<STOP>

        # With carry
        <GO>39+28=
            <GO>9+8=17<STOP>
            <GO>3+1=4<STOP>
            <GO>4+2=6<STOP>
            67<STOP>

        # Solve recursively
        <GO>394+281=
            <GO>4+1=5<STOP>
            <GO>39+28=67<STOP>
            675<STOP>
    """"""
    name = 'Add'
    dependencies = {}
    symbols = ['+']

    def generate(self):
        # Generate [0, 999...999]
        max_num = 10 ** self.config['max_digits']
        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}+{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left + right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        l_last, r_last = left % 10, right % 10
        thoughts = [T(Add, (l_last, r_last))]

        l_rest, r_rest = left // 10, right // 10
        if l_last + r_last >= 10:
            thoughts.append(T(Add, (l_rest, 1)))
            l_rest += 1

        if l_rest > 0 and r_rest > 0:
            thoughts.append(T(Add, (l_rest, r_rest)))

        return thoughts


class Sub(Problem):
    """"""Subtraction of two positive integers
    E.g.,
        # Memorize trivial case
        <GO>14-8=6<STOP>

        # Without borrow
        <GO>445-283=
            <GO>15-3=12<STOP>
            <GO>44-28=16<STOP>
            162<STOP>

        # With borrow
        <GO>441-383=
            <GO>11-3=8<STOP>
            <GO>44-1=43<STOP>
            <GO>43-38=5<STOP>
            162<STOP>
    """"""

    name = 'Sub'
    dependencies = {}
    symbols = ['-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)

        if left < right:
            return right, left
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}-{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 19 and right <= 9:
            return []

        l_last = left % 10 + 10
        r_last = right % 10
        thoughts = [T(Sub, (l_last, r_last))]
        l_rest, r_rest = left // 10, right // 10
        if l_last - r_last < 10:
            thoughts.append(T(Sub, (l_rest, 1)))
            l_rest -= 1
        if r_rest > 0:
            thoughts.append(T(Sub, (l_rest, r_rest)))

        return thoughts

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(max_num):
            for right in range(left + 1):
                args.append((left, right))
        return args


class Mul(Problem):
    """"""Multiplication
    E.g.,
        # Memorize trivial cases
        <GO>3*4=12<STOP>
        <GO>37284*1=37284<STOP>
        <GO>0*748=0<STOP>

        # Solve recursively
        <GO>123*45=
            <GO>123*5=615<STOP>
            <GO>123*4=492<STOP>
            <GO>4920+615=5535<STOP>
            5535<STOP>
    """"""
    name = 'Mul'
    dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2}
    }
    symbols = ['*']

    def generate(self):
        # Generate [0, 999...999]
        max_digits = self.config['max_digits']
        max_num = 10 ** max_digits
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}*{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left * right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 1 or right <= 1:
            return []
        if left <= 9 and right <= 9:
            return []

        thoughts = []
        if right < 10:
            thoughts.append(T(Mul, (left % 10, right)))
            thoughts.append(T(Mul, (left // 10, right)))

            a1 = (left % 10) * right
            a2 = (left // 10) * right
            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        else:
            a1 = left * (right % 10)
            thoughts.append(T(Mul, (left, right % 10)))

            a2 = left * (right // 10)
            thoughts.append(T(Mul, (left, right // 10)))

            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        return thoughts


class Div(Problem):
    """"""Integer division
    E.g.,
        # Memorize trivial case
        <GO>173=5<R>2<STOP>
        <GO>24534=
            <GO>245<VS>34=<GT><STOP>
            <GO>245<VS>340=<LT><STOP>
            <GO>245-34=211<STOP>
            <GO>21134=6<R>7<STOP>
            <GO>6+1=7<STOP>
            7<R>7<STOP>
        <GO>228534=
            <GO>2285<VS>34=<GT><STOP>
            <GO>2285<VS>340=<GT><STOP>
            <GO>22834=6<R>24<STOP>
            <GO>24534=7<R>7<STOP>
            67<R>7<STOP>
    """"""
    name = 'Div'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Sub: lambda config: config,
    }
    symbols = ['', '<R>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        divisor = self.log_randrange(1, max_num)
        quotient = self.log_randrange(0, (max_num - 1) / divisor)
        max_remainder = min(divisor, max_num - quotient * divisor)
        remainder = self.log_randrange(0, max_remainder)
        dividend = divisor * quotient + remainder
        return dividend, divisor

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left // right}<R>{left % right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args
        thoughts = [T(Compare, (left, right))]

        # Base cases
        if left <= right:
            return thoughts

        thoughts.append(T(Compare, (left, right * 10)))
        if left <= right * 10:
            diff = left - right
            thoughts.append(T(Sub, (left, right)))
            thoughts.append(T(Div, (diff, right)))
        else:
            thoughts.append(T(Div, (left // 10, right)))
            left_remainder = (left // 10) % right * 10 + left % 10
            thoughts.append(T(Div, (left_remainder, right)))
        return thoughts

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(0, max_num):
            for right in range(1, max_num):
                args.append((left, right))
        return args


class Gcd(Problem):
    """"""Greatest Common Divisor
    E.g.,
        # Base case
        <GO>72<GCD>36=
            <GO>72<VS>36=<GT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>72=
            <GO>36<VS>72=<LT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>36=
            <GO>36<VS>36=<EQ><STOP>
            36<STOP>

        # Solve recursively
        <GO>78696<GCD>19332=
            <GO>78696<VS>19332=<GT><STOP>
            <GO>7869619332=4<R>1368<STOP>
            <GO>19332<GCD>1368=36<STOP>
            36<STOP>
    """"""
    name = 'Gcd'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Div: lambda config: config,
    }
    symbols = ['<GCD>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)

        if random.random() < 0.85:
            left = cd * self.log_randrange(1, max_num // cd + 1)
            right = cd * self.log_randrange(1, max_num // cd + 1)
        else:
            left = right = cd

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<GCD>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{math.gcd(left, right)}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left == right:
            return thoughts
        elif left < right:
            left, right = right, left

        thoughts.append(T(Div, (left, right)))

        rest = left % right
        # Except base case
        if rest != 0:
            thoughts.append(T(Gcd, (right, rest)))

        return thoughts


class Lcm(Problem):
    """"""Least Common Multiple
    E.g.,
        <GO>36<LCM>72=
            <GO>36<GCD>72=36<STOP>
            <GO>3636=1<R>0<STOP>
            <GO>1*72=72<STOP>
            72<STOP>
        <GO>78696<LCM>19332=
            <GO>78696<GCD>19332=36<STOP>
            <GO>7869636=2186<R>0<STOP>
            <GO>2186*19332=42259752<STOP>
            42259752<STOP>
    """"""
    name = 'Lcm'
    dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
        Mul: lambda config: config,
    }
    symbols = ['<LCM>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)
        left = cd * random.randrange(1, max_num // cd + 1)
        right = cd * random.randrange(1, max_num // cd + 1)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<LCM>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{math.lcm(left, right)}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [
            T(Gcd, (left, right)),
            T(Div, (left, math.gcd(left, right))),
            T(Mul, (left // math.gcd(left, right), right))
        ]

        return thoughts


class Reduce(Problem):
    """"""Make a fraction irreducible
    E.g.,
        <GO><REDUCE>10/5=
            <GO>10<GCD>5=5<STOP>
            <GO>105=2<R>0<STOP>
            <GO>55=1<R>0<STOP>
            <GO>1<VS>1=<EQ>
            2<STOP>
        <GO><REDUCE>10/4=
            <GO>10<GCD>4=2<STOP>
            <GO>102=5<R>0<STOP>
            <GO>42=2<R>0<STOP>
            <GO>2<VS>1=<GT>
            5/2<STOP>
        <GO><REDUCE>10/3=
            <GO>10<GCD>3=1<STOP>
            <GO>101=10<R>0<STOP>
            <GO>31=3<R>0<STOP>
            <GO>3<VS>1=<GT>
            10/3<STOP>
        # trivial case
        <GO><REDUCE>10/1=
            10<STOP>
        <GO><REDUCE>0/23=
            0<STOP>
    """"""
    name = 'Reduce'
    dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
    }
    symbols = ['<REDUCE>', '/']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        rand = random.random()
        if rand < 0.65:
            cd = self.log_randrange(1, max_num)
            numer = cd * random.randrange(1, max_num // cd + 1)
            denom = cd * random.randrange(1, max_num // cd + 1)
        elif rand < 0.7:
            numer = self.log_randrange(0, max_num)
            denom = 1
        else:
            numer = self.log_randrange(0, max_num)
            denom = self.log_randrange(1, max_num)
        return numer, denom

    @staticmethod
    def question(args):
        numer, denom = args
        return f'<GO><REDUCE>{numer}/{denom}='

    @staticmethod
    def answer(args):
        return frac_to_str(args, reduce=True)

    @staticmethod
    def thought(args) -> list[T]:
        numer, denom = args

        # Trivial case
        if denom == 1:
            return []
        if numer == 0:
            return []

        return [T(Gcd, (numer, denom)),
                T(Div, (numer, math.gcd(numer, denom))),
                T(Div, (denom, math.gcd(numer, denom)))]

    @staticmethod
    def get_answer(args):
        numer, denom = args

        if numer == 0:
            return 0, 1

        gcd = math.gcd(numer, denom)
        numer = numer // gcd
        denom = denom // gcd

        if denom < 0:
            numer = -numer
            denom = -denom

        return numer, denom


class Sub_pos_int(Problem):
    """"""Subtraction of two positive integers including smaller - larger
    E.g.
        <GO>441<SUB_POS_INT>383=
            <GO>441<VS>383=<GT><STOP>
            <GO>441-383=62<STOP>
            62<STOP>
        <GO>383<SUB_POS_INT>441=
            <GO>383<VS>441=<LT><STOP>
            <GO>441-383=62<STOP>
            -62<STOP>
        <GO>383<SUB_POS_INT>383=
            <GO>383<VS>383=<EQ><STOP>
            0<STOP>
    """"""

    name = 'Sub_pos_int'
    dependencies = {
        Sub: lambda config: config,
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
    }

    symbols = ['<SUB_POS_INT>', '-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<SUB_POS_INT>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left != right:
            thoughts.append(T(Sub, (max(left, right), min(left, right))))

        return thoughts


class Add_frac(Problem):
    """"""Fraction Addition
    E.g.,
        <GO>23/10<ADD_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322+60=382<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>382/140=191/70<STOP>
            191/70<STOP>

        <GO>23/10<ADD_FRAC>6=
            <GO>23/10<ADD_FRAC>6/1=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23/10=
            <GO>6/1<ADD_FRAC>23/10=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23=
            <GO>6+23=29
            29<STOP>
    """"""
    name = 'Add_frac'
    dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2},
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<ADD_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<ADD_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<ADD_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return Add.answer(args)
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom + numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * denom + numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

        return frac_to_str((numer, denom), reduce=True)

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Add, (left, right))]

        elif isinstance(left, int):
            return [T(Add_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Add_frac, (left, (right, 1)))]

        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Add, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]


class Sub_frac(Problem):
    """"""Subtraction of two positive fractions
    E.g.,
        <GO>23/10<SUB_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322<SUB_POS_INT>60=262<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            131/70<STOP>

        <GO>6/14<SUB_FRAC>23/10=
            <GO>6*10=60<STOP>
            <GO>23*14=322<STOP>
            <GO>60<SUB_POS_INT>322=-262<STOP>
            <GO>14*10=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            -131/70<STOP>

        <GO>6/14<SUB_FRAC>3/7=
            <GO>6*7=42<STOP>
            <GO>3*14=42<STOP>
            <GO>42<SUB_POS_INT>42=0<STOP>
            0<STOP>

        <GO>23/10<SUB_FRAC>6=
            <GO>23/10<SUB_FRAC>6/1=-37/10<STOP>
            -37/10<STOP><STOP>

        <GO>6<SUB_FRAC>23/10=
            <GO>6/1<SUB_FRAC>23/10<STOP>
            37/10<STOP>

        <GO>6<SUB_FRAC>23=
            <GO>6<SUB_POS_INT>23=-17<STOP>
            -17<STOP>
        <GO>23<SUB_FRAC>6=
            <GO>23<SUB_POS_INT>6=17<STOP>
            17<STOP>
    """"""
    name = 'Sub_frac'
    dependencies = {
        Mul: lambda config: config,
        Sub_pos_int: lambda config: {'max_digits': config['max_digits'] * 2},
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<SUB_FRAC>', '-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<SUB_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<SUB_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        return f'{frac_to_str(Sub_frac.get_answer(args))}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Sub_pos_int, (left, right))]
        elif isinstance(left, int):
            return [T(Sub_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Sub_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Sub_pos_int, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (abs(numer), denom))]

    @staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer =  left - right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom - numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = numer_left - right * denom
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

        return Reduce.get_answer((numer, denom))


class Mul_frac(Problem):
    """"""Fraction Multiplication
    E.g.,
        <GO>105/10<MUL_FRAC>6/14=
            <GO>105*6=630<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>630/140=9/2<STOP>
            9/2<STOP>

        <GO>105/10<MUL_FRAC>6=
            <GO>105/10<MUL_FRAC>6/1=63<STOP>
            63<STOP>

        <GO>105<MUL_FRAC>6/14=
            <GO>105/1<MUL_FRAC>6/14=45<STOP>
            45<STOP>

        <GO>105<MUL_FRAC>6=
            <GO>105*6=630<STOP>
            630<STOP>
    """"""
    name = 'Mul_frac'
    dependencies = {
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<MUL_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(0, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<MUL_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<MUL_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        return f'{frac_to_str(Mul_frac.get_answer(args))}<STOP>'

    @staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0 or right == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Mul, (left, right))]
        elif isinstance(left, int):
            return [T(Mul_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Mul_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, numer_right)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]

    @staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left * right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

        if numer == 0:
            return 0

        return Reduce.get_answer((numer, denom))


class Div_frac(Problem):
    """"""Division between two positive fractions
    E.g.,
        <GO>23/25<DIV_FRAC>6/45=
            <GO>23/25<MUL_FRAC>45/6=345/52<STOP>
            345/52<STOP>

        <GO>23/25<DIV_FRAC>2=
            <GO>23/25<DIV_FRAC>2/1=23/50<STOP>
            23/50<STOP>

        <GO>2<DIV_FRAC>23/25=
            <GO>2/1<DIV_FRAC>23/25<STOP>
            50/23<STOP>

        <GO>23<DIV_FRAC>6=
            <GO><REDUCE>23/6=23/6<STOP>
            23/6<STOP>
    """"""
    name = 'Div_frac'
    dependencies = {
        Reduce: lambda config: config,
        Mul_frac: lambda config: config,
    }
    symbols = ['<DIV_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<DIV_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<DIV_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        return f'{frac_to_str(Div_frac.get_answer(args))}<STOP>'

    @staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Reduce, (left, right))]

        elif isinstance(left, int):
            return [T(Div_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Div_frac, (left, (right, 1)))]
        else:
            numer_right, denom_right = right
            return [T(Mul_frac, (left, (denom_right, numer_right)))]

    @staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left
            denom = right
        elif isinstance(left, int):
            numer_right, denom_right = right
            numer = left * denom_right
            denom = numer_right
        elif isinstance(right, int):
            numer_left, denom_left = left
            numer = numer_left
            denom = denom_left * right
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * denom_right
            denom = denom_left * numer_right

        if numer == 0:
            return 0, 1

        return Reduce.get_answer((numer, denom))


class Operations(Problem):
    """"""Extension of Four Fundamental Arithmetic Operations to Negative Number
    E.g.,
        # Each operands can be an integer or an fraction
        <GO>23<ADD>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<ADD>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<ADD>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<ADD>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<SUB>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<SUB>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<SUB>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<SUB>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>
        <GO>-23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>-23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>

        <GO>23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
        <GO>-23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>-23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
    """"""
    name = 'Operations'
    dependencies = {
        Add_frac: lambda config: config,
        Sub_frac: lambda config: config,
        Mul_frac: lambda config: config,
        Div_frac: lambda config: config,
    }
    symbols = ['<ADD>', '<SUB>', '<MUL>', '<DIV>', '-', '/']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        prob = random.sample(('Add', 'Sub', 'Mul', 'Div'), 1)[0]
        # prob = random.sample(('Add', 'Sub'), 1)[0]

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            left = negate_frac(left)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            if prob == 'Div':
                right = self.log_randrange(1, max_num)
            else:
                right = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            right = negate_frac(right)

        return prob, left, right

    @staticmethod
    def question(args):
        prob, left, right = args

        q_list = ['<GO>']

        if isinstance(left, int):
            q_list.append(f'{left}')
        else:
            numer_left, denom_left = left
            q_list.append(f'{numer_left}/{denom_left}')

        q_list.append(f'<{prob.upper()}>')

        if isinstance(right, int):
            q_list.append(f'{right}')
        else:
            numer_right, denom_right = right
            q_list.append(f'{numer_right}/{denom_right}')

        q_list.append('=')

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        prob, left, right = args

        if prob == 'Add':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left + right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom + numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left + right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right + numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Sub':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left - right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom - numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left - right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right - numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Mul':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left * right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * numer_right
                denom = denom_left * denom_right

        else:
            if isinstance(left, int) and isinstance(right, int):
                numer = left
                denom = right
            elif isinstance(left, int):
                numer_right, denom_right = right
                numer = left * denom_right
                denom = numer_right
            elif isinstance(right, int):
                numer_left, denom_left = left
                numer = numer_left
                denom = denom_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right
                denom = denom_left * numer_right

        return f'{frac_to_str((numer, denom), reduce=True)}<STOP>'


    @staticmethod
    def thought(args) -> list[T]:
        prob, left, right = args

        if prob == 'Add':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Sub':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Mul':
            thoughts = [T(Mul_frac, (abs_frac(left), abs_frac(right)))]

        else:
            thoughts = [T(Div_frac, (abs_frac(left), abs_frac(right)))]

        return thoughts


def is_frac_neg(arg):
    if isinstance(arg, int):
        return arg < 0
    else:
        return arg[0] < 0

def negate_frac(arg):
    if isinstance(arg, int):
        return -arg
    else:
        return -arg[0], arg[1]

def abs_frac(arg):
    if isinstance(arg, int):
        return abs(arg)
    else:
        return abs(arg[0]), arg[1]

def frac_to_str(frac, reduce=False):
    if isinstance(frac, int):
        return f'{frac}'

    if reduce:
        numer, denom = Reduce.get_answer(frac)
    else:
        numer, denom = frac

    if denom == 1:
        return f'{numer}'
    else:
        return f'{numer}/{denom}'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,,NA,Previous sibling does not exist,"import math
import random
from .problem import Problem, T","(0, 0)","(1342, 33)",N,module,module,,10462,57046d33-e404-4915-a990-7da1b34ff573
"import math
import random
from .problem import Problem, T",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,Previous sibling does not exist,"class Compare(Problem):
    """"""Compare two numbers
    E.g.,
        <GO>123<VS>234=<LT><STOP>
        <GO>84<VS>2=<GT><STOP>
        <GO>74<VS>74=<EQ><STOP>
        <GO>73847<VS>7243=<GT><STOP>
        <GO>73847<VS>73413=
            <GO>7<VS>7=<EQ><STOP>
            <GO>3847<VS>3413=<GT><STOP>
            <GT><STOP>
    """"""

    name = 'Compare'
    dependencies = {}
    symbols = ['<VS>', '<GT>', '<LT>', '<EQ>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        smaller = random.randrange(0, max_num)
        larger = random.randrange(0, max_num)
        if random.random() < 0.5:
            return smaller, larger
        else:
            return larger, smaller

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<VS>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        if left > right:
            return '<GT><STOP>'
        elif left < right:
            return '<LT><STOP>'
        else:
            return '<EQ><STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        thoughts = []
        digit_l, digit_r = len(str(left)), len(str(right))
        if digit_l == digit_r:
            # Compare first digit
            l_first, r_first = int(str(left)[0]), int(str(right)[0])
            thoughts.append(T(Compare, (l_first, r_first)))
            if l_first == r_first:
                # Compare the rest
                l_rest = int(str(left)[1:])
                r_rest = int(str(right)[1:])
                thoughts.append(T(Compare, (l_rest, r_rest)))

        return thoughts","(0, 0)","(3, 31)",N,"import_statement,import_statement,import_from_statement",import_statement,,11,c413a0cb-1f13-4f16-aede-df93d1354c47
"class Compare(Problem):
    """"""Compare two numbers
    E.g.,
        <GO>123<VS>234=<LT><STOP>
        <GO>84<VS>2=<GT><STOP>
        <GO>74<VS>74=<EQ><STOP>
        <GO>73847<VS>7243=<GT><STOP>
        <GO>73847<VS>73413=
            <GO>7<VS>7=<EQ><STOP>
            <GO>3847<VS>3413=<GT><STOP>
            <GT><STOP>
    """"""

    name = 'Compare'
    dependencies = {}
    symbols = ['<VS>', '<GT>', '<LT>', '<EQ>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        smaller = random.randrange(0, max_num)
        larger = random.randrange(0, max_num)
        if random.random() < 0.5:
            return smaller, larger
        else:
            return larger, smaller

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<VS>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        if left > right:
            return '<GT><STOP>'
        elif left < right:
            return '<LT><STOP>'
        else:
            return '<EQ><STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        thoughts = []
        digit_l, digit_r = len(str(left)), len(str(right))
        if digit_l == digit_r:
            # Compare first digit
            l_first, r_first = int(str(left)[0]), int(str(right)[0])
            thoughts.append(T(Compare, (l_first, r_first)))
            if l_first == r_first:
                # Compare the rest
                l_rest = int(str(left)[1:])
                r_rest = int(str(right)[1:])
                thoughts.append(T(Compare, (l_rest, r_rest)))

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"import math
import random
from .problem import Problem, T","class Add(Problem):
    """"""Addition of two positive integers
    E.g.,
        # Without carry
        <GO>31+28=
            <GO>1+8=9<STOP>
            <GO>3+2=5<STOP>
            59<STOP>

        # With carry
        <GO>39+28=
            <GO>9+8=17<STOP>
            <GO>3+1=4<STOP>
            <GO>4+2=6<STOP>
            67<STOP>

        # Solve recursively
        <GO>394+281=
            <GO>4+1=5<STOP>
            <GO>39+28=67<STOP>
            675<STOP>
    """"""
    name = 'Add'
    dependencies = {}
    symbols = ['+']

    def generate(self):
        # Generate [0, 999...999]
        max_num = 10 ** self.config['max_digits']
        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}+{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left + right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        l_last, r_last = left % 10, right % 10
        thoughts = [T(Add, (l_last, r_last))]

        l_rest, r_rest = left // 10, right // 10
        if l_last + r_last >= 10:
            thoughts.append(T(Add, (l_rest, 1)))
            l_rest += 1

        if l_rest > 0 and r_rest > 0:
            thoughts.append(T(Add, (l_rest, r_rest)))

        return thoughts","(6, 0)","(67, 23)",N,class_definition,Compare,,456,06bf780e-9422-4961-91ac-aa2ca5acf7f5
"def generate(self):
        max_num = 10 ** self.config['max_digits']
        smaller = random.randrange(0, max_num)
        larger = random.randrange(0, max_num)
        if random.random() < 0.5:
            return smaller, larger
        else:
            return larger, smaller",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Compare/,Compare,"symbols = ['<VS>', '<GT>', '<LT>', '<EQ>']","@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<VS>{right}='","(23, 4)","(30, 34)",N,function_definition,generate,,64,7a01b5f4-d9d5-45f0-9bb8-d6a7713befeb
"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<VS>{right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Compare/,Compare,"def generate(self):
        max_num = 10 ** self.config['max_digits']
        smaller = random.randrange(0, max_num)
        larger = random.randrange(0, max_num)
        if random.random() < 0.5:
            return smaller, larger
        else:
            return larger, smaller","@staticmethod
    def answer(args):
        left, right = args
        if left > right:
            return '<GT><STOP>'
        elif left < right:
            return '<LT><STOP>'
        else:
            return '<EQ><STOP>'","(32, 4)","(35, 40)",N,function_definition,"def question(args):
        left, right = args
        return f'<GO>{left}<VS>{right}='",,28,3263793b-eddd-4ee4-b29b-4188e340b6c8
"@staticmethod
    def answer(args):
        left, right = args
        if left > right:
            return '<GT><STOP>'
        elif left < right:
            return '<LT><STOP>'
        else:
            return '<EQ><STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Compare/,Compare,"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<VS>{right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        thoughts = []
        digit_l, digit_r = len(str(left)), len(str(right))
        if digit_l == digit_r:
            # Compare first digit
            l_first, r_first = int(str(left)[0]), int(str(right)[0])
            thoughts.append(T(Compare, (l_first, r_first)))
            if l_first == r_first:
                # Compare the rest
                l_rest = int(str(left)[1:])
                r_rest = int(str(right)[1:])
                thoughts.append(T(Compare, (l_rest, r_rest)))

        return thoughts","(37, 4)","(45, 31)",N,function_definition,"def answer(args):
        left, right = args
        if left > right:
            return '<GT><STOP>'
        elif left < right:
            return '<LT><STOP>'
        else:
            return '<EQ><STOP>'",,51,0a11fd34-c9c6-4b50-8fb3-f12e16946d63
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        thoughts = []
        digit_l, digit_r = len(str(left)), len(str(right))
        if digit_l == digit_r:
            # Compare first digit
            l_first, r_first = int(str(left)[0]), int(str(right)[0])
            thoughts.append(T(Compare, (l_first, r_first)))
            if l_first == r_first:
                # Compare the rest
                l_rest = int(str(left)[1:])
                r_rest = int(str(right)[1:])
                thoughts.append(T(Compare, (l_rest, r_rest)))

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Compare/,Compare,"@staticmethod
    def answer(args):
        left, right = args
        if left > right:
            return '<GT><STOP>'
        elif left < right:
            return '<LT><STOP>'
        else:
            return '<EQ><STOP>'",Next sibling does not exist,"(47, 4)","(67, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        thoughts = []
        digit_l, digit_r = len(str(left)), len(str(right))
        if digit_l == digit_r:
            # Compare first digit
            l_first, r_first = int(str(left)[0]), int(str(right)[0])
            thoughts.append(T(Compare, (l_first, r_first)))
            if l_first == r_first:
                # Compare the rest
                l_rest = int(str(left)[1:])
                r_rest = int(str(right)[1:])
                thoughts.append(T(Compare, (l_rest, r_rest)))

        return thoughts",,156,600e042e-aeb4-4849-94dc-1365fb38439e
"class Add(Problem):
    """"""Addition of two positive integers
    E.g.,
        # Without carry
        <GO>31+28=
            <GO>1+8=9<STOP>
            <GO>3+2=5<STOP>
            59<STOP>

        # With carry
        <GO>39+28=
            <GO>9+8=17<STOP>
            <GO>3+1=4<STOP>
            <GO>4+2=6<STOP>
            67<STOP>

        # Solve recursively
        <GO>394+281=
            <GO>4+1=5<STOP>
            <GO>39+28=67<STOP>
            675<STOP>
    """"""
    name = 'Add'
    dependencies = {}
    symbols = ['+']

    def generate(self):
        # Generate [0, 999...999]
        max_num = 10 ** self.config['max_digits']
        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}+{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left + right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        l_last, r_last = left % 10, right % 10
        thoughts = [T(Add, (l_last, r_last))]

        l_rest, r_rest = left // 10, right // 10
        if l_last + r_last >= 10:
            thoughts.append(T(Add, (l_rest, 1)))
            l_rest += 1

        if l_rest > 0 and r_rest > 0:
            thoughts.append(T(Add, (l_rest, r_rest)))

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Compare(Problem):
    """"""Compare two numbers
    E.g.,
        <GO>123<VS>234=<LT><STOP>
        <GO>84<VS>2=<GT><STOP>
        <GO>74<VS>74=<EQ><STOP>
        <GO>73847<VS>7243=<GT><STOP>
        <GO>73847<VS>73413=
            <GO>7<VS>7=<EQ><STOP>
            <GO>3847<VS>3413=<GT><STOP>
            <GT><STOP>
    """"""

    name = 'Compare'
    dependencies = {}
    symbols = ['<VS>', '<GT>', '<LT>', '<EQ>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        smaller = random.randrange(0, max_num)
        larger = random.randrange(0, max_num)
        if random.random() < 0.5:
            return smaller, larger
        else:
            return larger, smaller

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<VS>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        if left > right:
            return '<GT><STOP>'
        elif left < right:
            return '<LT><STOP>'
        else:
            return '<EQ><STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        thoughts = []
        digit_l, digit_r = len(str(left)), len(str(right))
        if digit_l == digit_r:
            # Compare first digit
            l_first, r_first = int(str(left)[0]), int(str(right)[0])
            thoughts.append(T(Compare, (l_first, r_first)))
            if l_first == r_first:
                # Compare the rest
                l_rest = int(str(left)[1:])
                r_rest = int(str(right)[1:])
                thoughts.append(T(Compare, (l_rest, r_rest)))

        return thoughts","class Sub(Problem):
    """"""Subtraction of two positive integers
    E.g.,
        # Memorize trivial case
        <GO>14-8=6<STOP>

        # Without borrow
        <GO>445-283=
            <GO>15-3=12<STOP>
            <GO>44-28=16<STOP>
            162<STOP>

        # With borrow
        <GO>441-383=
            <GO>11-3=8<STOP>
            <GO>44-1=43<STOP>
            <GO>43-38=5<STOP>
            162<STOP>
    """"""

    name = 'Sub'
    dependencies = {}
    symbols = ['-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)

        if left < right:
            return right, left
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}-{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 19 and right <= 9:
            return []

        l_last = left % 10 + 10
        r_last = right % 10
        thoughts = [T(Sub, (l_last, r_last))]
        l_rest, r_rest = left // 10, right // 10
        if l_last - r_last < 10:
            thoughts.append(T(Sub, (l_rest, 1)))
            l_rest -= 1
        if r_rest > 0:
            thoughts.append(T(Sub, (l_rest, r_rest)))

        return thoughts

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(max_num):
            for right in range(left + 1):
                args.append((left, right))
        return args","(70, 0)","(132, 23)",N,class_definition,Add,,444,70ef9bef-625c-4722-b67a-e25747de7ef2
"def generate(self):
        # Generate [0, 999...999]
        max_num = 10 ** self.config['max_digits']
        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)
        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Add/,Add,symbols = ['+'],"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}+{right}='","(96, 4)","(101, 26)",N,function_definition,generate,,55,4686183e-62b6-49ac-96f2-488ac23f56ac
"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}+{right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Add/,Add,"def generate(self):
        # Generate [0, 999...999]
        max_num = 10 ** self.config['max_digits']
        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)
        return left, right","@staticmethod
    def answer(args):
        left, right = args
        return f'{left + right}<STOP>'","(103, 4)","(106, 37)",N,function_definition,"def question(args):
        left, right = args
        return f'<GO>{left}+{right}='",,28,20b58bdc-d81e-4ddc-b664-eb49ae4f8730
"@staticmethod
    def answer(args):
        left, right = args
        return f'{left + right}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Add/,Add,"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}+{right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        l_last, r_last = left % 10, right % 10
        thoughts = [T(Add, (l_last, r_last))]

        l_rest, r_rest = left // 10, right // 10
        if l_last + r_last >= 10:
            thoughts.append(T(Add, (l_rest, 1)))
            l_rest += 1

        if l_rest > 0 and r_rest > 0:
            thoughts.append(T(Add, (l_rest, r_rest)))

        return thoughts","(108, 4)","(111, 38)",N,function_definition,"def answer(args):
        left, right = args
        return f'{left + right}<STOP>'",,25,2f715d34-f7c0-48d5-bb84-f30e0de38ff2
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        l_last, r_last = left % 10, right % 10
        thoughts = [T(Add, (l_last, r_last))]

        l_rest, r_rest = left // 10, right // 10
        if l_last + r_last >= 10:
            thoughts.append(T(Add, (l_rest, 1)))
            l_rest += 1

        if l_rest > 0 and r_rest > 0:
            thoughts.append(T(Add, (l_rest, r_rest)))

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Add/,Add,"@staticmethod
    def answer(args):
        left, right = args
        return f'{left + right}<STOP>'",Next sibling does not exist,"(113, 4)","(132, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        l_last, r_last = left % 10, right % 10
        thoughts = [T(Add, (l_last, r_last))]

        l_rest, r_rest = left // 10, right // 10
        if l_last + r_last >= 10:
            thoughts.append(T(Add, (l_rest, 1)))
            l_rest += 1

        if l_rest > 0 and r_rest > 0:
            thoughts.append(T(Add, (l_rest, r_rest)))

        return thoughts",,152,3d4e0069-9ccd-41d2-8c52-28b5a7c054eb
"class Sub(Problem):
    """"""Subtraction of two positive integers
    E.g.,
        # Memorize trivial case
        <GO>14-8=6<STOP>

        # Without borrow
        <GO>445-283=
            <GO>15-3=12<STOP>
            <GO>44-28=16<STOP>
            162<STOP>

        # With borrow
        <GO>441-383=
            <GO>11-3=8<STOP>
            <GO>44-1=43<STOP>
            <GO>43-38=5<STOP>
            162<STOP>
    """"""

    name = 'Sub'
    dependencies = {}
    symbols = ['-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)

        if left < right:
            return right, left
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}-{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 19 and right <= 9:
            return []

        l_last = left % 10 + 10
        r_last = right % 10
        thoughts = [T(Sub, (l_last, r_last))]
        l_rest, r_rest = left // 10, right // 10
        if l_last - r_last < 10:
            thoughts.append(T(Sub, (l_rest, 1)))
            l_rest -= 1
        if r_rest > 0:
            thoughts.append(T(Sub, (l_rest, r_rest)))

        return thoughts

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(max_num):
            for right in range(left + 1):
                args.append((left, right))
        return args",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Add(Problem):
    """"""Addition of two positive integers
    E.g.,
        # Without carry
        <GO>31+28=
            <GO>1+8=9<STOP>
            <GO>3+2=5<STOP>
            59<STOP>

        # With carry
        <GO>39+28=
            <GO>9+8=17<STOP>
            <GO>3+1=4<STOP>
            <GO>4+2=6<STOP>
            67<STOP>

        # Solve recursively
        <GO>394+281=
            <GO>4+1=5<STOP>
            <GO>39+28=67<STOP>
            675<STOP>
    """"""
    name = 'Add'
    dependencies = {}
    symbols = ['+']

    def generate(self):
        # Generate [0, 999...999]
        max_num = 10 ** self.config['max_digits']
        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}+{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left + right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left < 10 and right < 10:
            return []

        l_last, r_last = left % 10, right % 10
        thoughts = [T(Add, (l_last, r_last))]

        l_rest, r_rest = left // 10, right // 10
        if l_last + r_last >= 10:
            thoughts.append(T(Add, (l_rest, 1)))
            l_rest += 1

        if l_rest > 0 and r_rest > 0:
            thoughts.append(T(Add, (l_rest, r_rest)))

        return thoughts","class Mul(Problem):
    """"""Multiplication
    E.g.,
        # Memorize trivial cases
        <GO>3*4=12<STOP>
        <GO>37284*1=37284<STOP>
        <GO>0*748=0<STOP>

        # Solve recursively
        <GO>123*45=
            <GO>123*5=615<STOP>
            <GO>123*4=492<STOP>
            <GO>4920+615=5535<STOP>
            5535<STOP>
    """"""
    name = 'Mul'
    dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2}
    }
    symbols = ['*']

    def generate(self):
        # Generate [0, 999...999]
        max_digits = self.config['max_digits']
        max_num = 10 ** max_digits
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}*{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left * right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 1 or right <= 1:
            return []
        if left <= 9 and right <= 9:
            return []

        thoughts = []
        if right < 10:
            thoughts.append(T(Mul, (left % 10, right)))
            thoughts.append(T(Mul, (left // 10, right)))

            a1 = (left % 10) * right
            a2 = (left // 10) * right
            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        else:
            a1 = left * (right % 10)
            thoughts.append(T(Mul, (left, right % 10)))

            a2 = left * (right // 10)
            thoughts.append(T(Mul, (left, right // 10)))

            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        return thoughts","(135, 0)","(205, 19)",N,class_definition,Sub,,465,d9e59fd9-7bf8-4591-b32f-c860f04d6e65
"def generate(self):
        max_num = 10 ** self.config['max_digits']

        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)

        if left < right:
            return right, left
        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub/,Sub,symbols = ['-'],"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}-{right}='","(159, 4)","(167, 26)",N,function_definition,generate,,56,457908ca-6621-4c7b-8cdf-ae8c1040d4c1
"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}-{right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub/,Sub,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)

        if left < right:
            return right, left
        return left, right","@staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'","(169, 4)","(172, 37)",N,function_definition,"def question(args):
        left, right = args
        return f'<GO>{left}-{right}='",,26,2a742d7e-c012-43d9-a559-bc43ba8b2769
"@staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub/,Sub,"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}-{right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 19 and right <= 9:
            return []

        l_last = left % 10 + 10
        r_last = right % 10
        thoughts = [T(Sub, (l_last, r_last))]
        l_rest, r_rest = left // 10, right // 10
        if l_last - r_last < 10:
            thoughts.append(T(Sub, (l_rest, 1)))
            l_rest -= 1
        if r_rest > 0:
            thoughts.append(T(Sub, (l_rest, r_rest)))

        return thoughts","(174, 4)","(177, 38)",N,function_definition,"def answer(args):
        left, right = args
        return f'{left - right}<STOP>'",,25,f6b6d364-68c1-43af-b375-2e473045dcc4
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 19 and right <= 9:
            return []

        l_last = left % 10 + 10
        r_last = right % 10
        thoughts = [T(Sub, (l_last, r_last))]
        l_rest, r_rest = left // 10, right // 10
        if l_last - r_last < 10:
            thoughts.append(T(Sub, (l_rest, 1)))
            l_rest -= 1
        if r_rest > 0:
            thoughts.append(T(Sub, (l_rest, r_rest)))

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub/,Sub,"@staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'","def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(max_num):
            for right in range(left + 1):
                args.append((left, right))
        return args","(179, 4)","(197, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 19 and right <= 9:
            return []

        l_last = left % 10 + 10
        r_last = right % 10
        thoughts = [T(Sub, (l_last, r_last))]
        l_rest, r_rest = left // 10, right // 10
        if l_last - r_last < 10:
            thoughts.append(T(Sub, (l_rest, 1)))
            l_rest -= 1
        if r_rest > 0:
            thoughts.append(T(Sub, (l_rest, r_rest)))

        return thoughts",,146,fc244ba4-15f2-482a-860f-faec6fa2f332
"def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(max_num):
            for right in range(left + 1):
                args.append((left, right))
        return args",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub/,Sub,"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 19 and right <= 9:
            return []

        l_last = left % 10 + 10
        r_last = right % 10
        thoughts = [T(Sub, (l_last, r_last))]
        l_rest, r_rest = left // 10, right // 10
        if l_last - r_last < 10:
            thoughts.append(T(Sub, (l_rest, 1)))
            l_rest -= 1
        if r_rest > 0:
            thoughts.append(T(Sub, (l_rest, r_rest)))

        return thoughts",Next sibling does not exist,"(199, 4)","(205, 19)",N,function_definition,enum_args,,51,d36a3b8d-2bac-49cc-8f39-65e622f813ec
"class Mul(Problem):
    """"""Multiplication
    E.g.,
        # Memorize trivial cases
        <GO>3*4=12<STOP>
        <GO>37284*1=37284<STOP>
        <GO>0*748=0<STOP>

        # Solve recursively
        <GO>123*45=
            <GO>123*5=615<STOP>
            <GO>123*4=492<STOP>
            <GO>4920+615=5535<STOP>
            5535<STOP>
    """"""
    name = 'Mul'
    dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2}
    }
    symbols = ['*']

    def generate(self):
        # Generate [0, 999...999]
        max_digits = self.config['max_digits']
        max_num = 10 ** max_digits
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}*{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left * right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 1 or right <= 1:
            return []
        if left <= 9 and right <= 9:
            return []

        thoughts = []
        if right < 10:
            thoughts.append(T(Mul, (left % 10, right)))
            thoughts.append(T(Mul, (left // 10, right)))

            a1 = (left % 10) * right
            a2 = (left // 10) * right
            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        else:
            a1 = left * (right % 10)
            thoughts.append(T(Mul, (left, right % 10)))

            a2 = left * (right // 10)
            thoughts.append(T(Mul, (left, right // 10)))

            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Sub(Problem):
    """"""Subtraction of two positive integers
    E.g.,
        # Memorize trivial case
        <GO>14-8=6<STOP>

        # Without borrow
        <GO>445-283=
            <GO>15-3=12<STOP>
            <GO>44-28=16<STOP>
            162<STOP>

        # With borrow
        <GO>441-383=
            <GO>11-3=8<STOP>
            <GO>44-1=43<STOP>
            <GO>43-38=5<STOP>
            162<STOP>
    """"""

    name = 'Sub'
    dependencies = {}
    symbols = ['-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        left = random.randrange(0, max_num)
        right = random.randrange(0, max_num)

        if left < right:
            return right, left
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}-{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 19 and right <= 9:
            return []

        l_last = left % 10 + 10
        r_last = right % 10
        thoughts = [T(Sub, (l_last, r_last))]
        l_rest, r_rest = left // 10, right // 10
        if l_last - r_last < 10:
            thoughts.append(T(Sub, (l_rest, 1)))
            l_rest -= 1
        if r_rest > 0:
            thoughts.append(T(Sub, (l_rest, r_rest)))

        return thoughts

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(max_num):
            for right in range(left + 1):
                args.append((left, right))
        return args","""""""Multiplication
    E.g.,
        # Memorize trivial cases
        <GO>3*4=12<STOP>
        <GO>37284*1=37284<STOP>
        <GO>0*748=0<STOP>

        # Solve recursively
        <GO>123*45=
            <GO>123*5=615<STOP>
            <GO>123*4=492<STOP>
            <GO>4920+615=5535<STOP>
            5535<STOP>
    """"""
name = 'Mul'
dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2}
    }
symbols = ['*']","(208, 0)","(273, 23)",N,class_definition,Mul,,502,f732cf61-bd8a-4ad0-8bc4-d0c2d92b94f9
"""""""Multiplication
    E.g.,
        # Memorize trivial cases
        <GO>3*4=12<STOP>
        <GO>37284*1=37284<STOP>
        <GO>0*748=0<STOP>

        # Solve recursively
        <GO>123*45=
            <GO>123*5=615<STOP>
            <GO>123*4=492<STOP>
            <GO>4920+615=5535<STOP>
            5535<STOP>
    """"""
name = 'Mul'
dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2}
    }
symbols = ['*']",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul/,Mul,Previous sibling does not exist,"def generate(self):
        # Generate [0, 999...999]
        max_digits = self.config['max_digits']
        max_num = 10 ** max_digits
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right","(209, 4)","(227, 19)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,147,5f9546db-e874-421a-82aa-993e2bba3fd3
"def generate(self):
        # Generate [0, 999...999]
        max_digits = self.config['max_digits']
        max_num = 10 ** max_digits
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul/,Mul,"""""""Multiplication
    E.g.,
        # Memorize trivial cases
        <GO>3*4=12<STOP>
        <GO>37284*1=37284<STOP>
        <GO>0*748=0<STOP>

        # Solve recursively
        <GO>123*45=
            <GO>123*5=615<STOP>
            <GO>123*4=492<STOP>
            <GO>4920+615=5535<STOP>
            5535<STOP>
    """"""
name = 'Mul'
dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2}
    }
symbols = ['*']","@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}*{right}='","(229, 4)","(235, 26)",N,function_definition,generate,,66,a0109b78-c5ad-40b7-be21-1174d15c58db
"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}*{right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul/,Mul,"def generate(self):
        # Generate [0, 999...999]
        max_digits = self.config['max_digits']
        max_num = 10 ** max_digits
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right","@staticmethod
    def answer(args):
        left, right = args
        return f'{left * right}<STOP>'","(237, 4)","(240, 37)",N,function_definition,"def question(args):
        left, right = args
        return f'<GO>{left}*{right}='",,27,8d5be57a-66cc-4ed4-8f97-15719313b881
"@staticmethod
    def answer(args):
        left, right = args
        return f'{left * right}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul/,Mul,"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}*{right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 1 or right <= 1:
            return []
        if left <= 9 and right <= 9:
            return []

        thoughts = []
        if right < 10:
            thoughts.append(T(Mul, (left % 10, right)))
            thoughts.append(T(Mul, (left // 10, right)))

            a1 = (left % 10) * right
            a2 = (left // 10) * right
            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        else:
            a1 = left * (right % 10)
            thoughts.append(T(Mul, (left, right % 10)))

            a2 = left * (right // 10)
            thoughts.append(T(Mul, (left, right // 10)))

            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        return thoughts","(242, 4)","(245, 38)",N,function_definition,"def answer(args):
        left, right = args
        return f'{left * right}<STOP>'",,25,492cfefa-24f0-45fd-a2b3-940521b3538d
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 1 or right <= 1:
            return []
        if left <= 9 and right <= 9:
            return []

        thoughts = []
        if right < 10:
            thoughts.append(T(Mul, (left % 10, right)))
            thoughts.append(T(Mul, (left // 10, right)))

            a1 = (left % 10) * right
            a2 = (left // 10) * right
            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        else:
            a1 = left * (right % 10)
            thoughts.append(T(Mul, (left, right % 10)))

            a2 = left * (right // 10)
            thoughts.append(T(Mul, (left, right // 10)))

            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul/,Mul,"@staticmethod
    def answer(args):
        left, right = args
        return f'{left * right}<STOP>'",Next sibling does not exist,"(247, 4)","(273, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 1 or right <= 1:
            return []
        if left <= 9 and right <= 9:
            return []

        thoughts = []
        if right < 10:
            thoughts.append(T(Mul, (left % 10, right)))
            thoughts.append(T(Mul, (left // 10, right)))

            a1 = (left % 10) * right
            a2 = (left // 10) * right
            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        else:
            a1 = left * (right % 10)
            thoughts.append(T(Mul, (left, right % 10)))

            a2 = left * (right // 10)
            thoughts.append(T(Mul, (left, right // 10)))

            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        return thoughts",,221,3b0b26b8-8ea6-4f30-aa7d-2156ff5fb7c8
"class Div(Problem):
    """"""Integer division
    E.g.,
        # Memorize trivial case
        <GO>173=5<R>2<STOP>
        <GO>24534=
            <GO>245<VS>34=<GT><STOP>
            <GO>245<VS>340=<LT><STOP>
            <GO>245-34=211<STOP>
            <GO>21134=6<R>7<STOP>
            <GO>6+1=7<STOP>
            7<R>7<STOP>
        <GO>228534=
            <GO>2285<VS>34=<GT><STOP>
            <GO>2285<VS>340=<GT><STOP>
            <GO>22834=6<R>24<STOP>
            <GO>24534=7<R>7<STOP>
            67<R>7<STOP>
    """"""
    name = 'Div'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Sub: lambda config: config,
    }
    symbols = ['', '<R>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        divisor = self.log_randrange(1, max_num)
        quotient = self.log_randrange(0, (max_num - 1) / divisor)
        max_remainder = min(divisor, max_num - quotient * divisor)
        remainder = self.log_randrange(0, max_remainder)
        dividend = divisor * quotient + remainder
        return dividend, divisor

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left // right}<R>{left % right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args
        thoughts = [T(Compare, (left, right))]

        # Base cases
        if left <= right:
            return thoughts

        thoughts.append(T(Compare, (left, right * 10)))
        if left <= right * 10:
            diff = left - right
            thoughts.append(T(Sub, (left, right)))
            thoughts.append(T(Div, (diff, right)))
        else:
            thoughts.append(T(Div, (left // 10, right)))
            left_remainder = (left // 10) % right * 10 + left % 10
            thoughts.append(T(Div, (left_remainder, right)))
        return thoughts

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(0, max_num):
            for right in range(1, max_num):
                args.append((left, right))
        return args",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Mul(Problem):
    """"""Multiplication
    E.g.,
        # Memorize trivial cases
        <GO>3*4=12<STOP>
        <GO>37284*1=37284<STOP>
        <GO>0*748=0<STOP>

        # Solve recursively
        <GO>123*45=
            <GO>123*5=615<STOP>
            <GO>123*4=492<STOP>
            <GO>4920+615=5535<STOP>
            5535<STOP>
    """"""
    name = 'Mul'
    dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2}
    }
    symbols = ['*']

    def generate(self):
        # Generate [0, 999...999]
        max_digits = self.config['max_digits']
        max_num = 10 ** max_digits
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}*{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left * right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        # Base cases
        if left <= 1 or right <= 1:
            return []
        if left <= 9 and right <= 9:
            return []

        thoughts = []
        if right < 10:
            thoughts.append(T(Mul, (left % 10, right)))
            thoughts.append(T(Mul, (left // 10, right)))

            a1 = (left % 10) * right
            a2 = (left // 10) * right
            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        else:
            a1 = left * (right % 10)
            thoughts.append(T(Mul, (left, right % 10)))

            a2 = left * (right // 10)
            thoughts.append(T(Mul, (left, right // 10)))

            thoughts.append(T(Add, (a2 * 10, a1), 'tail'))
        return thoughts","""""""Integer division
    E.g.,
        # Memorize trivial case
        <GO>173=5<R>2<STOP>
        <GO>24534=
            <GO>245<VS>34=<GT><STOP>
            <GO>245<VS>340=<LT><STOP>
            <GO>245-34=211<STOP>
            <GO>21134=6<R>7<STOP>
            <GO>6+1=7<STOP>
            7<R>7<STOP>
        <GO>228534=
            <GO>2285<VS>34=<GT><STOP>
            <GO>2285<VS>340=<GT><STOP>
            <GO>22834=6<R>24<STOP>
            <GO>24534=7<R>7<STOP>
            67<R>7<STOP>
    """"""
name = 'Div'
dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Sub: lambda config: config,
    }
symbols = ['', '<R>']","(276, 0)","(347, 19)",N,class_definition,Div,,633,aaae3650-09ab-4776-841e-33cc4c04508d
"""""""Integer division
    E.g.,
        # Memorize trivial case
        <GO>173=5<R>2<STOP>
        <GO>24534=
            <GO>245<VS>34=<GT><STOP>
            <GO>245<VS>340=<LT><STOP>
            <GO>245-34=211<STOP>
            <GO>21134=6<R>7<STOP>
            <GO>6+1=7<STOP>
            7<R>7<STOP>
        <GO>228534=
            <GO>2285<VS>34=<GT><STOP>
            <GO>2285<VS>340=<GT><STOP>
            <GO>22834=6<R>24<STOP>
            <GO>24534=7<R>7<STOP>
            67<R>7<STOP>
    """"""
name = 'Div'
dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Sub: lambda config: config,
    }
symbols = ['', '<R>']",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div/,Div,Previous sibling does not exist,"def generate(self):
        max_num = 10 ** self.config['max_digits']
        divisor = self.log_randrange(1, max_num)
        quotient = self.log_randrange(0, (max_num - 1) / divisor)
        max_remainder = min(divisor, max_num - quotient * divisor)
        remainder = self.log_randrange(0, max_remainder)
        dividend = divisor * quotient + remainder
        return dividend, divisor","(277, 4)","(300, 27)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,247,955cd5fa-fd90-42c8-b591-a877214db7c2
"def generate(self):
        max_num = 10 ** self.config['max_digits']
        divisor = self.log_randrange(1, max_num)
        quotient = self.log_randrange(0, (max_num - 1) / divisor)
        max_remainder = min(divisor, max_num - quotient * divisor)
        remainder = self.log_randrange(0, max_remainder)
        dividend = divisor * quotient + remainder
        return dividend, divisor",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div/,Div,"""""""Integer division
    E.g.,
        # Memorize trivial case
        <GO>173=5<R>2<STOP>
        <GO>24534=
            <GO>245<VS>34=<GT><STOP>
            <GO>245<VS>340=<LT><STOP>
            <GO>245-34=211<STOP>
            <GO>21134=6<R>7<STOP>
            <GO>6+1=7<STOP>
            7<R>7<STOP>
        <GO>228534=
            <GO>2285<VS>34=<GT><STOP>
            <GO>2285<VS>340=<GT><STOP>
            <GO>22834=6<R>24<STOP>
            <GO>24534=7<R>7<STOP>
            67<R>7<STOP>
    """"""
name = 'Div'
dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Sub: lambda config: config,
    }
symbols = ['', '<R>']","@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}{right}='","(302, 4)","(309, 32)",N,function_definition,generate,,94,4c5a5bc2-7ef0-47b9-b639-ac7e54a68fdd
"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}{right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div/,Div,"def generate(self):
        max_num = 10 ** self.config['max_digits']
        divisor = self.log_randrange(1, max_num)
        quotient = self.log_randrange(0, (max_num - 1) / divisor)
        max_remainder = min(divisor, max_num - quotient * divisor)
        remainder = self.log_randrange(0, max_remainder)
        dividend = divisor * quotient + remainder
        return dividend, divisor","@staticmethod
    def answer(args):
        left, right = args
        return f'{left // right}<R>{left % right}<STOP>'","(311, 4)","(314, 38)",N,function_definition,"def question(args):
        left, right = args
        return f'<GO>{left}{right}='",,29,67c00963-b8ea-4cfa-bc07-d55cdf4b4466
"@staticmethod
    def answer(args):
        left, right = args
        return f'{left // right}<R>{left % right}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div/,Div,"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}{right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args
        thoughts = [T(Compare, (left, right))]

        # Base cases
        if left <= right:
            return thoughts

        thoughts.append(T(Compare, (left, right * 10)))
        if left <= right * 10:
            diff = left - right
            thoughts.append(T(Sub, (left, right)))
            thoughts.append(T(Div, (diff, right)))
        else:
            thoughts.append(T(Div, (left // 10, right)))
            left_remainder = (left // 10) % right * 10 + left % 10
            thoughts.append(T(Div, (left_remainder, right)))
        return thoughts","(316, 4)","(319, 56)",N,function_definition,"def answer(args):
        left, right = args
        return f'{left // right}<R>{left % right}<STOP>'",,31,32dc25bb-6ddd-4a59-959e-c2042d8cbf2a
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args
        thoughts = [T(Compare, (left, right))]

        # Base cases
        if left <= right:
            return thoughts

        thoughts.append(T(Compare, (left, right * 10)))
        if left <= right * 10:
            diff = left - right
            thoughts.append(T(Sub, (left, right)))
            thoughts.append(T(Div, (diff, right)))
        else:
            thoughts.append(T(Div, (left // 10, right)))
            left_remainder = (left // 10) % right * 10 + left % 10
            thoughts.append(T(Div, (left_remainder, right)))
        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div/,Div,"@staticmethod
    def answer(args):
        left, right = args
        return f'{left // right}<R>{left % right}<STOP>'","def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(0, max_num):
            for right in range(1, max_num):
                args.append((left, right))
        return args","(321, 4)","(339, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args
        thoughts = [T(Compare, (left, right))]

        # Base cases
        if left <= right:
            return thoughts

        thoughts.append(T(Compare, (left, right * 10)))
        if left <= right * 10:
            diff = left - right
            thoughts.append(T(Sub, (left, right)))
            thoughts.append(T(Div, (diff, right)))
        else:
            thoughts.append(T(Div, (left // 10, right)))
            left_remainder = (left // 10) % right * 10 + left % 10
            thoughts.append(T(Div, (left_remainder, right)))
        return thoughts",,159,2114dfc8-d565-4456-bf82-f14a9c5209b2
"def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(0, max_num):
            for right in range(1, max_num):
                args.append((left, right))
        return args",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div/,Div,"@staticmethod
    def thought(args) -> list[T]:
        left, right = args
        thoughts = [T(Compare, (left, right))]

        # Base cases
        if left <= right:
            return thoughts

        thoughts.append(T(Compare, (left, right * 10)))
        if left <= right * 10:
            diff = left - right
            thoughts.append(T(Sub, (left, right)))
            thoughts.append(T(Div, (diff, right)))
        else:
            thoughts.append(T(Div, (left // 10, right)))
            left_remainder = (left // 10) % right * 10 + left % 10
            thoughts.append(T(Div, (left_remainder, right)))
        return thoughts",Next sibling does not exist,"(341, 4)","(347, 19)",N,function_definition,enum_args,,55,0f34c389-c2a4-4b81-b53e-c674fb1867cf
"class Gcd(Problem):
    """"""Greatest Common Divisor
    E.g.,
        # Base case
        <GO>72<GCD>36=
            <GO>72<VS>36=<GT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>72=
            <GO>36<VS>72=<LT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>36=
            <GO>36<VS>36=<EQ><STOP>
            36<STOP>

        # Solve recursively
        <GO>78696<GCD>19332=
            <GO>78696<VS>19332=<GT><STOP>
            <GO>7869619332=4<R>1368<STOP>
            <GO>19332<GCD>1368=36<STOP>
            36<STOP>
    """"""
    name = 'Gcd'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Div: lambda config: config,
    }
    symbols = ['<GCD>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)

        if random.random() < 0.85:
            left = cd * self.log_randrange(1, max_num // cd + 1)
            right = cd * self.log_randrange(1, max_num // cd + 1)
        else:
            left = right = cd

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<GCD>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{math.gcd(left, right)}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left == right:
            return thoughts
        elif left < right:
            left, right = right, left

        thoughts.append(T(Div, (left, right)))

        rest = left % right
        # Except base case
        if rest != 0:
            thoughts.append(T(Gcd, (right, rest)))

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Div(Problem):
    """"""Integer division
    E.g.,
        # Memorize trivial case
        <GO>173=5<R>2<STOP>
        <GO>24534=
            <GO>245<VS>34=<GT><STOP>
            <GO>245<VS>340=<LT><STOP>
            <GO>245-34=211<STOP>
            <GO>21134=6<R>7<STOP>
            <GO>6+1=7<STOP>
            7<R>7<STOP>
        <GO>228534=
            <GO>2285<VS>34=<GT><STOP>
            <GO>2285<VS>340=<GT><STOP>
            <GO>22834=6<R>24<STOP>
            <GO>24534=7<R>7<STOP>
            67<R>7<STOP>
    """"""
    name = 'Div'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Sub: lambda config: config,
    }
    symbols = ['', '<R>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        divisor = self.log_randrange(1, max_num)
        quotient = self.log_randrange(0, (max_num - 1) / divisor)
        max_remainder = min(divisor, max_num - quotient * divisor)
        remainder = self.log_randrange(0, max_remainder)
        dividend = divisor * quotient + remainder
        return dividend, divisor

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left // right}<R>{left % right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args
        thoughts = [T(Compare, (left, right))]

        # Base cases
        if left <= right:
            return thoughts

        thoughts.append(T(Compare, (left, right * 10)))
        if left <= right * 10:
            diff = left - right
            thoughts.append(T(Sub, (left, right)))
            thoughts.append(T(Div, (diff, right)))
        else:
            thoughts.append(T(Div, (left // 10, right)))
            left_remainder = (left // 10) % right * 10 + left % 10
            thoughts.append(T(Div, (left_remainder, right)))
        return thoughts

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        args = []
        for left in range(0, max_num):
            for right in range(1, max_num):
                args.append((left, right))
        return args","""""""Greatest Common Divisor
    E.g.,
        # Base case
        <GO>72<GCD>36=
            <GO>72<VS>36=<GT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>72=
            <GO>36<VS>72=<LT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>36=
            <GO>36<VS>36=<EQ><STOP>
            36<STOP>

        # Solve recursively
        <GO>78696<GCD>19332=
            <GO>78696<VS>19332=<GT><STOP>
            <GO>7869619332=4<R>1368<STOP>
            <GO>19332<GCD>1368=36<STOP>
            36<STOP>
    """"""
name = 'Gcd'
dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Div: lambda config: config,
    }
symbols = ['<GCD>']","(350, 0)","(420, 23)",N,class_definition,Gcd,,536,8bed058f-3e51-4d67-a7cc-4ed8f3eb3d2f
"""""""Greatest Common Divisor
    E.g.,
        # Base case
        <GO>72<GCD>36=
            <GO>72<VS>36=<GT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>72=
            <GO>36<VS>72=<LT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>36=
            <GO>36<VS>36=<EQ><STOP>
            36<STOP>

        # Solve recursively
        <GO>78696<GCD>19332=
            <GO>78696<VS>19332=<GT><STOP>
            <GO>7869619332=4<R>1368<STOP>
            <GO>19332<GCD>1368=36<STOP>
            36<STOP>
    """"""
name = 'Gcd'
dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Div: lambda config: config,
    }
symbols = ['<GCD>']",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Gcd/,Gcd,Previous sibling does not exist,"def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)

        if random.random() < 0.85:
            left = cd * self.log_randrange(1, max_num // cd + 1)
            right = cd * self.log_randrange(1, max_num // cd + 1)
        else:
            left = right = cd

        return left, right","(351, 4)","(378, 23)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,260,31dea44b-3996-44cc-b33d-ae8ee2e71727
"def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)

        if random.random() < 0.85:
            left = cd * self.log_randrange(1, max_num // cd + 1)
            right = cd * self.log_randrange(1, max_num // cd + 1)
        else:
            left = right = cd

        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Gcd/,Gcd,"""""""Greatest Common Divisor
    E.g.,
        # Base case
        <GO>72<GCD>36=
            <GO>72<VS>36=<GT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>72=
            <GO>36<VS>72=<LT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>36=
            <GO>36<VS>36=<EQ><STOP>
            36<STOP>

        # Solve recursively
        <GO>78696<GCD>19332=
            <GO>78696<VS>19332=<GT><STOP>
            <GO>7869619332=4<R>1368<STOP>
            <GO>19332<GCD>1368=36<STOP>
            36<STOP>
    """"""
name = 'Gcd'
dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Div: lambda config: config,
    }
symbols = ['<GCD>']","@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<GCD>{right}='","(380, 4)","(390, 26)",N,function_definition,generate,,96,fe38e3d3-ef72-4425-a4bb-93cdb4598ff4
"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<GCD>{right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Gcd/,Gcd,"def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)

        if random.random() < 0.85:
            left = cd * self.log_randrange(1, max_num // cd + 1)
            right = cd * self.log_randrange(1, max_num // cd + 1)
        else:
            left = right = cd

        return left, right","@staticmethod
    def answer(args):
        left, right = args
        return f'{math.gcd(left, right)}<STOP>'","(392, 4)","(395, 41)",N,function_definition,"def question(args):
        left, right = args
        return f'<GO>{left}<GCD>{right}='",,29,0530a324-bcca-4a94-8ecc-9c4584c18223
"@staticmethod
    def answer(args):
        left, right = args
        return f'{math.gcd(left, right)}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Gcd/,Gcd,"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<GCD>{right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left == right:
            return thoughts
        elif left < right:
            left, right = right, left

        thoughts.append(T(Div, (left, right)))

        rest = left % right
        # Except base case
        if rest != 0:
            thoughts.append(T(Gcd, (right, rest)))

        return thoughts","(397, 4)","(400, 47)",N,function_definition,"def answer(args):
        left, right = args
        return f'{math.gcd(left, right)}<STOP>'",,29,939611dd-4a82-4ca1-b1b0-25f9c8b1b9cd
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left == right:
            return thoughts
        elif left < right:
            left, right = right, left

        thoughts.append(T(Div, (left, right)))

        rest = left % right
        # Except base case
        if rest != 0:
            thoughts.append(T(Gcd, (right, rest)))

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Gcd/,Gcd,"@staticmethod
    def answer(args):
        left, right = args
        return f'{math.gcd(left, right)}<STOP>'",Next sibling does not exist,"(402, 4)","(420, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left == right:
            return thoughts
        elif left < right:
            left, right = right, left

        thoughts.append(T(Div, (left, right)))

        rest = left % right
        # Except base case
        if rest != 0:
            thoughts.append(T(Gcd, (right, rest)))

        return thoughts",,105,5a63344f-3d8d-4fe8-9f00-c5874fc97f97
"class Lcm(Problem):
    """"""Least Common Multiple
    E.g.,
        <GO>36<LCM>72=
            <GO>36<GCD>72=36<STOP>
            <GO>3636=1<R>0<STOP>
            <GO>1*72=72<STOP>
            72<STOP>
        <GO>78696<LCM>19332=
            <GO>78696<GCD>19332=36<STOP>
            <GO>7869636=2186<R>0<STOP>
            <GO>2186*19332=42259752<STOP>
            42259752<STOP>
    """"""
    name = 'Lcm'
    dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
        Mul: lambda config: config,
    }
    symbols = ['<LCM>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)
        left = cd * random.randrange(1, max_num // cd + 1)
        right = cd * random.randrange(1, max_num // cd + 1)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<LCM>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{math.lcm(left, right)}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [
            T(Gcd, (left, right)),
            T(Div, (left, math.gcd(left, right))),
            T(Mul, (left // math.gcd(left, right), right))
        ]

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Gcd(Problem):
    """"""Greatest Common Divisor
    E.g.,
        # Base case
        <GO>72<GCD>36=
            <GO>72<VS>36=<GT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>72=
            <GO>36<VS>72=<LT><STOP>
            <GO>7236=2<R>0<STOP>
            36<STOP>
        <GO>36<GCD>36=
            <GO>36<VS>36=<EQ><STOP>
            36<STOP>

        # Solve recursively
        <GO>78696<GCD>19332=
            <GO>78696<VS>19332=<GT><STOP>
            <GO>7869619332=4<R>1368<STOP>
            <GO>19332<GCD>1368=36<STOP>
            36<STOP>
    """"""
    name = 'Gcd'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
        Div: lambda config: config,
    }
    symbols = ['<GCD>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)

        if random.random() < 0.85:
            left = cd * self.log_randrange(1, max_num // cd + 1)
            right = cd * self.log_randrange(1, max_num // cd + 1)
        else:
            left = right = cd

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<GCD>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{math.gcd(left, right)}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left == right:
            return thoughts
        elif left < right:
            left, right = right, left

        thoughts.append(T(Div, (left, right)))

        rest = left % right
        # Except base case
        if rest != 0:
            thoughts.append(T(Gcd, (right, rest)))

        return thoughts","class Reduce(Problem):
    """"""Make a fraction irreducible
    E.g.,
        <GO><REDUCE>10/5=
            <GO>10<GCD>5=5<STOP>
            <GO>105=2<R>0<STOP>
            <GO>55=1<R>0<STOP>
            <GO>1<VS>1=<EQ>
            2<STOP>
        <GO><REDUCE>10/4=
            <GO>10<GCD>4=2<STOP>
            <GO>102=5<R>0<STOP>
            <GO>42=2<R>0<STOP>
            <GO>2<VS>1=<GT>
            5/2<STOP>
        <GO><REDUCE>10/3=
            <GO>10<GCD>3=1<STOP>
            <GO>101=10<R>0<STOP>
            <GO>31=3<R>0<STOP>
            <GO>3<VS>1=<GT>
            10/3<STOP>
        # trivial case
        <GO><REDUCE>10/1=
            10<STOP>
        <GO><REDUCE>0/23=
            0<STOP>
    """"""
    name = 'Reduce'
    dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
    }
    symbols = ['<REDUCE>', '/']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        rand = random.random()
        if rand < 0.65:
            cd = self.log_randrange(1, max_num)
            numer = cd * random.randrange(1, max_num // cd + 1)
            denom = cd * random.randrange(1, max_num // cd + 1)
        elif rand < 0.7:
            numer = self.log_randrange(0, max_num)
            denom = 1
        else:
            numer = self.log_randrange(0, max_num)
            denom = self.log_randrange(1, max_num)
        return numer, denom

    @staticmethod
    def question(args):
        numer, denom = args
        return f'<GO><REDUCE>{numer}/{denom}='

    @staticmethod
    def answer(args):
        return frac_to_str(args, reduce=True)

    @staticmethod
    def thought(args) -> list[T]:
        numer, denom = args

        # Trivial case
        if denom == 1:
            return []
        if numer == 0:
            return []

        return [T(Gcd, (numer, denom)),
                T(Div, (numer, math.gcd(numer, denom))),
                T(Div, (denom, math.gcd(numer, denom)))]

    @staticmethod
    def get_answer(args):
        numer, denom = args

        if numer == 0:
            return 0, 1

        gcd = math.gcd(numer, denom)
        numer = numer // gcd
        denom = denom // gcd

        if denom < 0:
            numer = -numer
            denom = -denom

        return numer, denom","(423, 0)","(473, 23)",N,class_definition,Lcm,,401,8064083f-e855-4cc8-95d4-8f1df20bc06c
"def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)
        left = cd * random.randrange(1, max_num // cd + 1)
        right = cd * random.randrange(1, max_num // cd + 1)

        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Lcm/,Lcm,symbols = ['<LCM>'],"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<LCM>{right}='","(445, 4)","(451, 26)",N,function_definition,generate,,71,96389fb2-0e9f-415e-8a70-d138eada5819
"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<LCM>{right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Lcm/,Lcm,"def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)
        left = cd * random.randrange(1, max_num // cd + 1)
        right = cd * random.randrange(1, max_num // cd + 1)

        return left, right","@staticmethod
    def answer(args):
        left, right = args
        return f'{math.lcm(left, right)}<STOP>'","(453, 4)","(456, 41)",N,function_definition,"def question(args):
        left, right = args
        return f'<GO>{left}<LCM>{right}='",,29,a6b97eae-774b-4f7e-a929-7a7f2b8d3460
"@staticmethod
    def answer(args):
        left, right = args
        return f'{math.lcm(left, right)}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Lcm/,Lcm,"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<LCM>{right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [
            T(Gcd, (left, right)),
            T(Div, (left, math.gcd(left, right))),
            T(Mul, (left // math.gcd(left, right), right))
        ]

        return thoughts","(458, 4)","(461, 47)",N,function_definition,"def answer(args):
        left, right = args
        return f'{math.lcm(left, right)}<STOP>'",,29,aa7b3235-87f1-4bc2-9141-e1951d1634fd
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [
            T(Gcd, (left, right)),
            T(Div, (left, math.gcd(left, right))),
            T(Mul, (left // math.gcd(left, right), right))
        ]

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Lcm/,Lcm,"@staticmethod
    def answer(args):
        left, right = args
        return f'{math.lcm(left, right)}<STOP>'",Next sibling does not exist,"(463, 4)","(473, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        thoughts = [
            T(Gcd, (left, right)),
            T(Div, (left, math.gcd(left, right))),
            T(Mul, (left // math.gcd(left, right), right))
        ]

        return thoughts",,70,72bee383-fc32-4199-a22e-f2d99f2e34f7
"class Reduce(Problem):
    """"""Make a fraction irreducible
    E.g.,
        <GO><REDUCE>10/5=
            <GO>10<GCD>5=5<STOP>
            <GO>105=2<R>0<STOP>
            <GO>55=1<R>0<STOP>
            <GO>1<VS>1=<EQ>
            2<STOP>
        <GO><REDUCE>10/4=
            <GO>10<GCD>4=2<STOP>
            <GO>102=5<R>0<STOP>
            <GO>42=2<R>0<STOP>
            <GO>2<VS>1=<GT>
            5/2<STOP>
        <GO><REDUCE>10/3=
            <GO>10<GCD>3=1<STOP>
            <GO>101=10<R>0<STOP>
            <GO>31=3<R>0<STOP>
            <GO>3<VS>1=<GT>
            10/3<STOP>
        # trivial case
        <GO><REDUCE>10/1=
            10<STOP>
        <GO><REDUCE>0/23=
            0<STOP>
    """"""
    name = 'Reduce'
    dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
    }
    symbols = ['<REDUCE>', '/']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        rand = random.random()
        if rand < 0.65:
            cd = self.log_randrange(1, max_num)
            numer = cd * random.randrange(1, max_num // cd + 1)
            denom = cd * random.randrange(1, max_num // cd + 1)
        elif rand < 0.7:
            numer = self.log_randrange(0, max_num)
            denom = 1
        else:
            numer = self.log_randrange(0, max_num)
            denom = self.log_randrange(1, max_num)
        return numer, denom

    @staticmethod
    def question(args):
        numer, denom = args
        return f'<GO><REDUCE>{numer}/{denom}='

    @staticmethod
    def answer(args):
        return frac_to_str(args, reduce=True)

    @staticmethod
    def thought(args) -> list[T]:
        numer, denom = args

        # Trivial case
        if denom == 1:
            return []
        if numer == 0:
            return []

        return [T(Gcd, (numer, denom)),
                T(Div, (numer, math.gcd(numer, denom))),
                T(Div, (denom, math.gcd(numer, denom)))]

    @staticmethod
    def get_answer(args):
        numer, denom = args

        if numer == 0:
            return 0, 1

        gcd = math.gcd(numer, denom)
        numer = numer // gcd
        denom = denom // gcd

        if denom < 0:
            numer = -numer
            denom = -denom

        return numer, denom",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Lcm(Problem):
    """"""Least Common Multiple
    E.g.,
        <GO>36<LCM>72=
            <GO>36<GCD>72=36<STOP>
            <GO>3636=1<R>0<STOP>
            <GO>1*72=72<STOP>
            72<STOP>
        <GO>78696<LCM>19332=
            <GO>78696<GCD>19332=36<STOP>
            <GO>7869636=2186<R>0<STOP>
            <GO>2186*19332=42259752<STOP>
            42259752<STOP>
    """"""
    name = 'Lcm'
    dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
        Mul: lambda config: config,
    }
    symbols = ['<LCM>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        cd = self.log_randrange(1, max_num)
        left = cd * random.randrange(1, max_num // cd + 1)
        right = cd * random.randrange(1, max_num // cd + 1)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<LCM>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{math.lcm(left, right)}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [
            T(Gcd, (left, right)),
            T(Div, (left, math.gcd(left, right))),
            T(Mul, (left // math.gcd(left, right), right))
        ]

        return thoughts","""""""Make a fraction irreducible
    E.g.,
        <GO><REDUCE>10/5=
            <GO>10<GCD>5=5<STOP>
            <GO>105=2<R>0<STOP>
            <GO>55=1<R>0<STOP>
            <GO>1<VS>1=<EQ>
            2<STOP>
        <GO><REDUCE>10/4=
            <GO>10<GCD>4=2<STOP>
            <GO>102=5<R>0<STOP>
            <GO>42=2<R>0<STOP>
            <GO>2<VS>1=<GT>
            5/2<STOP>
        <GO><REDUCE>10/3=
            <GO>10<GCD>3=1<STOP>
            <GO>101=10<R>0<STOP>
            <GO>31=3<R>0<STOP>
            <GO>3<VS>1=<GT>
            10/3<STOP>
        # trivial case
        <GO><REDUCE>10/1=
            10<STOP>
        <GO><REDUCE>0/23=
            0<STOP>
    """"""
name = 'Reduce'
dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
    }
symbols = ['<REDUCE>', '/']","(476, 0)","(563, 27)",N,class_definition,Reduce,,696,2fd67ada-6548-45ac-a167-ddc7cd7e65bc
"""""""Make a fraction irreducible
    E.g.,
        <GO><REDUCE>10/5=
            <GO>10<GCD>5=5<STOP>
            <GO>105=2<R>0<STOP>
            <GO>55=1<R>0<STOP>
            <GO>1<VS>1=<EQ>
            2<STOP>
        <GO><REDUCE>10/4=
            <GO>10<GCD>4=2<STOP>
            <GO>102=5<R>0<STOP>
            <GO>42=2<R>0<STOP>
            <GO>2<VS>1=<GT>
            5/2<STOP>
        <GO><REDUCE>10/3=
            <GO>10<GCD>3=1<STOP>
            <GO>101=10<R>0<STOP>
            <GO>31=3<R>0<STOP>
            <GO>3<VS>1=<GT>
            10/3<STOP>
        # trivial case
        <GO><REDUCE>10/1=
            10<STOP>
        <GO><REDUCE>0/23=
            0<STOP>
    """"""
name = 'Reduce'
dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
    }
symbols = ['<REDUCE>', '/']",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Reduce/,Reduce,Previous sibling does not exist,"def generate(self):
        max_num = 10 ** self.config['max_digits']
        rand = random.random()
        if rand < 0.65:
            cd = self.log_randrange(1, max_num)
            numer = cd * random.randrange(1, max_num // cd + 1)
            denom = cd * random.randrange(1, max_num // cd + 1)
        elif rand < 0.7:
            numer = self.log_randrange(0, max_num)
            denom = 1
        else:
            numer = self.log_randrange(0, max_num)
            denom = self.log_randrange(1, max_num)
        return numer, denom","(477, 4)","(508, 31)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,317,bbadc8ed-0eb3-455a-af2e-c87ac844c3d6
"def generate(self):
        max_num = 10 ** self.config['max_digits']
        rand = random.random()
        if rand < 0.65:
            cd = self.log_randrange(1, max_num)
            numer = cd * random.randrange(1, max_num // cd + 1)
            denom = cd * random.randrange(1, max_num // cd + 1)
        elif rand < 0.7:
            numer = self.log_randrange(0, max_num)
            denom = 1
        else:
            numer = self.log_randrange(0, max_num)
            denom = self.log_randrange(1, max_num)
        return numer, denom",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Reduce/,Reduce,"""""""Make a fraction irreducible
    E.g.,
        <GO><REDUCE>10/5=
            <GO>10<GCD>5=5<STOP>
            <GO>105=2<R>0<STOP>
            <GO>55=1<R>0<STOP>
            <GO>1<VS>1=<EQ>
            2<STOP>
        <GO><REDUCE>10/4=
            <GO>10<GCD>4=2<STOP>
            <GO>102=5<R>0<STOP>
            <GO>42=2<R>0<STOP>
            <GO>2<VS>1=<GT>
            5/2<STOP>
        <GO><REDUCE>10/3=
            <GO>10<GCD>3=1<STOP>
            <GO>101=10<R>0<STOP>
            <GO>31=3<R>0<STOP>
            <GO>3<VS>1=<GT>
            10/3<STOP>
        # trivial case
        <GO><REDUCE>10/1=
            10<STOP>
        <GO><REDUCE>0/23=
            0<STOP>
    """"""
name = 'Reduce'
dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
    }
symbols = ['<REDUCE>', '/']","@staticmethod
    def question(args):
        numer, denom = args
        return f'<GO><REDUCE>{numer}/{denom}='","(510, 4)","(523, 27)",N,function_definition,generate,,143,e3ec1669-6491-42d8-aca0-510016021c2e
"@staticmethod
    def question(args):
        numer, denom = args
        return f'<GO><REDUCE>{numer}/{denom}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Reduce/,Reduce,"def generate(self):
        max_num = 10 ** self.config['max_digits']
        rand = random.random()
        if rand < 0.65:
            cd = self.log_randrange(1, max_num)
            numer = cd * random.randrange(1, max_num // cd + 1)
            denom = cd * random.randrange(1, max_num // cd + 1)
        elif rand < 0.7:
            numer = self.log_randrange(0, max_num)
            denom = 1
        else:
            numer = self.log_randrange(0, max_num)
            denom = self.log_randrange(1, max_num)
        return numer, denom","@staticmethod
    def answer(args):
        return frac_to_str(args, reduce=True)","(525, 4)","(528, 46)",N,function_definition,"def question(args):
        numer, denom = args
        return f'<GO><REDUCE>{numer}/{denom}='",,30,3f1b04bf-26d2-4d7a-a262-b0ac8bd4e103
"@staticmethod
    def answer(args):
        return frac_to_str(args, reduce=True)",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Reduce/,Reduce,"@staticmethod
    def question(args):
        numer, denom = args
        return f'<GO><REDUCE>{numer}/{denom}='","@staticmethod
    def thought(args) -> list[T]:
        numer, denom = args

        # Trivial case
        if denom == 1:
            return []
        if numer == 0:
            return []

        return [T(Gcd, (numer, denom)),
                T(Div, (numer, math.gcd(numer, denom))),
                T(Div, (denom, math.gcd(numer, denom)))]","(530, 4)","(532, 45)",N,function_definition,"def answer(args):
        return frac_to_str(args, reduce=True)",,18,d3772451-c4a9-413a-acf5-8345ecb681e7
"@staticmethod
    def thought(args) -> list[T]:
        numer, denom = args

        # Trivial case
        if denom == 1:
            return []
        if numer == 0:
            return []

        return [T(Gcd, (numer, denom)),
                T(Div, (numer, math.gcd(numer, denom))),
                T(Div, (denom, math.gcd(numer, denom)))]",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Reduce/,Reduce,"@staticmethod
    def answer(args):
        return frac_to_str(args, reduce=True)","@staticmethod
    def get_answer(args):
        numer, denom = args

        if numer == 0:
            return 0, 1

        gcd = math.gcd(numer, denom)
        numer = numer // gcd
        denom = denom // gcd

        if denom < 0:
            numer = -numer
            denom = -denom

        return numer, denom","(534, 4)","(546, 56)",N,function_definition,"def thought(args) -> list[T]:
        numer, denom = args

        # Trivial case
        if denom == 1:
            return []
        if numer == 0:
            return []

        return [T(Gcd, (numer, denom)),
                T(Div, (numer, math.gcd(numer, denom))),
                T(Div, (denom, math.gcd(numer, denom)))]",,91,c9247a88-554d-4b2a-80d9-46e9df9dd5dc
"@staticmethod
    def get_answer(args):
        numer, denom = args

        if numer == 0:
            return 0, 1

        gcd = math.gcd(numer, denom)
        numer = numer // gcd
        denom = denom // gcd

        if denom < 0:
            numer = -numer
            denom = -denom

        return numer, denom",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Reduce/,Reduce,"@staticmethod
    def thought(args) -> list[T]:
        numer, denom = args

        # Trivial case
        if denom == 1:
            return []
        if numer == 0:
            return []

        return [T(Gcd, (numer, denom)),
                T(Div, (numer, math.gcd(numer, denom))),
                T(Div, (denom, math.gcd(numer, denom)))]",Next sibling does not exist,"(548, 4)","(563, 27)",N,function_definition,"def get_answer(args):
        numer, denom = args

        if numer == 0:
            return 0, 1

        gcd = math.gcd(numer, denom)
        numer = numer // gcd
        denom = denom // gcd

        if denom < 0:
            numer = -numer
            denom = -denom

        return numer, denom",,81,2e3de469-fab7-4d65-9f06-d226706b7c8a
"class Sub_pos_int(Problem):
    """"""Subtraction of two positive integers including smaller - larger
    E.g.
        <GO>441<SUB_POS_INT>383=
            <GO>441<VS>383=<GT><STOP>
            <GO>441-383=62<STOP>
            62<STOP>
        <GO>383<SUB_POS_INT>441=
            <GO>383<VS>441=<LT><STOP>
            <GO>441-383=62<STOP>
            -62<STOP>
        <GO>383<SUB_POS_INT>383=
            <GO>383<VS>383=<EQ><STOP>
            0<STOP>
    """"""

    name = 'Sub_pos_int'
    dependencies = {
        Sub: lambda config: config,
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
    }

    symbols = ['<SUB_POS_INT>', '-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<SUB_POS_INT>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left != right:
            thoughts.append(T(Sub, (max(left, right), min(left, right))))

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Reduce(Problem):
    """"""Make a fraction irreducible
    E.g.,
        <GO><REDUCE>10/5=
            <GO>10<GCD>5=5<STOP>
            <GO>105=2<R>0<STOP>
            <GO>55=1<R>0<STOP>
            <GO>1<VS>1=<EQ>
            2<STOP>
        <GO><REDUCE>10/4=
            <GO>10<GCD>4=2<STOP>
            <GO>102=5<R>0<STOP>
            <GO>42=2<R>0<STOP>
            <GO>2<VS>1=<GT>
            5/2<STOP>
        <GO><REDUCE>10/3=
            <GO>10<GCD>3=1<STOP>
            <GO>101=10<R>0<STOP>
            <GO>31=3<R>0<STOP>
            <GO>3<VS>1=<GT>
            10/3<STOP>
        # trivial case
        <GO><REDUCE>10/1=
            10<STOP>
        <GO><REDUCE>0/23=
            0<STOP>
    """"""
    name = 'Reduce'
    dependencies = {
        Gcd: lambda config: config,
        Div: lambda config: config,
    }
    symbols = ['<REDUCE>', '/']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        rand = random.random()
        if rand < 0.65:
            cd = self.log_randrange(1, max_num)
            numer = cd * random.randrange(1, max_num // cd + 1)
            denom = cd * random.randrange(1, max_num // cd + 1)
        elif rand < 0.7:
            numer = self.log_randrange(0, max_num)
            denom = 1
        else:
            numer = self.log_randrange(0, max_num)
            denom = self.log_randrange(1, max_num)
        return numer, denom

    @staticmethod
    def question(args):
        numer, denom = args
        return f'<GO><REDUCE>{numer}/{denom}='

    @staticmethod
    def answer(args):
        return frac_to_str(args, reduce=True)

    @staticmethod
    def thought(args) -> list[T]:
        numer, denom = args

        # Trivial case
        if denom == 1:
            return []
        if numer == 0:
            return []

        return [T(Gcd, (numer, denom)),
                T(Div, (numer, math.gcd(numer, denom))),
                T(Div, (denom, math.gcd(numer, denom)))]

    @staticmethod
    def get_answer(args):
        numer, denom = args

        if numer == 0:
            return 0, 1

        gcd = math.gcd(numer, denom)
        numer = numer // gcd
        denom = denom // gcd

        if denom < 0:
            numer = -numer
            denom = -denom

        return numer, denom","class Add_frac(Problem):
    """"""Fraction Addition
    E.g.,
        <GO>23/10<ADD_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322+60=382<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>382/140=191/70<STOP>
            191/70<STOP>

        <GO>23/10<ADD_FRAC>6=
            <GO>23/10<ADD_FRAC>6/1=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23/10=
            <GO>6/1<ADD_FRAC>23/10=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23=
            <GO>6+23=29
            29<STOP>
    """"""
    name = 'Add_frac'
    dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2},
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<ADD_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<ADD_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<ADD_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return Add.answer(args)
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom + numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * denom + numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

        return frac_to_str((numer, denom), reduce=True)

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Add, (left, right))]

        elif isinstance(left, int):
            return [T(Add_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Add_frac, (left, (right, 1)))]

        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Add, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]","(566, 0)","(615, 23)",N,class_definition,Sub_pos_int,,367,d78a7992-887a-4dae-bb57-05ddcad1d403
"def generate(self):
        max_num = 10 ** self.config['max_digits']
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_pos_int/,Sub_pos_int,"symbols = ['<SUB_POS_INT>', '-']","@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<SUB_POS_INT>{right}='","(590, 4)","(594, 26)",N,function_definition,generate,,48,f9ef24b5-cd8a-404d-917f-2c2a22b0f519
"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<SUB_POS_INT>{right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_pos_int/,Sub_pos_int,"def generate(self):
        max_num = 10 ** self.config['max_digits']
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right","@staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'","(596, 4)","(599, 49)",N,function_definition,"def question(args):
        left, right = args
        return f'<GO>{left}<SUB_POS_INT>{right}='",,30,735f9766-7be8-483c-a4bb-4bce3d5ae137
"@staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_pos_int/,Sub_pos_int,"@staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<SUB_POS_INT>{right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left != right:
            thoughts.append(T(Sub, (max(left, right), min(left, right))))

        return thoughts","(601, 4)","(604, 38)",N,function_definition,"def answer(args):
        left, right = args
        return f'{left - right}<STOP>'",,25,3ad71a12-c8cc-4f0a-b612-96612e4bf93c
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left != right:
            thoughts.append(T(Sub, (max(left, right), min(left, right))))

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_pos_int/,Sub_pos_int,"@staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'",Next sibling does not exist,"(606, 4)","(615, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left != right:
            thoughts.append(T(Sub, (max(left, right), min(left, right))))

        return thoughts",,59,6f0c1af7-6106-4ede-9393-8bc3aeda7050
"class Add_frac(Problem):
    """"""Fraction Addition
    E.g.,
        <GO>23/10<ADD_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322+60=382<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>382/140=191/70<STOP>
            191/70<STOP>

        <GO>23/10<ADD_FRAC>6=
            <GO>23/10<ADD_FRAC>6/1=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23/10=
            <GO>6/1<ADD_FRAC>23/10=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23=
            <GO>6+23=29
            29<STOP>
    """"""
    name = 'Add_frac'
    dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2},
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<ADD_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<ADD_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<ADD_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return Add.answer(args)
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom + numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * denom + numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

        return frac_to_str((numer, denom), reduce=True)

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Add, (left, right))]

        elif isinstance(left, int):
            return [T(Add_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Add_frac, (left, (right, 1)))]

        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Add, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Sub_pos_int(Problem):
    """"""Subtraction of two positive integers including smaller - larger
    E.g.
        <GO>441<SUB_POS_INT>383=
            <GO>441<VS>383=<GT><STOP>
            <GO>441-383=62<STOP>
            62<STOP>
        <GO>383<SUB_POS_INT>441=
            <GO>383<VS>441=<LT><STOP>
            <GO>441-383=62<STOP>
            -62<STOP>
        <GO>383<SUB_POS_INT>383=
            <GO>383<VS>383=<EQ><STOP>
            0<STOP>
    """"""

    name = 'Sub_pos_int'
    dependencies = {
        Sub: lambda config: config,
        Compare: lambda config: {'max_digits': config['max_digits'] + 1},
    }

    symbols = ['<SUB_POS_INT>', '-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']
        left = self.log_randrange(0, max_num)
        right = self.log_randrange(0, max_num)
        return left, right

    @staticmethod
    def question(args):
        left, right = args
        return f'<GO>{left}<SUB_POS_INT>{right}='

    @staticmethod
    def answer(args):
        left, right = args
        return f'{left - right}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Compare, (left, right))]

        if left != right:
            thoughts.append(T(Sub, (max(left, right), min(left, right))))

        return thoughts","""""""Fraction Addition
    E.g.,
        <GO>23/10<ADD_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322+60=382<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>382/140=191/70<STOP>
            191/70<STOP>

        <GO>23/10<ADD_FRAC>6=
            <GO>23/10<ADD_FRAC>6/1=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23/10=
            <GO>6/1<ADD_FRAC>23/10=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23=
            <GO>6+23=29
            29<STOP>
    """"""
name = 'Add_frac'
dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2},
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
symbols = ['<ADD_FRAC>']","(618, 0)","(730, 46)",N,class_definition,Add_frac,,970,9db393d9-3beb-4231-98d2-f16ca7987347
"""""""Fraction Addition
    E.g.,
        <GO>23/10<ADD_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322+60=382<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>382/140=191/70<STOP>
            191/70<STOP>

        <GO>23/10<ADD_FRAC>6=
            <GO>23/10<ADD_FRAC>6/1=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23/10=
            <GO>6/1<ADD_FRAC>23/10=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23=
            <GO>6+23=29
            29<STOP>
    """"""
name = 'Add_frac'
dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2},
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
symbols = ['<ADD_FRAC>']",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Add_frac/,Add_frac,Previous sibling does not exist,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right","(619, 4)","(647, 28)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,281,df88c910-d7a7-43f6-b422-f828f62e2cbe
"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Add_frac/,Add_frac,"""""""Fraction Addition
    E.g.,
        <GO>23/10<ADD_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322+60=382<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>382/140=191/70<STOP>
            191/70<STOP>

        <GO>23/10<ADD_FRAC>6=
            <GO>23/10<ADD_FRAC>6/1=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23/10=
            <GO>6/1<ADD_FRAC>23/10=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23=
            <GO>6+23=29
            29<STOP>
    """"""
name = 'Add_frac'
dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2},
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
symbols = ['<ADD_FRAC>']","@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<ADD_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<ADD_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{numer_right}/{denom_right}='","(649, 4)","(668, 26)",N,function_definition,generate,,160,07485f83-a4f6-4ab4-afbd-7f0f1d93c96c
"@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<ADD_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<ADD_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{numer_right}/{denom_right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Add_frac/,Add_frac,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right","@staticmethod
    def answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return Add.answer(args)
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom + numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * denom + numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

        return frac_to_str((numer, denom), reduce=True)","(670, 4)","(684, 89)",N,function_definition,"def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<ADD_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<ADD_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{numer_right}/{denom_right}='",,164,2c1cb378-cba6-4889-81bd-aab0d34db6fe
"@staticmethod
    def answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return Add.answer(args)
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom + numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * denom + numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

        return frac_to_str((numer, denom), reduce=True)",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Add_frac/,Add_frac,"@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<ADD_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<ADD_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{numer_right}/{denom_right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Add, (left, right))]

        elif isinstance(left, int):
            return [T(Add_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Add_frac, (left, (right, 1)))]

        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Add, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]","(686, 4)","(704, 55)",N,function_definition,"def answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return Add.answer(args)
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom + numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * denom + numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

        return frac_to_str((numer, denom), reduce=True)",,142,c60e9ac2-f49c-4f51-aa70-0f1ba39de040
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Add, (left, right))]

        elif isinstance(left, int):
            return [T(Add_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Add_frac, (left, (right, 1)))]

        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Add, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Add_frac/,Add_frac,"@staticmethod
    def answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return Add.answer(args)
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom + numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * denom + numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

        return frac_to_str((numer, denom), reduce=True)",Next sibling does not exist,"(706, 4)","(730, 46)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Add, (left, right))]

        elif isinstance(left, int):
            return [T(Add_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Add_frac, (left, (right, 1)))]

        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Add, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]",,207,563a9505-d2ca-4104-86a4-12c4d9cf0741
"class Sub_frac(Problem):
    """"""Subtraction of two positive fractions
    E.g.,
        <GO>23/10<SUB_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322<SUB_POS_INT>60=262<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            131/70<STOP>

        <GO>6/14<SUB_FRAC>23/10=
            <GO>6*10=60<STOP>
            <GO>23*14=322<STOP>
            <GO>60<SUB_POS_INT>322=-262<STOP>
            <GO>14*10=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            -131/70<STOP>

        <GO>6/14<SUB_FRAC>3/7=
            <GO>6*7=42<STOP>
            <GO>3*14=42<STOP>
            <GO>42<SUB_POS_INT>42=0<STOP>
            0<STOP>

        <GO>23/10<SUB_FRAC>6=
            <GO>23/10<SUB_FRAC>6/1=-37/10<STOP>
            -37/10<STOP><STOP>

        <GO>6<SUB_FRAC>23/10=
            <GO>6/1<SUB_FRAC>23/10<STOP>
            37/10<STOP>

        <GO>6<SUB_FRAC>23=
            <GO>6<SUB_POS_INT>23=-17<STOP>
            -17<STOP>
        <GO>23<SUB_FRAC>6=
            <GO>23<SUB_POS_INT>6=17<STOP>
            17<STOP>
    """"""
    name = 'Sub_frac'
    dependencies = {
        Mul: lambda config: config,
        Sub_pos_int: lambda config: {'max_digits': config['max_digits'] * 2},
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<SUB_FRAC>', '-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<SUB_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<SUB_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        return f'{frac_to_str(Sub_frac.get_answer(args))}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Sub_pos_int, (left, right))]
        elif isinstance(left, int):
            return [T(Sub_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Sub_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Sub_pos_int, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (abs(numer), denom))]

    @staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer =  left - right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom - numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = numer_left - right * denom
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

        return Reduce.get_answer((numer, denom))",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Add_frac(Problem):
    """"""Fraction Addition
    E.g.,
        <GO>23/10<ADD_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322+60=382<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>382/140=191/70<STOP>
            191/70<STOP>

        <GO>23/10<ADD_FRAC>6=
            <GO>23/10<ADD_FRAC>6/1=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23/10=
            <GO>6/1<ADD_FRAC>23/10=83/10<STOP>
            83/10<STOP>

        <GO>6<ADD_FRAC>23=
            <GO>6+23=29
            29<STOP>
    """"""
    name = 'Add_frac'
    dependencies = {
        Add: lambda config: {'max_digits': config['max_digits'] * 2},
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<ADD_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<ADD_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<ADD_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<ADD_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return Add.answer(args)
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom + numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * denom + numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

        return frac_to_str((numer, denom), reduce=True)

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Add, (left, right))]

        elif isinstance(left, int):
            return [T(Add_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Add_frac, (left, (right, 1)))]

        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right + numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Add, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]","""""""Subtraction of two positive fractions
    E.g.,
        <GO>23/10<SUB_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322<SUB_POS_INT>60=262<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            131/70<STOP>

        <GO>6/14<SUB_FRAC>23/10=
            <GO>6*10=60<STOP>
            <GO>23*14=322<STOP>
            <GO>60<SUB_POS_INT>322=-262<STOP>
            <GO>14*10=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            -131/70<STOP>

        <GO>6/14<SUB_FRAC>3/7=
            <GO>6*7=42<STOP>
            <GO>3*14=42<STOP>
            <GO>42<SUB_POS_INT>42=0<STOP>
            0<STOP>

        <GO>23/10<SUB_FRAC>6=
            <GO>23/10<SUB_FRAC>6/1=-37/10<STOP>
            -37/10<STOP><STOP>

        <GO>6<SUB_FRAC>23/10=
            <GO>6/1<SUB_FRAC>23/10<STOP>
            37/10<STOP>

        <GO>6<SUB_FRAC>23=
            <GO>6<SUB_POS_INT>23=-17<STOP>
            -17<STOP>
        <GO>23<SUB_FRAC>6=
            <GO>23<SUB_POS_INT>6=17<STOP>
            17<STOP>
    """"""
name = 'Sub_frac'
dependencies = {
        Mul: lambda config: config,
        Sub_pos_int: lambda config: {'max_digits': config['max_digits'] * 2},
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
symbols = ['<SUB_FRAC>', '-']","(733, 0)","(864, 48)",N,class_definition,Sub_frac,,1207,1d6b1d83-c387-4521-848b-62e1a2742108
"""""""Subtraction of two positive fractions
    E.g.,
        <GO>23/10<SUB_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322<SUB_POS_INT>60=262<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            131/70<STOP>

        <GO>6/14<SUB_FRAC>23/10=
            <GO>6*10=60<STOP>
            <GO>23*14=322<STOP>
            <GO>60<SUB_POS_INT>322=-262<STOP>
            <GO>14*10=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            -131/70<STOP>

        <GO>6/14<SUB_FRAC>3/7=
            <GO>6*7=42<STOP>
            <GO>3*14=42<STOP>
            <GO>42<SUB_POS_INT>42=0<STOP>
            0<STOP>

        <GO>23/10<SUB_FRAC>6=
            <GO>23/10<SUB_FRAC>6/1=-37/10<STOP>
            -37/10<STOP><STOP>

        <GO>6<SUB_FRAC>23/10=
            <GO>6/1<SUB_FRAC>23/10<STOP>
            37/10<STOP>

        <GO>6<SUB_FRAC>23=
            <GO>6<SUB_POS_INT>23=-17<STOP>
            -17<STOP>
        <GO>23<SUB_FRAC>6=
            <GO>23<SUB_POS_INT>6=17<STOP>
            17<STOP>
    """"""
name = 'Sub_frac'
dependencies = {
        Mul: lambda config: config,
        Sub_pos_int: lambda config: {'max_digits': config['max_digits'] * 2},
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
symbols = ['<SUB_FRAC>', '-']",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_frac/,Sub_frac,Previous sibling does not exist,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right","(734, 4)","(779, 33)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,485,6cfe9b0b-7af8-44ce-9a63-bea5bbd8ab34
"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_frac/,Sub_frac,"""""""Subtraction of two positive fractions
    E.g.,
        <GO>23/10<SUB_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322<SUB_POS_INT>60=262<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            131/70<STOP>

        <GO>6/14<SUB_FRAC>23/10=
            <GO>6*10=60<STOP>
            <GO>23*14=322<STOP>
            <GO>60<SUB_POS_INT>322=-262<STOP>
            <GO>14*10=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            -131/70<STOP>

        <GO>6/14<SUB_FRAC>3/7=
            <GO>6*7=42<STOP>
            <GO>3*14=42<STOP>
            <GO>42<SUB_POS_INT>42=0<STOP>
            0<STOP>

        <GO>23/10<SUB_FRAC>6=
            <GO>23/10<SUB_FRAC>6/1=-37/10<STOP>
            -37/10<STOP><STOP>

        <GO>6<SUB_FRAC>23/10=
            <GO>6/1<SUB_FRAC>23/10<STOP>
            37/10<STOP>

        <GO>6<SUB_FRAC>23=
            <GO>6<SUB_POS_INT>23=-17<STOP>
            -17<STOP>
        <GO>23<SUB_FRAC>6=
            <GO>23<SUB_POS_INT>6=17<STOP>
            17<STOP>
    """"""
name = 'Sub_frac'
dependencies = {
        Mul: lambda config: config,
        Sub_pos_int: lambda config: {'max_digits': config['max_digits'] * 2},
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
symbols = ['<SUB_FRAC>', '-']","@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<SUB_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<SUB_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{numer_right}/{denom_right}='","(781, 4)","(800, 26)",N,function_definition,generate,,160,31257ab5-7dfa-483c-a175-6cf9591ed9a3
"@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<SUB_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<SUB_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{numer_right}/{denom_right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_frac/,Sub_frac,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right","@staticmethod
    def answer(args):
        return f'{frac_to_str(Sub_frac.get_answer(args))}<STOP>'","(802, 4)","(816, 89)",N,function_definition,"def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<SUB_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<SUB_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{numer_right}/{denom_right}='",,164,9bcac339-dc6c-4bf3-bd3c-0aa0f91c2242
"@staticmethod
    def answer(args):
        return f'{frac_to_str(Sub_frac.get_answer(args))}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_frac/,Sub_frac,"@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<SUB_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<SUB_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{numer_right}/{denom_right}='","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Sub_pos_int, (left, right))]
        elif isinstance(left, int):
            return [T(Sub_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Sub_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Sub_pos_int, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (abs(numer), denom))]","(818, 4)","(820, 64)",N,function_definition,"def answer(args):
        return f'{frac_to_str(Sub_frac.get_answer(args))}<STOP>'",,24,746d0775-5df3-46dd-9772-c4d6363daa64
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Sub_pos_int, (left, right))]
        elif isinstance(left, int):
            return [T(Sub_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Sub_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Sub_pos_int, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (abs(numer), denom))]",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_frac/,Sub_frac,"@staticmethod
    def answer(args):
        return f'{frac_to_str(Sub_frac.get_answer(args))}<STOP>'","@staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer =  left - right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom - numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = numer_left - right * denom
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

        return Reduce.get_answer((numer, denom))","(822, 4)","(843, 51)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Sub_pos_int, (left, right))]
        elif isinstance(left, int):
            return [T(Sub_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Sub_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Sub_pos_int, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (abs(numer), denom))]",,207,6af75e86-375e-4012-9f17-4a11189f05c9
"@staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer =  left - right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom - numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = numer_left - right * denom
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

        return Reduce.get_answer((numer, denom))",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Sub_frac/,Sub_frac,"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Sub_pos_int, (left, right))]
        elif isinstance(left, int):
            return [T(Sub_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Sub_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Sub_pos_int, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (abs(numer), denom))]",Next sibling does not exist,"(845, 4)","(864, 48)",N,function_definition,"def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer =  left - right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom - numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = numer_left - right * denom
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

        return Reduce.get_answer((numer, denom))",,148,c8f9b25b-bb79-4a44-9734-6d1f88c0f269
"class Mul_frac(Problem):
    """"""Fraction Multiplication
    E.g.,
        <GO>105/10<MUL_FRAC>6/14=
            <GO>105*6=630<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>630/140=9/2<STOP>
            9/2<STOP>

        <GO>105/10<MUL_FRAC>6=
            <GO>105/10<MUL_FRAC>6/1=63<STOP>
            63<STOP>

        <GO>105<MUL_FRAC>6/14=
            <GO>105/1<MUL_FRAC>6/14=45<STOP>
            45<STOP>

        <GO>105<MUL_FRAC>6=
            <GO>105*6=630<STOP>
            630<STOP>
    """"""
    name = 'Mul_frac'
    dependencies = {
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<MUL_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(0, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<MUL_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<MUL_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        return f'{frac_to_str(Mul_frac.get_answer(args))}<STOP>'

    @staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0 or right == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Mul, (left, right))]
        elif isinstance(left, int):
            return [T(Mul_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Mul_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, numer_right)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]

    @staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left * right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

        if numer == 0:
            return 0

        return Reduce.get_answer((numer, denom))",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Sub_frac(Problem):
    """"""Subtraction of two positive fractions
    E.g.,
        <GO>23/10<SUB_FRAC>6/14=
            <GO>23*14=322<STOP>
            <GO>6*10=60<STOP>
            <GO>322<SUB_POS_INT>60=262<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            131/70<STOP>

        <GO>6/14<SUB_FRAC>23/10=
            <GO>6*10=60<STOP>
            <GO>23*14=322<STOP>
            <GO>60<SUB_POS_INT>322=-262<STOP>
            <GO>14*10=140<STOP>
            <GO><REDUCE>262/140=131/70<STOP>
            -131/70<STOP>

        <GO>6/14<SUB_FRAC>3/7=
            <GO>6*7=42<STOP>
            <GO>3*14=42<STOP>
            <GO>42<SUB_POS_INT>42=0<STOP>
            0<STOP>

        <GO>23/10<SUB_FRAC>6=
            <GO>23/10<SUB_FRAC>6/1=-37/10<STOP>
            -37/10<STOP><STOP>

        <GO>6<SUB_FRAC>23/10=
            <GO>6/1<SUB_FRAC>23/10<STOP>
            37/10<STOP>

        <GO>6<SUB_FRAC>23=
            <GO>6<SUB_POS_INT>23=-17<STOP>
            -17<STOP>
        <GO>23<SUB_FRAC>6=
            <GO>23<SUB_POS_INT>6=17<STOP>
            17<STOP>
    """"""
    name = 'Sub_frac'
    dependencies = {
        Mul: lambda config: config,
        Sub_pos_int: lambda config: {'max_digits': config['max_digits'] * 2},
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<SUB_FRAC>', '-']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<SUB_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<SUB_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<SUB_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        return f'{frac_to_str(Sub_frac.get_answer(args))}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        if isinstance(left, int) and isinstance(right, int):
            return [T(Sub_pos_int, (left, right))]
        elif isinstance(left, int):
            return [T(Sub_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Sub_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, denom_right)),
                    T(Mul, (numer_right, denom_left)),
                    T(Sub_pos_int, (numer_left * denom_right, numer_right * denom_left)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (abs(numer), denom))]

    @staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer =  left - right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * denom - numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = numer_left - right * denom
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right

            numer = numer_left * denom_right - numer_right * denom_left
            denom = denom_left * denom_right

        return Reduce.get_answer((numer, denom))","""""""Fraction Multiplication
    E.g.,
        <GO>105/10<MUL_FRAC>6/14=
            <GO>105*6=630<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>630/140=9/2<STOP>
            9/2<STOP>

        <GO>105/10<MUL_FRAC>6=
            <GO>105/10<MUL_FRAC>6/1=63<STOP>
            63<STOP>

        <GO>105<MUL_FRAC>6/14=
            <GO>105/1<MUL_FRAC>6/14=45<STOP>
            45<STOP>

        <GO>105<MUL_FRAC>6=
            <GO>105*6=630<STOP>
            630<STOP>
    """"""
name = 'Mul_frac'
dependencies = {
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
symbols = ['<MUL_FRAC>']","(867, 0)","(980, 48)",N,class_definition,Mul_frac,,950,6754e877-a602-4de9-9670-028973218ff7
"""""""Fraction Multiplication
    E.g.,
        <GO>105/10<MUL_FRAC>6/14=
            <GO>105*6=630<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>630/140=9/2<STOP>
            9/2<STOP>

        <GO>105/10<MUL_FRAC>6=
            <GO>105/10<MUL_FRAC>6/1=63<STOP>
            63<STOP>

        <GO>105<MUL_FRAC>6/14=
            <GO>105/1<MUL_FRAC>6/14=45<STOP>
            45<STOP>

        <GO>105<MUL_FRAC>6=
            <GO>105*6=630<STOP>
            630<STOP>
    """"""
name = 'Mul_frac'
dependencies = {
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
symbols = ['<MUL_FRAC>']",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul_frac/,Mul_frac,Previous sibling does not exist,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(0, max_num)

        return left, right","(868, 4)","(893, 28)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,234,03d621aa-1618-4899-8a60-97f0c394bdcf
"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(0, max_num)

        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul_frac/,Mul_frac,"""""""Fraction Multiplication
    E.g.,
        <GO>105/10<MUL_FRAC>6/14=
            <GO>105*6=630<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>630/140=9/2<STOP>
            9/2<STOP>

        <GO>105/10<MUL_FRAC>6=
            <GO>105/10<MUL_FRAC>6/1=63<STOP>
            63<STOP>

        <GO>105<MUL_FRAC>6/14=
            <GO>105/1<MUL_FRAC>6/14=45<STOP>
            45<STOP>

        <GO>105<MUL_FRAC>6=
            <GO>105*6=630<STOP>
            630<STOP>
    """"""
name = 'Mul_frac'
dependencies = {
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
symbols = ['<MUL_FRAC>']","@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<MUL_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<MUL_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{numer_right}/{denom_right}='","(895, 4)","(914, 26)",N,function_definition,generate,,160,235af0b4-bc21-422f-9bae-0a47ce18bc12
"@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<MUL_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<MUL_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{numer_right}/{denom_right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul_frac/,Mul_frac,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(0, max_num)

        return left, right","@staticmethod
    def answer(args):
        return f'{frac_to_str(Mul_frac.get_answer(args))}<STOP>'","(916, 4)","(930, 89)",N,function_definition,"def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<MUL_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<MUL_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{numer_right}/{denom_right}='",,168,f9d01a66-d30e-4d31-913c-97b154764a15
"@staticmethod
    def answer(args):
        return f'{frac_to_str(Mul_frac.get_answer(args))}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul_frac/,Mul_frac,"@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<MUL_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<MUL_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{numer_right}/{denom_right}='","@staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0 or right == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Mul, (left, right))]
        elif isinstance(left, int):
            return [T(Mul_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Mul_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, numer_right)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]","(932, 4)","(934, 64)",N,function_definition,"def answer(args):
        return f'{frac_to_str(Mul_frac.get_answer(args))}<STOP>'",,25,e9e12372-757e-4154-8747-44b569d913ad
"@staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0 or right == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Mul, (left, right))]
        elif isinstance(left, int):
            return [T(Mul_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Mul_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, numer_right)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul_frac/,Mul_frac,"@staticmethod
    def answer(args):
        return f'{frac_to_str(Mul_frac.get_answer(args))}<STOP>'","@staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left * right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

        if numer == 0:
            return 0

        return Reduce.get_answer((numer, denom))","(936, 4)","(957, 46)",N,function_definition,"def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0 or right == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Mul, (left, right))]
        elif isinstance(left, int):
            return [T(Mul_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Mul_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, numer_right)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]",,195,a93a14b6-32ed-4e00-9195-99123afb4b25
"@staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left * right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

        if numer == 0:
            return 0

        return Reduce.get_answer((numer, denom))",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Mul_frac/,Mul_frac,"@staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0 or right == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Mul, (left, right))]
        elif isinstance(left, int):
            return [T(Mul_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Mul_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, numer_right)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]",Next sibling does not exist,"(959, 4)","(980, 48)",N,function_definition,"def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left * right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

        if numer == 0:
            return 0

        return Reduce.get_answer((numer, denom))",,149,ed8b9782-d8da-4136-a2a1-94a31f3553b2
"class Div_frac(Problem):
    """"""Division between two positive fractions
    E.g.,
        <GO>23/25<DIV_FRAC>6/45=
            <GO>23/25<MUL_FRAC>45/6=345/52<STOP>
            345/52<STOP>

        <GO>23/25<DIV_FRAC>2=
            <GO>23/25<DIV_FRAC>2/1=23/50<STOP>
            23/50<STOP>

        <GO>2<DIV_FRAC>23/25=
            <GO>2/1<DIV_FRAC>23/25<STOP>
            50/23<STOP>

        <GO>23<DIV_FRAC>6=
            <GO><REDUCE>23/6=23/6<STOP>
            23/6<STOP>
    """"""
    name = 'Div_frac'
    dependencies = {
        Reduce: lambda config: config,
        Mul_frac: lambda config: config,
    }
    symbols = ['<DIV_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<DIV_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<DIV_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        return f'{frac_to_str(Div_frac.get_answer(args))}<STOP>'

    @staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Reduce, (left, right))]

        elif isinstance(left, int):
            return [T(Div_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Div_frac, (left, (right, 1)))]
        else:
            numer_right, denom_right = right
            return [T(Mul_frac, (left, (denom_right, numer_right)))]

    @staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left
            denom = right
        elif isinstance(left, int):
            numer_right, denom_right = right
            numer = left * denom_right
            denom = numer_right
        elif isinstance(right, int):
            numer_left, denom_left = left
            numer = numer_left
            denom = denom_left * right
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * denom_right
            denom = denom_left * numer_right

        if numer == 0:
            return 0, 1

        return Reduce.get_answer((numer, denom))",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Mul_frac(Problem):
    """"""Fraction Multiplication
    E.g.,
        <GO>105/10<MUL_FRAC>6/14=
            <GO>105*6=630<STOP>
            <GO>10*14=140<STOP>
            <GO><REDUCE>630/140=9/2<STOP>
            9/2<STOP>

        <GO>105/10<MUL_FRAC>6=
            <GO>105/10<MUL_FRAC>6/1=63<STOP>
            63<STOP>

        <GO>105<MUL_FRAC>6/14=
            <GO>105/1<MUL_FRAC>6/14=45<STOP>
            45<STOP>

        <GO>105<MUL_FRAC>6=
            <GO>105*6=630<STOP>
            630<STOP>
    """"""
    name = 'Mul_frac'
    dependencies = {
        Mul: lambda config: config,
        Reduce: lambda config: {'max_digits': config['max_digits'] * 2},
    }
    symbols = ['<MUL_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(0, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<MUL_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<MUL_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<MUL_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        return f'{frac_to_str(Mul_frac.get_answer(args))}<STOP>'

    @staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0 or right == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Mul, (left, right))]
        elif isinstance(left, int):
            return [T(Mul_frac, ((left, 1), right))]
        elif isinstance(right, int):
            return [T(Mul_frac, (left, (right, 1)))]
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

            return [T(Mul, (numer_left, numer_right)),
                    T(Mul, (denom_left, denom_right)),
                    T(Reduce, (numer, denom))]

    @staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left * right
            denom = 1
        elif isinstance(left, int):
            numer_right, denom = right
            numer = left * numer_right
        elif isinstance(right, int):
            numer_left, denom = left
            numer = right * numer_left
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * numer_right
            denom = denom_left * denom_right

        if numer == 0:
            return 0

        return Reduce.get_answer((numer, denom))","""""""Division between two positive fractions
    E.g.,
        <GO>23/25<DIV_FRAC>6/45=
            <GO>23/25<MUL_FRAC>45/6=345/52<STOP>
            345/52<STOP>

        <GO>23/25<DIV_FRAC>2=
            <GO>23/25<DIV_FRAC>2/1=23/50<STOP>
            23/50<STOP>

        <GO>2<DIV_FRAC>23/25=
            <GO>2/1<DIV_FRAC>23/25<STOP>
            50/23<STOP>

        <GO>23<DIV_FRAC>6=
            <GO><REDUCE>23/6=23/6<STOP>
            23/6<STOP>
    """"""
name = 'Div_frac'
dependencies = {
        Reduce: lambda config: config,
        Mul_frac: lambda config: config,
    }
symbols = ['<DIV_FRAC>']","(983, 0)","(1092, 48)",N,class_definition,Div_frac,,895,ecdabb3c-8ec1-48a7-a63c-fb9100d6deba
"""""""Division between two positive fractions
    E.g.,
        <GO>23/25<DIV_FRAC>6/45=
            <GO>23/25<MUL_FRAC>45/6=345/52<STOP>
            345/52<STOP>

        <GO>23/25<DIV_FRAC>2=
            <GO>23/25<DIV_FRAC>2/1=23/50<STOP>
            23/50<STOP>

        <GO>2<DIV_FRAC>23/25=
            <GO>2/1<DIV_FRAC>23/25<STOP>
            50/23<STOP>

        <GO>23<DIV_FRAC>6=
            <GO><REDUCE>23/6=23/6<STOP>
            23/6<STOP>
    """"""
name = 'Div_frac'
dependencies = {
        Reduce: lambda config: config,
        Mul_frac: lambda config: config,
    }
symbols = ['<DIV_FRAC>']",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div_frac/,Div_frac,Previous sibling does not exist,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right","(984, 4)","(1007, 28)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,217,9ae2a785-c3cb-441b-87e6-66080c99c9da
"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div_frac/,Div_frac,"""""""Division between two positive fractions
    E.g.,
        <GO>23/25<DIV_FRAC>6/45=
            <GO>23/25<MUL_FRAC>45/6=345/52<STOP>
            345/52<STOP>

        <GO>23/25<DIV_FRAC>2=
            <GO>23/25<DIV_FRAC>2/1=23/50<STOP>
            23/50<STOP>

        <GO>2<DIV_FRAC>23/25=
            <GO>2/1<DIV_FRAC>23/25<STOP>
            50/23<STOP>

        <GO>23<DIV_FRAC>6=
            <GO><REDUCE>23/6=23/6<STOP>
            23/6<STOP>
    """"""
name = 'Div_frac'
dependencies = {
        Reduce: lambda config: config,
        Mul_frac: lambda config: config,
    }
symbols = ['<DIV_FRAC>']","@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<DIV_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<DIV_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{numer_right}/{denom_right}='","(1009, 4)","(1028, 26)",N,function_definition,generate,,160,4846b16a-d171-4023-be0b-66513ee3011e
"@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<DIV_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<DIV_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{numer_right}/{denom_right}='",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div_frac/,Div_frac,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right","@staticmethod
    def answer(args):
        return f'{frac_to_str(Div_frac.get_answer(args))}<STOP>'","(1030, 4)","(1044, 89)",N,function_definition,"def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<DIV_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<DIV_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{numer_right}/{denom_right}='",,164,9af33f05-afdd-4c0c-be0b-6486cf72bf91
"@staticmethod
    def answer(args):
        return f'{frac_to_str(Div_frac.get_answer(args))}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div_frac/,Div_frac,"@staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<DIV_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<DIV_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{numer_right}/{denom_right}='","@staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Reduce, (left, right))]

        elif isinstance(left, int):
            return [T(Div_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Div_frac, (left, (right, 1)))]
        else:
            numer_right, denom_right = right
            return [T(Mul_frac, (left, (denom_right, numer_right)))]","(1046, 4)","(1048, 64)",N,function_definition,"def answer(args):
        return f'{frac_to_str(Div_frac.get_answer(args))}<STOP>'",,25,3cf27059-4679-4e23-93d2-0a590ec3f433
"@staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Reduce, (left, right))]

        elif isinstance(left, int):
            return [T(Div_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Div_frac, (left, (right, 1)))]
        else:
            numer_right, denom_right = right
            return [T(Mul_frac, (left, (denom_right, numer_right)))]",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div_frac/,Div_frac,"@staticmethod
    def answer(args):
        return f'{frac_to_str(Div_frac.get_answer(args))}<STOP>'","@staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left
            denom = right
        elif isinstance(left, int):
            numer_right, denom_right = right
            numer = left * denom_right
            denom = numer_right
        elif isinstance(right, int):
            numer_left, denom_left = left
            numer = numer_left
            denom = denom_left * right
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * denom_right
            denom = denom_left * numer_right

        if numer == 0:
            return 0, 1

        return Reduce.get_answer((numer, denom))","(1050, 4)","(1067, 68)",N,function_definition,"def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Reduce, (left, right))]

        elif isinstance(left, int):
            return [T(Div_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Div_frac, (left, (right, 1)))]
        else:
            numer_right, denom_right = right
            return [T(Mul_frac, (left, (denom_right, numer_right)))]",,148,2746de09-c4e3-48be-a521-b81a19f89381
"@staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left
            denom = right
        elif isinstance(left, int):
            numer_right, denom_right = right
            numer = left * denom_right
            denom = numer_right
        elif isinstance(right, int):
            numer_left, denom_left = left
            numer = numer_left
            denom = denom_left * right
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * denom_right
            denom = denom_left * numer_right

        if numer == 0:
            return 0, 1

        return Reduce.get_answer((numer, denom))",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Div_frac/,Div_frac,"@staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Reduce, (left, right))]

        elif isinstance(left, int):
            return [T(Div_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Div_frac, (left, (right, 1)))]
        else:
            numer_right, denom_right = right
            return [T(Mul_frac, (left, (denom_right, numer_right)))]",Next sibling does not exist,"(1069, 4)","(1092, 48)",N,function_definition,"def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left
            denom = right
        elif isinstance(left, int):
            numer_right, denom_right = right
            numer = left * denom_right
            denom = numer_right
        elif isinstance(right, int):
            numer_left, denom_left = left
            numer = numer_left
            denom = denom_left * right
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * denom_right
            denom = denom_left * numer_right

        if numer == 0:
            return 0, 1

        return Reduce.get_answer((numer, denom))",,163,66a569ab-42d9-4df8-b8e5-c26bf1760715
"class Operations(Problem):
    """"""Extension of Four Fundamental Arithmetic Operations to Negative Number
    E.g.,
        # Each operands can be an integer or an fraction
        <GO>23<ADD>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<ADD>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<ADD>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<ADD>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<SUB>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<SUB>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<SUB>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<SUB>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>
        <GO>-23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>-23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>

        <GO>23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
        <GO>-23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>-23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
    """"""
    name = 'Operations'
    dependencies = {
        Add_frac: lambda config: config,
        Sub_frac: lambda config: config,
        Mul_frac: lambda config: config,
        Div_frac: lambda config: config,
    }
    symbols = ['<ADD>', '<SUB>', '<MUL>', '<DIV>', '-', '/']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        prob = random.sample(('Add', 'Sub', 'Mul', 'Div'), 1)[0]
        # prob = random.sample(('Add', 'Sub'), 1)[0]

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            left = negate_frac(left)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            if prob == 'Div':
                right = self.log_randrange(1, max_num)
            else:
                right = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            right = negate_frac(right)

        return prob, left, right

    @staticmethod
    def question(args):
        prob, left, right = args

        q_list = ['<GO>']

        if isinstance(left, int):
            q_list.append(f'{left}')
        else:
            numer_left, denom_left = left
            q_list.append(f'{numer_left}/{denom_left}')

        q_list.append(f'<{prob.upper()}>')

        if isinstance(right, int):
            q_list.append(f'{right}')
        else:
            numer_right, denom_right = right
            q_list.append(f'{numer_right}/{denom_right}')

        q_list.append('=')

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        prob, left, right = args

        if prob == 'Add':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left + right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom + numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left + right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right + numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Sub':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left - right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom - numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left - right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right - numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Mul':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left * right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * numer_right
                denom = denom_left * denom_right

        else:
            if isinstance(left, int) and isinstance(right, int):
                numer = left
                denom = right
            elif isinstance(left, int):
                numer_right, denom_right = right
                numer = left * denom_right
                denom = numer_right
            elif isinstance(right, int):
                numer_left, denom_left = left
                numer = numer_left
                denom = denom_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right
                denom = denom_left * numer_right

        return f'{frac_to_str((numer, denom), reduce=True)}<STOP>'


    @staticmethod
    def thought(args) -> list[T]:
        prob, left, right = args

        if prob == 'Add':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Sub':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Mul':
            thoughts = [T(Mul_frac, (abs_frac(left), abs_frac(right)))]

        else:
            thoughts = [T(Div_frac, (abs_frac(left), abs_frac(right)))]

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Div_frac(Problem):
    """"""Division between two positive fractions
    E.g.,
        <GO>23/25<DIV_FRAC>6/45=
            <GO>23/25<MUL_FRAC>45/6=345/52<STOP>
            345/52<STOP>

        <GO>23/25<DIV_FRAC>2=
            <GO>23/25<DIV_FRAC>2/1=23/50<STOP>
            23/50<STOP>

        <GO>2<DIV_FRAC>23/25=
            <GO>2/1<DIV_FRAC>23/25<STOP>
            50/23<STOP>

        <GO>23<DIV_FRAC>6=
            <GO><REDUCE>23/6=23/6<STOP>
            23/6<STOP>
    """"""
    name = 'Div_frac'
    dependencies = {
        Reduce: lambda config: config,
        Mul_frac: lambda config: config,
    }
    symbols = ['<DIV_FRAC>']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(1, max_num)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            right = self.log_randrange(1, max_num)

        return left, right

    @staticmethod
    def question(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            return f'<GO>{left}<DIV_FRAC>{right}='
        elif isinstance(left, int):
            numer_right, denom_right = right
            return f'<GO>{left}<DIV_FRAC>{numer_right}/{denom_right}='
        elif isinstance(right, int):
            numer_left, denom_left = left
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{right}='
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            return f'<GO>{numer_left}/{denom_left}<DIV_FRAC>{numer_right}/{denom_right}='

    @staticmethod
    def answer(args):
        return f'{frac_to_str(Div_frac.get_answer(args))}<STOP>'

    @staticmethod
    def thought(args, recurse=False) -> list[tuple[str, list[tuple], str]]:
        left, right = args

        if left == 0:
            return []

        if isinstance(left, int) and isinstance(right, int):
            return [T(Reduce, (left, right))]

        elif isinstance(left, int):
            return [T(Div_frac, ((left, 1), right))]

        elif isinstance(right, int):
            return [T(Div_frac, (left, (right, 1)))]
        else:
            numer_right, denom_right = right
            return [T(Mul_frac, (left, (denom_right, numer_right)))]

    @staticmethod
    def get_answer(args):
        left, right = args
        if isinstance(left, int) and isinstance(right, int):
            numer = left
            denom = right
        elif isinstance(left, int):
            numer_right, denom_right = right
            numer = left * denom_right
            denom = numer_right
        elif isinstance(right, int):
            numer_left, denom_left = left
            numer = numer_left
            denom = denom_left * right
        else:
            numer_left, denom_left = left
            numer_right, denom_right = right
            numer = numer_left * denom_right
            denom = denom_left * numer_right

        if numer == 0:
            return 0, 1

        return Reduce.get_answer((numer, denom))","def is_frac_neg(arg):
    if isinstance(arg, int):
        return arg < 0
    else:
        return arg[0] < 0","(1095, 0)","(1309, 23)",N,class_definition,Operations,,1745,acce3dbf-b7b7-45de-95e4-e068508e641d
"""""""Extension of Four Fundamental Arithmetic Operations to Negative Number
    E.g.,
        # Each operands can be an integer or an fraction
        <GO>23<ADD>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<ADD>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<ADD>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<ADD>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<SUB>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<SUB>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<SUB>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<SUB>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>
        <GO>-23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>-23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Operations/,Operations,Previous sibling does not exist,"<GO>23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
        <GO>-23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>-23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
    """"""
name = 'Operations'
dependencies = {
        Add_frac: lambda config: config,
        Sub_frac: lambda config: config,
        Mul_frac: lambda config: config,
        Div_frac: lambda config: config,
    }
symbols = ['<ADD>', '<SUB>', '<MUL>', '<DIV>', '-', '/']","(1096, 4)","(1150, 7)",N,expression_statement,expression_statement,"""""""Extension of Four Fundamental Arithmetic Operations to Negative Number
    E.g.,
        # Each operands can be an integer or an fraction
        <GO>23<ADD>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<ADD>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<ADD>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<ADD>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<SUB>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<SUB>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<SUB>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<SUB>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>
        <GO>-23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>-23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>

        <GO>23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
        <GO>-23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>-23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
    """"""",1152,d7b078b2-3cf9-464b-97ca-6a7076dc6cab
"<GO>23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
        <GO>-23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>-23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
    """"""
name = 'Operations'
dependencies = {
        Add_frac: lambda config: config,
        Sub_frac: lambda config: config,
        Mul_frac: lambda config: config,
        Div_frac: lambda config: config,
    }
symbols = ['<ADD>', '<SUB>', '<MUL>', '<DIV>', '-', '/']",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Operations/,Operations,"""""""Extension of Four Fundamental Arithmetic Operations to Negative Number
    E.g.,
        # Each operands can be an integer or an fraction
        <GO>23<ADD>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<ADD>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<ADD>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<ADD>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<SUB>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<SUB>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<SUB>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<SUB>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>
        <GO>-23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>-23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>","def generate(self):
        max_num = 10 ** self.config['max_digits']

        prob = random.sample(('Add', 'Sub', 'Mul', 'Div'), 1)[0]
        # prob = random.sample(('Add', 'Sub'), 1)[0]

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            left = negate_frac(left)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            if prob == 'Div':
                right = self.log_randrange(1, max_num)
            else:
                right = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            right = negate_frac(right)

        return prob, left, right","(1096, 4)","(1158, 60)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,"""""""Extension of Four Fundamental Arithmetic Operations to Negative Number
    E.g.,
        # Each operands can be an integer or an fraction
        <GO>23<ADD>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<ADD>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<ADD>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<ADD>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<SUB>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<SUB>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<SUB>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<SUB>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>
        <GO>-23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>-23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>

        <GO>23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
        <GO>-23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>-23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
    """"""",414,949b3cd9-56a5-4716-9ea6-c0f8c13b6b7e
"def generate(self):
        max_num = 10 ** self.config['max_digits']

        prob = random.sample(('Add', 'Sub', 'Mul', 'Div'), 1)[0]
        # prob = random.sample(('Add', 'Sub'), 1)[0]

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            left = negate_frac(left)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            if prob == 'Div':
                right = self.log_randrange(1, max_num)
            else:
                right = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            right = negate_frac(right)

        return prob, left, right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Operations/,Operations,"<GO>23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
        <GO>-23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>-23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
    """"""
name = 'Operations'
dependencies = {
        Add_frac: lambda config: config,
        Sub_frac: lambda config: config,
        Mul_frac: lambda config: config,
        Div_frac: lambda config: config,
    }
symbols = ['<ADD>', '<SUB>', '<MUL>', '<DIV>', '-', '/']","@staticmethod
    def question(args):
        prob, left, right = args

        q_list = ['<GO>']

        if isinstance(left, int):
            q_list.append(f'{left}')
        else:
            numer_left, denom_left = left
            q_list.append(f'{numer_left}/{denom_left}')

        q_list.append(f'<{prob.upper()}>')

        if isinstance(right, int):
            q_list.append(f'{right}')
        else:
            numer_right, denom_right = right
            q_list.append(f'{numer_right}/{denom_right}')

        q_list.append('=')

        return ''.join(q_list)","(1160, 4)","(1191, 32)",N,function_definition,generate,,260,707dc1b6-5033-4897-ad0d-83ba1406c926
"@staticmethod
    def question(args):
        prob, left, right = args

        q_list = ['<GO>']

        if isinstance(left, int):
            q_list.append(f'{left}')
        else:
            numer_left, denom_left = left
            q_list.append(f'{numer_left}/{denom_left}')

        q_list.append(f'<{prob.upper()}>')

        if isinstance(right, int):
            q_list.append(f'{right}')
        else:
            numer_right, denom_right = right
            q_list.append(f'{numer_right}/{denom_right}')

        q_list.append('=')

        return ''.join(q_list)",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Operations/,Operations,"def generate(self):
        max_num = 10 ** self.config['max_digits']

        prob = random.sample(('Add', 'Sub', 'Mul', 'Div'), 1)[0]
        # prob = random.sample(('Add', 'Sub'), 1)[0]

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            left = negate_frac(left)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            if prob == 'Div':
                right = self.log_randrange(1, max_num)
            else:
                right = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            right = negate_frac(right)

        return prob, left, right","@staticmethod
    def answer(args):
        prob, left, right = args

        if prob == 'Add':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left + right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom + numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left + right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right + numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Sub':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left - right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom - numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left - right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right - numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Mul':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left * right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * numer_right
                denom = denom_left * denom_right

        else:
            if isinstance(left, int) and isinstance(right, int):
                numer = left
                denom = right
            elif isinstance(left, int):
                numer_right, denom_right = right
                numer = left * denom_right
                denom = numer_right
            elif isinstance(right, int):
                numer_left, denom_left = left
                numer = numer_left
                denom = denom_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right
                denom = denom_left * numer_right

        return f'{frac_to_str((numer, denom), reduce=True)}<STOP>'","(1193, 4)","(1215, 30)",N,function_definition,"def question(args):
        prob, left, right = args

        q_list = ['<GO>']

        if isinstance(left, int):
            q_list.append(f'{left}')
        else:
            numer_left, denom_left = left
            q_list.append(f'{numer_left}/{denom_left}')

        q_list.append(f'<{prob.upper()}>')

        if isinstance(right, int):
            q_list.append(f'{right}')
        else:
            numer_right, denom_right = right
            q_list.append(f'{numer_right}/{denom_right}')

        q_list.append('=')

        return ''.join(q_list)",,131,10835f79-4e37-4328-ad00-b882034fd096
"@staticmethod
    def answer(args):
        prob, left, right = args

        if prob == 'Add':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left + right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom + numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left + right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right + numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Sub':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left - right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom - numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left - right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right - numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Mul':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left * right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * numer_right
                denom = denom_left * denom_right

        else:
            if isinstance(left, int) and isinstance(right, int):
                numer = left
                denom = right
            elif isinstance(left, int):
                numer_right, denom_right = right
                numer = left * denom_right
                denom = numer_right
            elif isinstance(right, int):
                numer_left, denom_left = left
                numer = numer_left
                denom = denom_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right
                denom = denom_left * numer_right

        return f'{frac_to_str((numer, denom), reduce=True)}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Operations/,Operations,"@staticmethod
    def question(args):
        prob, left, right = args

        q_list = ['<GO>']

        if isinstance(left, int):
            q_list.append(f'{left}')
        else:
            numer_left, denom_left = left
            q_list.append(f'{numer_left}/{denom_left}')

        q_list.append(f'<{prob.upper()}>')

        if isinstance(right, int):
            q_list.append(f'{right}')
        else:
            numer_right, denom_right = right
            q_list.append(f'{numer_right}/{denom_right}')

        q_list.append('=')

        return ''.join(q_list)","prob, left, right = args
if prob == 'Add':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left + right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom + numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left + right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right + numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Sub':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left - right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom - numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left - right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right - numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Mul':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left * right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * numer_right
                denom = denom_left * denom_right

        else:
            if isinstance(left, int) and isinstance(right, int):
                numer = left
                denom = right
            elif isinstance(left, int):
                numer_right, denom_right = right
                numer = left * denom_right
                denom = numer_right
            elif isinstance(right, int):
                numer_left, denom_left = left
                numer = numer_left
                denom = denom_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right
                denom = denom_left * numer_right","(1217, 4)","(1284, 66)",N,function_definition,"def answer(args):
        prob, left, right = args

        if prob == 'Add':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left + right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom + numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left + right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right + numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Sub':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left - right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom - numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left - right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right - numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Mul':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left * right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * numer_right
                denom = denom_left * denom_right

        else:
            if isinstance(left, int) and isinstance(right, int):
                numer = left
                denom = right
            elif isinstance(left, int):
                numer_right, denom_right = right
                numer = left * denom_right
                denom = numer_right
            elif isinstance(right, int):
                numer_left, denom_left = left
                numer = numer_left
                denom = denom_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right
                denom = denom_left * numer_right

        return f'{frac_to_str((numer, denom), reduce=True)}<STOP>'",,525,423f2552-6943-45af-86fd-6446e352f9e2
"prob, left, right = args
if prob == 'Add':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left + right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom + numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left + right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right + numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Sub':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left - right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom - numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left - right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right - numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Mul':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left * right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * numer_right
                denom = denom_left * denom_right

        else:
            if isinstance(left, int) and isinstance(right, int):
                numer = left
                denom = right
            elif isinstance(left, int):
                numer_right, denom_right = right
                numer = left * denom_right
                denom = numer_right
            elif isinstance(right, int):
                numer_left, denom_left = left
                numer = numer_left
                denom = denom_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right
                denom = denom_left * numer_right",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Operations/function_definition-answer/,answer,Previous sibling does not exist,"return f'{frac_to_str((numer, denom), reduce=True)}<STOP>'","(1219, 8)","(1282, 48)",N,"expression_statement,if_statement",expression_statement,,495,96dd75a7-0b54-4305-8ab7-8e5b791ad565
"return f'{frac_to_str((numer, denom), reduce=True)}<STOP>'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Operations/function_definition-answer/,answer,"if prob == 'Add':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left + right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom + numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left + right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right + numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Sub':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left - right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom - numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left - right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right - numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Mul':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left * right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * numer_right
                denom = denom_left * denom_right

        else:
            if isinstance(left, int) and isinstance(right, int):
                numer = left
                denom = right
            elif isinstance(left, int):
                numer_right, denom_right = right
                numer = left * denom_right
                denom = numer_right
            elif isinstance(right, int):
                numer_left, denom_left = left
                numer = numer_left
                denom = denom_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right
                denom = denom_left * numer_right",Next sibling does not exist,"(1284, 8)","(1284, 66)",N,return_statement,return_statement,,17,56c834a2-0e91-4159-8b02-45f713c6f59f
"@staticmethod
    def thought(args) -> list[T]:
        prob, left, right = args

        if prob == 'Add':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Sub':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Mul':
            thoughts = [T(Mul_frac, (abs_frac(left), abs_frac(right)))]

        else:
            thoughts = [T(Div_frac, (abs_frac(left), abs_frac(right)))]

        return thoughts",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/class_definition-Operations/,Operations,"return f'{frac_to_str((numer, denom), reduce=True)}<STOP>'",Next sibling does not exist,"(1287, 4)","(1309, 23)",N,function_definition,"def thought(args) -> list[T]:
        prob, left, right = args

        if prob == 'Add':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Sub':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Mul':
            thoughts = [T(Mul_frac, (abs_frac(left), abs_frac(right)))]

        else:
            thoughts = [T(Div_frac, (abs_frac(left), abs_frac(right)))]

        return thoughts",,192,034ff787-0c6d-4f35-97fd-a483564804e1
"def is_frac_neg(arg):
    if isinstance(arg, int):
        return arg < 0
    else:
        return arg[0] < 0",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"class Operations(Problem):
    """"""Extension of Four Fundamental Arithmetic Operations to Negative Number
    E.g.,
        # Each operands can be an integer or an fraction
        <GO>23<ADD>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<ADD>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<ADD>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<ADD>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<SUB>6=
            <GO>23<SUB_FRAC>6=17<STOP>
            17<STOP>
        <GO>-23<SUB>-6=
            <GO>23<SUB_FRAC>6=17<STOP>
            -17<STOP>
        <GO>23<SUB>-6=
            <GO>23<ADD_FRAC>6=29<STOP>
            29<STOP>
        <GO>-23<SUB>6=
            <GO>23<ADD_FRAC>6=29<STOP>
            -29<STOP>

        <GO>23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>
        <GO>-23<MUL>6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            -138<STOP>
        <GO>-23<MUL>-6=
            <GO>23<MUL_FRAC>6=138<STOP>
            138<STOP>

        <GO>23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
        <GO>-23<DIV>6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            -23/6<STOP>
        <GO>-23<DIV>-6=
            <GO>23<DIV_FRAC>6=23/6<STOP>
            23/6<STOP>
    """"""
    name = 'Operations'
    dependencies = {
        Add_frac: lambda config: config,
        Sub_frac: lambda config: config,
        Mul_frac: lambda config: config,
        Div_frac: lambda config: config,
    }
    symbols = ['<ADD>', '<SUB>', '<MUL>', '<DIV>', '-', '/']

    def generate(self):
        max_num = 10 ** self.config['max_digits']

        prob = random.sample(('Add', 'Sub', 'Mul', 'Div'), 1)[0]
        # prob = random.sample(('Add', 'Sub'), 1)[0]

        rand = random.random()
        if rand < 0.7:
            numer_left = self.log_randrange(1, max_num)
            denom_left = self.log_randrange(1, max_num)
            left = (numer_left, denom_left)
        else:
            left = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            left = negate_frac(left)

        rand = random.random()
        if rand < 0.7:
            numer_right = self.log_randrange(1, max_num)
            denom_right = self.log_randrange(1, max_num)
            right = (numer_right, denom_right)
        else:
            if prob == 'Div':
                right = self.log_randrange(1, max_num)
            else:
                right = self.log_randrange(0, max_num)

        if random.random() < 0.5:
            right = negate_frac(right)

        return prob, left, right

    @staticmethod
    def question(args):
        prob, left, right = args

        q_list = ['<GO>']

        if isinstance(left, int):
            q_list.append(f'{left}')
        else:
            numer_left, denom_left = left
            q_list.append(f'{numer_left}/{denom_left}')

        q_list.append(f'<{prob.upper()}>')

        if isinstance(right, int):
            q_list.append(f'{right}')
        else:
            numer_right, denom_right = right
            q_list.append(f'{numer_right}/{denom_right}')

        q_list.append('=')

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        prob, left, right = args

        if prob == 'Add':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left + right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom + numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left + right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right + numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Sub':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left - right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * denom - numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left - right * denom
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right - numer_right * denom_left
                denom = denom_left * denom_right

        elif prob == 'Mul':
            if isinstance(left, int) and isinstance(right, int):
                return f'{left * right}<STOP>'
            elif isinstance(left, int):
                numer_right, denom = right
                numer = left * numer_right
            elif isinstance(right, int):
                numer_left, denom = left
                numer = numer_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * numer_right
                denom = denom_left * denom_right

        else:
            if isinstance(left, int) and isinstance(right, int):
                numer = left
                denom = right
            elif isinstance(left, int):
                numer_right, denom_right = right
                numer = left * denom_right
                denom = numer_right
            elif isinstance(right, int):
                numer_left, denom_left = left
                numer = numer_left
                denom = denom_left * right
            else:
                numer_left, denom_left = left
                numer_right, denom_right = right
                numer = numer_left * denom_right
                denom = denom_left * numer_right

        return f'{frac_to_str((numer, denom), reduce=True)}<STOP>'


    @staticmethod
    def thought(args) -> list[T]:
        prob, left, right = args

        if prob == 'Add':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Sub':
            if is_frac_neg(left) == is_frac_neg(right):
                thoughts = [T(Sub_frac, (abs_frac(left), abs_frac(right)))]
            else:
                thoughts = [T(Add_frac, (abs_frac(left), abs_frac(right)))]

        elif prob == 'Mul':
            thoughts = [T(Mul_frac, (abs_frac(left), abs_frac(right)))]

        else:
            thoughts = [T(Div_frac, (abs_frac(left), abs_frac(right)))]

        return thoughts","def negate_frac(arg):
    if isinstance(arg, int):
        return -arg
    else:
        return -arg[0], arg[1]","(1312, 0)","(1316, 25)",N,function_definition,is_frac_neg,,32,4066779e-65d9-4f9c-aab8-1dce7bd6274c
"def negate_frac(arg):
    if isinstance(arg, int):
        return -arg
    else:
        return -arg[0], arg[1]",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"def is_frac_neg(arg):
    if isinstance(arg, int):
        return arg < 0
    else:
        return arg[0] < 0","def abs_frac(arg):
    if isinstance(arg, int):
        return abs(arg)
    else:
        return abs(arg[0]), arg[1]","(1318, 0)","(1322, 30)",N,function_definition,negate_frac,,31,8d960d1b-25e4-4a8e-8e4f-00350a72be4a
"def abs_frac(arg):
    if isinstance(arg, int):
        return abs(arg)
    else:
        return abs(arg[0]), arg[1]",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"def negate_frac(arg):
    if isinstance(arg, int):
        return -arg
    else:
        return -arg[0], arg[1]","def frac_to_str(frac, reduce=False):
    if isinstance(frac, int):
        return f'{frac}'

    if reduce:
        numer, denom = Reduce.get_answer(frac)
    else:
        numer, denom = frac

    if denom == 1:
        return f'{numer}'
    else:
        return f'{numer}/{denom}'","(1324, 0)","(1328, 34)",N,function_definition,abs_frac,,31,c6e2913d-0dbd-477c-a148-da55981f6b8d
"def frac_to_str(frac, reduce=False):
    if isinstance(frac, int):
        return f'{frac}'

    if reduce:
        numer, denom = Reduce.get_answer(frac)
    else:
        numer, denom = frac

    if denom == 1:
        return f'{numer}'
    else:
        return f'{numer}/{denom}'",arithmetic.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\arithmetic.py,module/,module,"def abs_frac(arg):
    if isinstance(arg, int):
        return abs(arg)
    else:
        return abs(arg[0]), arg[1]",Next sibling does not exist,"(1330, 0)","(1342, 33)",N,function_definition,frac_to_str,,75,33466a49-bc2e-4e9f-9f9b-4536b4c365ed
"from .arithmetic import *


class Linear_1d(Problem):
    """"""Solve 1D Linear Equation with Integer Coefficient
    E.g.,
        <GO><LINEAR_1D>3x=-7<SOLVE>
            <GO>-7<DIV>3=-7/3<STOP>
            x=-7/3<STOP>
        <GO><LINEAR_1D>5y=15<SOLVE>
            <GO>15<DIV>5=3<STOP>
            y=3<STOP>
    """"""
    name = 'Linear_1d'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<LINEAR_1D>', '<SOLVE>', 'x', 'y', '/', '-', '+']

    def generate(self):
        max_coef = 10 ** self.config['max_digits']
        linear = self.log_randrange(1, max_coef)
        if random.random() < 0.5:
            linear = -linear
        constant = self.log_randrange(0, max_coef)
        if random.random() < 0.5:
            constant = -constant

        variable = random.sample(('x', 'y'), 1)[0]

        return variable, linear, constant

    @staticmethod
    def question(args):
        variable, linear, constant = args

        q_list = ['<GO><LINEAR_1D>']

        if linear < 0:
            q_list.append('-')
        if abs(linear) == 1:
            pass
        else:
            q_list.append(f'{abs(linear)}')

        q_list.extend([variable,
                       '=',
                       frac_to_str(constant),
                       '<SOLVE>'])

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        variable, linear, constant = args
        numer, denom = Div_frac.get_answer((constant, linear))

        return f'{variable}={frac_to_str((numer, denom))}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) == 2:
            print(args)
        _, linear, constant = args
        return [T(Operations, ('Div', constant, linear))]


class Mul_both(Problem):
    """"""Multiply a constant to both sides of equation
    E.g.,
        <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
            <GO>1<MUL>8=8<STOP>
            <GO>2<MUL>8=16<STOP>
            <GO>5<MUL>8=40<STOP>
            8x+16=40<STOP>
        <GO><MUL_BOTH>-2x-y=-8<SEP>4<SOLVE>
            <GO>-2<MUL>4=-8<STOP>
            <GO>-1<MUL>4=-4<STOP>
            <GO>-8<MUL>4=-32<STOP>
            -8x-4y=-32<STOP>
        <GO><MUL_BOTH>2x=-8<SEP>4<SOLVE>
            <GO>2<MUL>4=8<STOP>
            <GO>-8<MUL>4=-32<STOP>
            8x=-32<STOP>
    """"""
    name = 'Mul_both'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<MUL_BOTH>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-']

    def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'])

        max_coef = 10 ** self.config['max_digits']
        multiplier = self.log_randrange(1, max_coef)

        return x_coef, y_coef, const, multiplier

    @staticmethod
    def question(args):
        # <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
        x_coef, y_coef, const, multiplier = args

        q_list = ['<GO><MUL_BOTH>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{multiplier}<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 8x+16=40<STOP>
        x_coef, y_coef, const, multiplier = args

        ans = make_linear_2d(x_coef * multiplier,
                                     y_coef * multiplier,
                                     const * multiplier)
        return f'{ans}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, multiplier = args

        thoughts = []
        if x_coef != 0:
            thoughts.append(T(Operations, ('Mul', x_coef, multiplier)))
        if y_coef != 0:
            thoughts.append(T(Operations, ('Mul', y_coef, multiplier)))
        thoughts.append(T(Operations, ('Mul', const, multiplier)))

        return thoughts


class Elim(Problem):
    """"""
    E.g.,
        # Base case
        <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>
            <GO>1<ADD>2=3<STOP>
            <GO>1<ADD>-1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            3x=13<STOP>
        <GO><ELIM>x+y=5<SEP>2x+y=8<SOLVE>
            <GO>1<SUB>2=-1<STOP>
            <GO>1<SUB>1=0<STOP>
            <GO>5<SUB>8=-3<STOP>
            x=3<STOP>
        <GO><ELIM>-2x-y=5<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            0=3<STOP>
        <GO><ELIM>-2x-y=-8<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>-8<ADD>8=0<STOP>
            0=0<STOP>
        # Recursion
        <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <GO><MUL_BOTH>-4x+3y=-8<SEP>7<SOLVE>-28x+21y=-56<STOP>
            <GO><MUL_BOTH>7x-4y=14<SEP>4<SOLVE>28x-16y=56<STOP>
            <GO><ELIM>-28x+21y=-56<SEP>28x-16y=56<SOLVE>5y=0<STOP>
    """"""
    name = 'Elim'
    dependencies = {
        Operations: lambda config: config,
        Mul_both: lambda config: config,
    }
    symbols = ['<ELIM>', '<SOLVE>', '<SEP>', 'x', 'y','+' ,'-']

    def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'])
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'])

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()

        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)

    @staticmethod
    def question(args):
        # <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><ELIM>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 5y=0<STOP>
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            ans = make_linear_2d(0, y_coef_l - y_coef_r, const_l - const_r)
        elif x_coef_l == -x_coef_r:
            ans = make_linear_2d(0, y_coef_l + y_coef_r, const_l + const_r)
        elif y_coef_l == y_coef_r:
            ans = make_linear_2d(x_coef_l - x_coef_r, 0, const_l - const_r)
        elif y_coef_l == -y_coef_r:
            ans = make_linear_2d(x_coef_l + x_coef_r, 0, const_l + const_r)
        else:
            ans = make_linear_2d(0,
                                         y_coef_l * abs(x_coef_r) - y_coef_r * abs(x_coef_l),
                                         const_l * abs(x_coef_r) - const_r * abs(x_coef_l))
        return f'{ans}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r or y_coef_l == y_coef_r:
            thoughts = [T(Operations, ('Sub', x_coef_l, x_coef_r)),
                        T(Operations, ('Sub', y_coef_l, y_coef_r)),
                        T(Operations, ('Sub', const_l, const_r))]

        elif x_coef_l == -x_coef_r or y_coef_l == -y_coef_r:
            thoughts = [T(Operations, ('Add', x_coef_l, x_coef_r)),
                        T(Operations, ('Add', y_coef_l, y_coef_r)),
                        T(Operations, ('Add', const_l, const_r))]
        else:
            thoughts = [T(Mul_both, (x_coef_l, y_coef_l, const_l, abs(x_coef_r))),
                        T(Mul_both, (x_coef_r, y_coef_r, const_r, abs(x_coef_l))),
                        T(Elim,
                         ((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                         (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l)))
                         )
                        ]
        return thoughts

    @staticmethod
    def get_answer(args):
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            return 'y', y_coef_l - y_coef_r, const_l - const_r
        elif x_coef_l == -x_coef_r:
            return 'y', y_coef_l + y_coef_r, const_l + const_r
        elif y_coef_l == y_coef_r:
            return 'x', x_coef_l - x_coef_r, const_l - const_r
        elif y_coef_l == -y_coef_r:
            return 'x', x_coef_l + x_coef_r, const_l + const_r
        else:
            return Elim.get_answer(((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                                    (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l))))


class Substitute(Problem):
    """"""Substitute a variable with a constant in 2d linear equation and solve it
    <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        <GO>2<MUL>13/3=26/3<STOP>
        <GO>5<SUB>26/3=-11/3<STOP>
        3y=-11/3<STOP>
    <GO><SUBSTITUTE>2x+3y=5<SEP>y=13/3<SOLVE>
        <GO>3<MUL>13/3=13<STOP>
        <GO>5<SUB>13=-8<STOP>
        2x=-8<STOP>
    """"""
    name = 'Substitute'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<SUBSTITUTE>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-', '/']

    def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'], 1)
        var = random.sample(('x', 'y'), 1)[0]
        var_value = self.sample_fraction(self.config['max_digits'], reduce=True)
        return x_coef, y_coef, const, var, var_value

    @staticmethod
    def question(args):
        # <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        x_coef, y_coef, const, var, var_value = args

        q_list = ['<GO><SUBSTITUTE>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{var}=',
                  frac_to_str(var_value),
                  '<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 3y=-11/3<STOP>
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            expr = make_linear_2d(0, y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef)))))
        else:
            expr = make_linear_2d(x_coef, 0, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef)))))
        return f'{expr}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            thoughts = [T(Operations, ('Mul', x_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, x_coef))))]
        else:
            thoughts = [T(Operations, ('Mul', y_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, y_coef))))]
        return thoughts

    @staticmethod
    def get_answer(args):
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            return 'y', y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef))))
        else:
            return 'x', x_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef))))


class Linear_2d(Problem):
    """"""Solve 2D Linear Equation
    E.g.,
        <GO><LINEAR_2D>x+y=5<SEP>2x-y=8<SOLVE>
            <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>3x=13<STOP>
            <GO><LINEAR_1D>3x=13<SOLVE>x=13/3<STOP>
            <GO><SUBSTITUTE>x+y=5<SEP>x=13/3<SOLVE>y=2/3<STOP>
            <GO><LINEAR_1D>y=2/3<SOLVE>y=2/3<STOP>
            x=13/3<SEP>y=2/3<STOP>
        <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>5y=0<STOP>
            <GO><LINEAR_1D>5y=0<SOLVE>y=0<STOP>
            <GO><SUBSTITUTE>-4x+3y=-8<SEP>y=0<SOLVE>-4x=-8<STOP>
            <GO><LINEAR_1D>-4x=-8<SOLVE>x=2<STOP>
            x=2<SEP>y=0<STOP>
        # Impossible
        <GO><LINEAR_2D>-32x+24y=-64<SEP>32x-24y=56<SOLVE>
            <GO><ELIM>-32x+24y=-64<SEP>32x-24y=56<SOLVE>0=-8<STOP>
            <NO_SOL><STOP>
        # Indeterminate
        <GO><LINEAR_2D>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>
            <GO><ELIM>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>0=0<STOP>
            <INDET><STOP>
    """"""
    name = 'Linear_2d'
    dependencies = {
        Linear_1d: lambda config: config,
        Elim: lambda config: config,
        Substitute: lambda config: config,
    }
    symbols = ['<LINEAR_2D>', '<SOLVE>', '<SEP>', 'x', 'y', '<NO_SOL>', '<INDET>', '-']

    def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'], min_num=1)
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'], min_num=1)

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()
        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)

    @staticmethod
    def question(args):
        # <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><LINEAR_2D>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # x=2<SEP>y=3<STOP>
        left, right = args

        if Linear_2d.is_impossible_2d(left, right):
            return '<NO_SOL><STOP>'
        if Linear_2d.is_indeterminate_2d(left, right):
            return '<INDET><STOP>'

        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        x_value = frac_to_str((const_l * y_coef_r - const_r * y_coef_l,
                               x_coef_l * y_coef_r - x_coef_r * y_coef_l),
                              reduce = True)
        y_value = frac_to_str((const_l * x_coef_r - const_r * x_coef_l,
                               y_coef_l * x_coef_r - y_coef_r * x_coef_l),
                              reduce = True)

        return f'x={x_value}<SEP>y={y_value}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Elim, (left, right))]

        if Linear_2d.is_impossible_2d(left, right) or Linear_2d.is_indeterminate_2d(left, right):
            return thoughts

        var, linear, const = Elim.get_answer((left, right))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        var_value = Reduce.get_answer((const, linear))
        x_coef_l, y_coef_l, const_l = left
        thoughts.append(T(Substitute, (x_coef_l, y_coef_l, const_l, var, var_value)))

        var, linear, const = Substitute.get_answer((x_coef_l, y_coef_l, const_l, var, var_value))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        return thoughts

    @staticmethod
    def is_impossible_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r != const_r * x_coef_l:
                return True
        return False

    @staticmethod
    def is_indeterminate_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r == const_r * x_coef_l:
                return True
        return False


# class Quadratic_1d(Problem):
#     """"""Solve 2D Linear Equation
#     E.g.,
#         # Base Case: Factorized
#         <GO><QUADRATIC_1D>(x+1)(x+2)=0<SOLVE>
#             <GO><LINEAR_1D>x+1=0<SOLVE>x=-1<STOP>
#             <GO><LINEAR_1D>x+2=0<SOLVE>x=-2<STOP>
#             x=-1<SEP>x=-2<STOP>
#         <GO><QUADRATIC_1D>(2x+1)(3x+2)=0<SOLVE>
#             <GO><LINEAR_1D>2x+1=0<SOLVE>x=-1/2<STOP>
#             <GO><LINEAR_1D>3x+2=0<SOLVE>x=-2/3<STOP>
#             x=-1/2<SEP>x=-2/3<STOP>
#         <GO><QUADRATIC_1D>(2x+1)^2=0<SOLVE>
#             <GO><LINEAR_1D>2x+1=0<SOLVE>x=-1/2<STOP>
#             x=-1/2<STOP>
#         # Solve Recursively: Perfect Square
#         <GO><QUADRATIC_1D>(2x+1)(2x+1)=0<SOLVE>
#             <GO><LINEAR_1D>(2x+1)^2=0<SOLVE>x=-1/2<STOP>
#             x=-1/2<STOP>
#         <GO><QUADRATIC_1D>x^2+2x+1=0<SOLVE>
#             <GO><FACTORIZE>x^2+2x+1<SOLVE>(x+1)^2<STOP>
#             <GO><QUADRATIC_1D>(x+1)^2=0<SOLVE>x=-1<STOP>
#             x=-1<STOP>
#         # Solve Recursively: Factorizable
#         <GO><QUADRATIC_1D>2x^2+3x+1=0<SOLVE>
#             <GO><FACTORIZE>2x^2+3x+1<SOLVE>(2x+1)(x+1)<STOP>
#             <QUADRATIC_1D>(2x+1)(x+1)=0<SOLVE>x=-1/2<SEP>x=-1<STOP>
#             x=-1/2<SEP>x=-1<STOP>
#         # Base case: Fail to factorize -> Check Discriminant
#         <GO><QUADRATIC_1D>2x^2+3x+2=0<SOLVE>
#             <GO><FACTORIZE>2x^2+3x+2<SOLVE><FAIL><STOP>
#             <GO><DISCRIMINANT>2x^2+3x+2<SOLVE>-7<STOP>
#             <NO_SOL><STOP>
#         # Base case: Call Quadratic Formula
#         <GO><QUADRATIC_1D>x^2+3x+1=0<SOLVE>
#             <GO><FACTORIZE>x^2+3x+1<SOLVE><FAIL><STOP>
#             <GO><DISCRIMINANT>x^2+3x+1<SOLVE>5<STOP>
#             <GO><QUAD_FORMULA>x^2+3x+1=0<SOLVE>x=-3/2+<SQRT>5<SEP>x=-3/2-<SQRT>5<STOP>
#             x=-3/2+<SQRT>5<SEP>x=-3/2-<SQRT>5<STOP>
#     """"""
#     name = 'Quadratic_1d'
#     dependencies = {
#         Linear_1d: lambda config: config,
#         # Factorize: lambda config: config,
#         # Discriminant: lambda config: config,
#         # Quad_formula: lambda config: config,
#     }
#     symbols = ['<QUADRATIC_1D>', '<SOLVE>', '<SEP>', '^', 'x', 'y', '<NO_SOL>', '-', '(', ')']
#
#     def generate(self, log_uniform=True):
#         pass
#     @staticmethod
#     def question(args):
#         pass
#     @staticmethod
#     def answer(args):
#         pass
#     @staticmethod
#     def thought(args) -> list[T]:
#         return []

def make_linear_2d(x_coef, y_coef, const):
    """"""Make 2d linear expression with its coefficients""""""
    equation = []

    if x_coef == 0 and y_coef == 0:
        return f'0={frac_to_str(const)}'

    if x_coef != 0:
        if x_coef < 0:
            equation.append('-')
        if abs(x_coef) != 1:
            equation.append(f'{abs(x_coef)}')
        equation.append('x')

    if y_coef != 0:
        if y_coef < 0:
            equation.append('-')
        elif x_coef != 0:
            equation.append('+')
        if abs(y_coef) != 1:
            equation.append(f'{abs(y_coef)}')
        equation.append('y')

    equation.extend([f'={frac_to_str(const)}'])
    return ''.join(equation)",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,,NA,Previous sibling does not exist,Next sibling does not exist,"(0, 0)","(528, 28)",N,module,module,,5812,d4acb57b-36d1-4fee-b82e-c471b6bb5423
from .arithmetic import *,equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,Previous sibling does not exist,"class Linear_1d(Problem):
    """"""Solve 1D Linear Equation with Integer Coefficient
    E.g.,
        <GO><LINEAR_1D>3x=-7<SOLVE>
            <GO>-7<DIV>3=-7/3<STOP>
            x=-7/3<STOP>
        <GO><LINEAR_1D>5y=15<SOLVE>
            <GO>15<DIV>5=3<STOP>
            y=3<STOP>
    """"""
    name = 'Linear_1d'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<LINEAR_1D>', '<SOLVE>', 'x', 'y', '/', '-', '+']

    def generate(self):
        max_coef = 10 ** self.config['max_digits']
        linear = self.log_randrange(1, max_coef)
        if random.random() < 0.5:
            linear = -linear
        constant = self.log_randrange(0, max_coef)
        if random.random() < 0.5:
            constant = -constant

        variable = random.sample(('x', 'y'), 1)[0]

        return variable, linear, constant

    @staticmethod
    def question(args):
        variable, linear, constant = args

        q_list = ['<GO><LINEAR_1D>']

        if linear < 0:
            q_list.append('-')
        if abs(linear) == 1:
            pass
        else:
            q_list.append(f'{abs(linear)}')

        q_list.extend([variable,
                       '=',
                       frac_to_str(constant),
                       '<SOLVE>'])

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        variable, linear, constant = args
        numer, denom = Div_frac.get_answer((constant, linear))

        return f'{variable}={frac_to_str((numer, denom))}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) == 2:
            print(args)
        _, linear, constant = args
        return [T(Operations, ('Div', constant, linear))]","(0, 0)","(0, 25)",N,import_from_statement,import_from_statement,,6,0f344d01-4839-4269-8654-48922b4045a6
"class Linear_1d(Problem):
    """"""Solve 1D Linear Equation with Integer Coefficient
    E.g.,
        <GO><LINEAR_1D>3x=-7<SOLVE>
            <GO>-7<DIV>3=-7/3<STOP>
            x=-7/3<STOP>
        <GO><LINEAR_1D>5y=15<SOLVE>
            <GO>15<DIV>5=3<STOP>
            y=3<STOP>
    """"""
    name = 'Linear_1d'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<LINEAR_1D>', '<SOLVE>', 'x', 'y', '/', '-', '+']

    def generate(self):
        max_coef = 10 ** self.config['max_digits']
        linear = self.log_randrange(1, max_coef)
        if random.random() < 0.5:
            linear = -linear
        constant = self.log_randrange(0, max_coef)
        if random.random() < 0.5:
            constant = -constant

        variable = random.sample(('x', 'y'), 1)[0]

        return variable, linear, constant

    @staticmethod
    def question(args):
        variable, linear, constant = args

        q_list = ['<GO><LINEAR_1D>']

        if linear < 0:
            q_list.append('-')
        if abs(linear) == 1:
            pass
        else:
            q_list.append(f'{abs(linear)}')

        q_list.extend([variable,
                       '=',
                       frac_to_str(constant),
                       '<SOLVE>'])

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        variable, linear, constant = args
        numer, denom = Div_frac.get_answer((constant, linear))

        return f'{variable}={frac_to_str((numer, denom))}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) == 2:
            print(args)
        _, linear, constant = args
        return [T(Operations, ('Div', constant, linear))]",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,from .arithmetic import *,"class Mul_both(Problem):
    """"""Multiply a constant to both sides of equation
    E.g.,
        <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
            <GO>1<MUL>8=8<STOP>
            <GO>2<MUL>8=16<STOP>
            <GO>5<MUL>8=40<STOP>
            8x+16=40<STOP>
        <GO><MUL_BOTH>-2x-y=-8<SEP>4<SOLVE>
            <GO>-2<MUL>4=-8<STOP>
            <GO>-1<MUL>4=-4<STOP>
            <GO>-8<MUL>4=-32<STOP>
            -8x-4y=-32<STOP>
        <GO><MUL_BOTH>2x=-8<SEP>4<SOLVE>
            <GO>2<MUL>4=8<STOP>
            <GO>-8<MUL>4=-32<STOP>
            8x=-32<STOP>
    """"""
    name = 'Mul_both'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<MUL_BOTH>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-']

    def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'])

        max_coef = 10 ** self.config['max_digits']
        multiplier = self.log_randrange(1, max_coef)

        return x_coef, y_coef, const, multiplier

    @staticmethod
    def question(args):
        # <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
        x_coef, y_coef, const, multiplier = args

        q_list = ['<GO><MUL_BOTH>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{multiplier}<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 8x+16=40<STOP>
        x_coef, y_coef, const, multiplier = args

        ans = make_linear_2d(x_coef * multiplier,
                                     y_coef * multiplier,
                                     const * multiplier)
        return f'{ans}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, multiplier = args

        thoughts = []
        if x_coef != 0:
            thoughts.append(T(Operations, ('Mul', x_coef, multiplier)))
        if y_coef != 0:
            thoughts.append(T(Operations, ('Mul', y_coef, multiplier)))
        thoughts.append(T(Operations, ('Mul', const, multiplier)))

        return thoughts","(3, 0)","(64, 57)",N,class_definition,Linear_1d,,460,249d15b5-3f36-451f-bfc1-5f53dcd1368e
"def generate(self):
        max_coef = 10 ** self.config['max_digits']
        linear = self.log_randrange(1, max_coef)
        if random.random() < 0.5:
            linear = -linear
        constant = self.log_randrange(0, max_coef)
        if random.random() < 0.5:
            constant = -constant

        variable = random.sample(('x', 'y'), 1)[0]

        return variable, linear, constant",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_1d/,Linear_1d,"symbols = ['<LINEAR_1D>', '<SOLVE>', 'x', 'y', '/', '-', '+']","@staticmethod
    def question(args):
        variable, linear, constant = args

        q_list = ['<GO><LINEAR_1D>']

        if linear < 0:
            q_list.append('-')
        if abs(linear) == 1:
            pass
        else:
            q_list.append(f'{abs(linear)}')

        q_list.extend([variable,
                       '=',
                       frac_to_str(constant),
                       '<SOLVE>'])

        return ''.join(q_list)","(19, 4)","(30, 41)",N,function_definition,generate,,100,3351e51e-8b60-4b5a-97c9-403e1ec589af
"@staticmethod
    def question(args):
        variable, linear, constant = args

        q_list = ['<GO><LINEAR_1D>']

        if linear < 0:
            q_list.append('-')
        if abs(linear) == 1:
            pass
        else:
            q_list.append(f'{abs(linear)}')

        q_list.extend([variable,
                       '=',
                       frac_to_str(constant),
                       '<SOLVE>'])

        return ''.join(q_list)",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_1d/,Linear_1d,"def generate(self):
        max_coef = 10 ** self.config['max_digits']
        linear = self.log_randrange(1, max_coef)
        if random.random() < 0.5:
            linear = -linear
        constant = self.log_randrange(0, max_coef)
        if random.random() < 0.5:
            constant = -constant

        variable = random.sample(('x', 'y'), 1)[0]

        return variable, linear, constant","@staticmethod
    def answer(args):
        variable, linear, constant = args
        numer, denom = Div_frac.get_answer((constant, linear))

        return f'{variable}={frac_to_str((numer, denom))}<STOP>'","(32, 4)","(50, 30)",N,function_definition,"def question(args):
        variable, linear, constant = args

        q_list = ['<GO><LINEAR_1D>']

        if linear < 0:
            q_list.append('-')
        if abs(linear) == 1:
            pass
        else:
            q_list.append(f'{abs(linear)}')

        q_list.extend([variable,
                       '=',
                       frac_to_str(constant),
                       '<SOLVE>'])

        return ''.join(q_list)",,102,ccf5c51d-bac9-4093-a389-b3aaf5346216
"@staticmethod
    def answer(args):
        variable, linear, constant = args
        numer, denom = Div_frac.get_answer((constant, linear))

        return f'{variable}={frac_to_str((numer, denom))}<STOP>'",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_1d/,Linear_1d,"@staticmethod
    def question(args):
        variable, linear, constant = args

        q_list = ['<GO><LINEAR_1D>']

        if linear < 0:
            q_list.append('-')
        if abs(linear) == 1:
            pass
        else:
            q_list.append(f'{abs(linear)}')

        q_list.extend([variable,
                       '=',
                       frac_to_str(constant),
                       '<SOLVE>'])

        return ''.join(q_list)","@staticmethod
    def thought(args) -> list[T]:
        if len(args) == 2:
            print(args)
        _, linear, constant = args
        return [T(Operations, ('Div', constant, linear))]","(52, 4)","(57, 64)",N,function_definition,"def answer(args):
        variable, linear, constant = args
        numer, denom = Div_frac.get_answer((constant, linear))

        return f'{variable}={frac_to_str((numer, denom))}<STOP>'",,49,1c3524e4-2b59-4a5a-8396-e2a6b38f9ab6
"@staticmethod
    def thought(args) -> list[T]:
        if len(args) == 2:
            print(args)
        _, linear, constant = args
        return [T(Operations, ('Div', constant, linear))]",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_1d/,Linear_1d,"@staticmethod
    def answer(args):
        variable, linear, constant = args
        numer, denom = Div_frac.get_answer((constant, linear))

        return f'{variable}={frac_to_str((numer, denom))}<STOP>'",Next sibling does not exist,"(59, 4)","(64, 57)",N,function_definition,"def thought(args) -> list[T]:
        if len(args) == 2:
            print(args)
        _, linear, constant = args
        return [T(Operations, ('Div', constant, linear))]",,47,2b6fa0e6-f753-4531-94df-d965a8cd45af
"class Mul_both(Problem):
    """"""Multiply a constant to both sides of equation
    E.g.,
        <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
            <GO>1<MUL>8=8<STOP>
            <GO>2<MUL>8=16<STOP>
            <GO>5<MUL>8=40<STOP>
            8x+16=40<STOP>
        <GO><MUL_BOTH>-2x-y=-8<SEP>4<SOLVE>
            <GO>-2<MUL>4=-8<STOP>
            <GO>-1<MUL>4=-4<STOP>
            <GO>-8<MUL>4=-32<STOP>
            -8x-4y=-32<STOP>
        <GO><MUL_BOTH>2x=-8<SEP>4<SOLVE>
            <GO>2<MUL>4=8<STOP>
            <GO>-8<MUL>4=-32<STOP>
            8x=-32<STOP>
    """"""
    name = 'Mul_both'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<MUL_BOTH>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-']

    def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'])

        max_coef = 10 ** self.config['max_digits']
        multiplier = self.log_randrange(1, max_coef)

        return x_coef, y_coef, const, multiplier

    @staticmethod
    def question(args):
        # <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
        x_coef, y_coef, const, multiplier = args

        q_list = ['<GO><MUL_BOTH>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{multiplier}<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 8x+16=40<STOP>
        x_coef, y_coef, const, multiplier = args

        ans = make_linear_2d(x_coef * multiplier,
                                     y_coef * multiplier,
                                     const * multiplier)
        return f'{ans}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, multiplier = args

        thoughts = []
        if x_coef != 0:
            thoughts.append(T(Operations, ('Mul', x_coef, multiplier)))
        if y_coef != 0:
            thoughts.append(T(Operations, ('Mul', y_coef, multiplier)))
        thoughts.append(T(Operations, ('Mul', const, multiplier)))

        return thoughts",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,"class Linear_1d(Problem):
    """"""Solve 1D Linear Equation with Integer Coefficient
    E.g.,
        <GO><LINEAR_1D>3x=-7<SOLVE>
            <GO>-7<DIV>3=-7/3<STOP>
            x=-7/3<STOP>
        <GO><LINEAR_1D>5y=15<SOLVE>
            <GO>15<DIV>5=3<STOP>
            y=3<STOP>
    """"""
    name = 'Linear_1d'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<LINEAR_1D>', '<SOLVE>', 'x', 'y', '/', '-', '+']

    def generate(self):
        max_coef = 10 ** self.config['max_digits']
        linear = self.log_randrange(1, max_coef)
        if random.random() < 0.5:
            linear = -linear
        constant = self.log_randrange(0, max_coef)
        if random.random() < 0.5:
            constant = -constant

        variable = random.sample(('x', 'y'), 1)[0]

        return variable, linear, constant

    @staticmethod
    def question(args):
        variable, linear, constant = args

        q_list = ['<GO><LINEAR_1D>']

        if linear < 0:
            q_list.append('-')
        if abs(linear) == 1:
            pass
        else:
            q_list.append(f'{abs(linear)}')

        q_list.extend([variable,
                       '=',
                       frac_to_str(constant),
                       '<SOLVE>'])

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        variable, linear, constant = args
        numer, denom = Div_frac.get_answer((constant, linear))

        return f'{variable}={frac_to_str((numer, denom))}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) == 2:
            print(args)
        _, linear, constant = args
        return [T(Operations, ('Div', constant, linear))]","""""""Multiply a constant to both sides of equation
    E.g.,
        <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
            <GO>1<MUL>8=8<STOP>
            <GO>2<MUL>8=16<STOP>
            <GO>5<MUL>8=40<STOP>
            8x+16=40<STOP>
        <GO><MUL_BOTH>-2x-y=-8<SEP>4<SOLVE>
            <GO>-2<MUL>4=-8<STOP>
            <GO>-1<MUL>4=-4<STOP>
            <GO>-8<MUL>4=-32<STOP>
            -8x-4y=-32<STOP>
        <GO><MUL_BOTH>2x=-8<SEP>4<SOLVE>
            <GO>2<MUL>4=8<STOP>
            <GO>-8<MUL>4=-32<STOP>
            8x=-32<STOP>
    """"""
name = 'Mul_both'
dependencies = {
        Operations: lambda config: config,
    }
symbols = ['<MUL_BOTH>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-']","(67, 0)","(131, 23)",N,class_definition,Mul_both,,585,86141951-99c8-4716-8696-1021a341df98
"""""""Multiply a constant to both sides of equation
    E.g.,
        <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
            <GO>1<MUL>8=8<STOP>
            <GO>2<MUL>8=16<STOP>
            <GO>5<MUL>8=40<STOP>
            8x+16=40<STOP>
        <GO><MUL_BOTH>-2x-y=-8<SEP>4<SOLVE>
            <GO>-2<MUL>4=-8<STOP>
            <GO>-1<MUL>4=-4<STOP>
            <GO>-8<MUL>4=-32<STOP>
            -8x-4y=-32<STOP>
        <GO><MUL_BOTH>2x=-8<SEP>4<SOLVE>
            <GO>2<MUL>4=8<STOP>
            <GO>-8<MUL>4=-32<STOP>
            8x=-32<STOP>
    """"""
name = 'Mul_both'
dependencies = {
        Operations: lambda config: config,
    }
symbols = ['<MUL_BOTH>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-']",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Mul_both/,Mul_both,Previous sibling does not exist,"def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'])

        max_coef = 10 ** self.config['max_digits']
        multiplier = self.log_randrange(1, max_coef)

        return x_coef, y_coef, const, multiplier","(68, 4)","(89, 68)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,263,7e84fde1-5ab7-4849-be40-ede288cad385
"def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'])

        max_coef = 10 ** self.config['max_digits']
        multiplier = self.log_randrange(1, max_coef)

        return x_coef, y_coef, const, multiplier",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Mul_both/,Mul_both,"""""""Multiply a constant to both sides of equation
    E.g.,
        <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
            <GO>1<MUL>8=8<STOP>
            <GO>2<MUL>8=16<STOP>
            <GO>5<MUL>8=40<STOP>
            8x+16=40<STOP>
        <GO><MUL_BOTH>-2x-y=-8<SEP>4<SOLVE>
            <GO>-2<MUL>4=-8<STOP>
            <GO>-1<MUL>4=-4<STOP>
            <GO>-8<MUL>4=-32<STOP>
            -8x-4y=-32<STOP>
        <GO><MUL_BOTH>2x=-8<SEP>4<SOLVE>
            <GO>2<MUL>4=8<STOP>
            <GO>-8<MUL>4=-32<STOP>
            8x=-32<STOP>
    """"""
name = 'Mul_both'
dependencies = {
        Operations: lambda config: config,
    }
symbols = ['<MUL_BOTH>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-']","@staticmethod
    def question(args):
        # <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
        x_coef, y_coef, const, multiplier = args

        q_list = ['<GO><MUL_BOTH>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{multiplier}<SOLVE>']

        return ''.join(q_list)","(91, 4)","(97, 48)",N,function_definition,generate,,62,49a9cc7a-48e9-4904-aff1-7ba23088ad78
"@staticmethod
    def question(args):
        # <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
        x_coef, y_coef, const, multiplier = args

        q_list = ['<GO><MUL_BOTH>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{multiplier}<SOLVE>']

        return ''.join(q_list)",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Mul_both/,Mul_both,"def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'])

        max_coef = 10 ** self.config['max_digits']
        multiplier = self.log_randrange(1, max_coef)

        return x_coef, y_coef, const, multiplier","@staticmethod
    def answer(args):
        # 8x+16=40<STOP>
        x_coef, y_coef, const, multiplier = args

        ans = make_linear_2d(x_coef * multiplier,
                                     y_coef * multiplier,
                                     const * multiplier)
        return f'{ans}<STOP>'","(99, 4)","(108, 30)",N,function_definition,"def question(args):
        # <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
        x_coef, y_coef, const, multiplier = args

        q_list = ['<GO><MUL_BOTH>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{multiplier}<SOLVE>']

        return ''.join(q_list)",,87,c9b2cebe-3369-4906-b2d2-5abc778908de
"@staticmethod
    def answer(args):
        # 8x+16=40<STOP>
        x_coef, y_coef, const, multiplier = args

        ans = make_linear_2d(x_coef * multiplier,
                                     y_coef * multiplier,
                                     const * multiplier)
        return f'{ans}<STOP>'",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Mul_both/,Mul_both,"@staticmethod
    def question(args):
        # <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
        x_coef, y_coef, const, multiplier = args

        q_list = ['<GO><MUL_BOTH>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{multiplier}<SOLVE>']

        return ''.join(q_list)","@staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, multiplier = args

        thoughts = []
        if x_coef != 0:
            thoughts.append(T(Operations, ('Mul', x_coef, multiplier)))
        if y_coef != 0:
            thoughts.append(T(Operations, ('Mul', y_coef, multiplier)))
        thoughts.append(T(Operations, ('Mul', const, multiplier)))

        return thoughts","(110, 4)","(118, 29)",N,function_definition,"def answer(args):
        # 8x+16=40<STOP>
        x_coef, y_coef, const, multiplier = args

        ans = make_linear_2d(x_coef * multiplier,
                                     y_coef * multiplier,
                                     const * multiplier)
        return f'{ans}<STOP>'",,65,fa66930d-34b2-4aff-9cc9-49adc91caf17
"@staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, multiplier = args

        thoughts = []
        if x_coef != 0:
            thoughts.append(T(Operations, ('Mul', x_coef, multiplier)))
        if y_coef != 0:
            thoughts.append(T(Operations, ('Mul', y_coef, multiplier)))
        thoughts.append(T(Operations, ('Mul', const, multiplier)))

        return thoughts",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Mul_both/,Mul_both,"@staticmethod
    def answer(args):
        # 8x+16=40<STOP>
        x_coef, y_coef, const, multiplier = args

        ans = make_linear_2d(x_coef * multiplier,
                                     y_coef * multiplier,
                                     const * multiplier)
        return f'{ans}<STOP>'",Next sibling does not exist,"(120, 4)","(131, 23)",N,function_definition,"def thought(args) -> list[T]:
        x_coef, y_coef, const, multiplier = args

        thoughts = []
        if x_coef != 0:
            thoughts.append(T(Operations, ('Mul', x_coef, multiplier)))
        if y_coef != 0:
            thoughts.append(T(Operations, ('Mul', y_coef, multiplier)))
        thoughts.append(T(Operations, ('Mul', const, multiplier)))

        return thoughts",,92,7fbdffa3-935e-424a-a23e-d841a228f83b
"class Elim(Problem):
    """"""
    E.g.,
        # Base case
        <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>
            <GO>1<ADD>2=3<STOP>
            <GO>1<ADD>-1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            3x=13<STOP>
        <GO><ELIM>x+y=5<SEP>2x+y=8<SOLVE>
            <GO>1<SUB>2=-1<STOP>
            <GO>1<SUB>1=0<STOP>
            <GO>5<SUB>8=-3<STOP>
            x=3<STOP>
        <GO><ELIM>-2x-y=5<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            0=3<STOP>
        <GO><ELIM>-2x-y=-8<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>-8<ADD>8=0<STOP>
            0=0<STOP>
        # Recursion
        <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <GO><MUL_BOTH>-4x+3y=-8<SEP>7<SOLVE>-28x+21y=-56<STOP>
            <GO><MUL_BOTH>7x-4y=14<SEP>4<SOLVE>28x-16y=56<STOP>
            <GO><ELIM>-28x+21y=-56<SEP>28x-16y=56<SOLVE>5y=0<STOP>
    """"""
    name = 'Elim'
    dependencies = {
        Operations: lambda config: config,
        Mul_both: lambda config: config,
    }
    symbols = ['<ELIM>', '<SOLVE>', '<SEP>', 'x', 'y','+' ,'-']

    def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'])
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'])

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()

        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)

    @staticmethod
    def question(args):
        # <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><ELIM>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 5y=0<STOP>
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            ans = make_linear_2d(0, y_coef_l - y_coef_r, const_l - const_r)
        elif x_coef_l == -x_coef_r:
            ans = make_linear_2d(0, y_coef_l + y_coef_r, const_l + const_r)
        elif y_coef_l == y_coef_r:
            ans = make_linear_2d(x_coef_l - x_coef_r, 0, const_l - const_r)
        elif y_coef_l == -y_coef_r:
            ans = make_linear_2d(x_coef_l + x_coef_r, 0, const_l + const_r)
        else:
            ans = make_linear_2d(0,
                                         y_coef_l * abs(x_coef_r) - y_coef_r * abs(x_coef_l),
                                         const_l * abs(x_coef_r) - const_r * abs(x_coef_l))
        return f'{ans}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r or y_coef_l == y_coef_r:
            thoughts = [T(Operations, ('Sub', x_coef_l, x_coef_r)),
                        T(Operations, ('Sub', y_coef_l, y_coef_r)),
                        T(Operations, ('Sub', const_l, const_r))]

        elif x_coef_l == -x_coef_r or y_coef_l == -y_coef_r:
            thoughts = [T(Operations, ('Add', x_coef_l, x_coef_r)),
                        T(Operations, ('Add', y_coef_l, y_coef_r)),
                        T(Operations, ('Add', const_l, const_r))]
        else:
            thoughts = [T(Mul_both, (x_coef_l, y_coef_l, const_l, abs(x_coef_r))),
                        T(Mul_both, (x_coef_r, y_coef_r, const_r, abs(x_coef_l))),
                        T(Elim,
                         ((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                         (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l)))
                         )
                        ]
        return thoughts

    @staticmethod
    def get_answer(args):
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            return 'y', y_coef_l - y_coef_r, const_l - const_r
        elif x_coef_l == -x_coef_r:
            return 'y', y_coef_l + y_coef_r, const_l + const_r
        elif y_coef_l == y_coef_r:
            return 'x', x_coef_l - x_coef_r, const_l - const_r
        elif y_coef_l == -y_coef_r:
            return 'x', x_coef_l + x_coef_r, const_l + const_r
        else:
            return Elim.get_answer(((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                                    (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l))))",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,"class Mul_both(Problem):
    """"""Multiply a constant to both sides of equation
    E.g.,
        <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
            <GO>1<MUL>8=8<STOP>
            <GO>2<MUL>8=16<STOP>
            <GO>5<MUL>8=40<STOP>
            8x+16=40<STOP>
        <GO><MUL_BOTH>-2x-y=-8<SEP>4<SOLVE>
            <GO>-2<MUL>4=-8<STOP>
            <GO>-1<MUL>4=-4<STOP>
            <GO>-8<MUL>4=-32<STOP>
            -8x-4y=-32<STOP>
        <GO><MUL_BOTH>2x=-8<SEP>4<SOLVE>
            <GO>2<MUL>4=8<STOP>
            <GO>-8<MUL>4=-32<STOP>
            8x=-32<STOP>
    """"""
    name = 'Mul_both'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<MUL_BOTH>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-']

    def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'])

        max_coef = 10 ** self.config['max_digits']
        multiplier = self.log_randrange(1, max_coef)

        return x_coef, y_coef, const, multiplier

    @staticmethod
    def question(args):
        # <GO><MUL_BOTH>x+2y=5<SEP>8<SOLVE>
        x_coef, y_coef, const, multiplier = args

        q_list = ['<GO><MUL_BOTH>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{multiplier}<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 8x+16=40<STOP>
        x_coef, y_coef, const, multiplier = args

        ans = make_linear_2d(x_coef * multiplier,
                                     y_coef * multiplier,
                                     const * multiplier)
        return f'{ans}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, multiplier = args

        thoughts = []
        if x_coef != 0:
            thoughts.append(T(Operations, ('Mul', x_coef, multiplier)))
        if y_coef != 0:
            thoughts.append(T(Operations, ('Mul', y_coef, multiplier)))
        thoughts.append(T(Operations, ('Mul', const, multiplier)))

        return thoughts","""""""
    E.g.,
        # Base case
        <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>
            <GO>1<ADD>2=3<STOP>
            <GO>1<ADD>-1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            3x=13<STOP>
        <GO><ELIM>x+y=5<SEP>2x+y=8<SOLVE>
            <GO>1<SUB>2=-1<STOP>
            <GO>1<SUB>1=0<STOP>
            <GO>5<SUB>8=-3<STOP>
            x=3<STOP>
        <GO><ELIM>-2x-y=5<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            0=3<STOP>
        <GO><ELIM>-2x-y=-8<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>-8<ADD>8=0<STOP>
            0=0<STOP>
        # Recursion
        <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <GO><MUL_BOTH>-4x+3y=-8<SEP>7<SOLVE>-28x+21y=-56<STOP>
            <GO><MUL_BOTH>7x-4y=14<SEP>4<SOLVE>28x-16y=56<STOP>
            <GO><ELIM>-28x+21y=-56<SEP>28x-16y=56<SOLVE>5y=0<STOP>
    """"""
name = 'Elim'
dependencies = {
        Operations: lambda config: config,
        Mul_both: lambda config: config,
    }
symbols = ['<ELIM>', '<SOLVE>', '<SEP>', 'x', 'y','+' ,'-']","(134, 0)","(256, 115)",N,class_definition,Elim,,1508,42601597-f161-4543-8c5b-4d04fbb0444e
"""""""
    E.g.,
        # Base case
        <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>
            <GO>1<ADD>2=3<STOP>
            <GO>1<ADD>-1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            3x=13<STOP>
        <GO><ELIM>x+y=5<SEP>2x+y=8<SOLVE>
            <GO>1<SUB>2=-1<STOP>
            <GO>1<SUB>1=0<STOP>
            <GO>5<SUB>8=-3<STOP>
            x=3<STOP>
        <GO><ELIM>-2x-y=5<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            0=3<STOP>
        <GO><ELIM>-2x-y=-8<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>-8<ADD>8=0<STOP>
            0=0<STOP>
        # Recursion
        <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <GO><MUL_BOTH>-4x+3y=-8<SEP>7<SOLVE>-28x+21y=-56<STOP>
            <GO><MUL_BOTH>7x-4y=14<SEP>4<SOLVE>28x-16y=56<STOP>
            <GO><ELIM>-28x+21y=-56<SEP>28x-16y=56<SOLVE>5y=0<STOP>
    """"""
name = 'Elim'
dependencies = {
        Operations: lambda config: config,
        Mul_both: lambda config: config,
    }
symbols = ['<ELIM>', '<SOLVE>', '<SEP>', 'x', 'y','+' ,'-']",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Elim/,Elim,Previous sibling does not exist,"def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'])
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'])

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()

        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)","(135, 4)","(169, 63)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,481,edfd287f-3e8d-4fae-b15b-35d46c1eb96e
"def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'])
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'])

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()

        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Elim/,Elim,"""""""
    E.g.,
        # Base case
        <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>
            <GO>1<ADD>2=3<STOP>
            <GO>1<ADD>-1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            3x=13<STOP>
        <GO><ELIM>x+y=5<SEP>2x+y=8<SOLVE>
            <GO>1<SUB>2=-1<STOP>
            <GO>1<SUB>1=0<STOP>
            <GO>5<SUB>8=-3<STOP>
            x=3<STOP>
        <GO><ELIM>-2x-y=5<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            0=3<STOP>
        <GO><ELIM>-2x-y=-8<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>-8<ADD>8=0<STOP>
            0=0<STOP>
        # Recursion
        <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <GO><MUL_BOTH>-4x+3y=-8<SEP>7<SOLVE>-28x+21y=-56<STOP>
            <GO><MUL_BOTH>7x-4y=14<SEP>4<SOLVE>28x-16y=56<STOP>
            <GO><ELIM>-28x+21y=-56<SEP>28x-16y=56<SOLVE>5y=0<STOP>
    """"""
name = 'Elim'
dependencies = {
        Operations: lambda config: config,
        Mul_both: lambda config: config,
    }
symbols = ['<ELIM>', '<SOLVE>', '<SEP>', 'x', 'y','+' ,'-']","@staticmethod
    def question(args):
        # <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><ELIM>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)","(171, 4)","(179, 75)",N,function_definition,generate,,120,e0a73240-1872-4fe8-9fe5-ada6cd1c8ddd
"@staticmethod
    def question(args):
        # <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><ELIM>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Elim/,Elim,"def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'])
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'])

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()

        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)","@staticmethod
    def answer(args):
        # 5y=0<STOP>
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            ans = make_linear_2d(0, y_coef_l - y_coef_r, const_l - const_r)
        elif x_coef_l == -x_coef_r:
            ans = make_linear_2d(0, y_coef_l + y_coef_r, const_l + const_r)
        elif y_coef_l == y_coef_r:
            ans = make_linear_2d(x_coef_l - x_coef_r, 0, const_l - const_r)
        elif y_coef_l == -y_coef_r:
            ans = make_linear_2d(x_coef_l + x_coef_r, 0, const_l + const_r)
        else:
            ans = make_linear_2d(0,
                                         y_coef_l * abs(x_coef_r) - y_coef_r * abs(x_coef_l),
                                         const_l * abs(x_coef_r) - const_r * abs(x_coef_l))
        return f'{ans}<STOP>'","(181, 4)","(192, 30)",N,function_definition,"def question(args):
        # <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><ELIM>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)",,107,464feb59-99a0-459e-a9ff-b4ef60dba077
"@staticmethod
    def answer(args):
        # 5y=0<STOP>
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            ans = make_linear_2d(0, y_coef_l - y_coef_r, const_l - const_r)
        elif x_coef_l == -x_coef_r:
            ans = make_linear_2d(0, y_coef_l + y_coef_r, const_l + const_r)
        elif y_coef_l == y_coef_r:
            ans = make_linear_2d(x_coef_l - x_coef_r, 0, const_l - const_r)
        elif y_coef_l == -y_coef_r:
            ans = make_linear_2d(x_coef_l + x_coef_r, 0, const_l + const_r)
        else:
            ans = make_linear_2d(0,
                                         y_coef_l * abs(x_coef_r) - y_coef_r * abs(x_coef_l),
                                         const_l * abs(x_coef_r) - const_r * abs(x_coef_l))
        return f'{ans}<STOP>'",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Elim/,Elim,"@staticmethod
    def question(args):
        # <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><ELIM>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)","@staticmethod
    def thought(args) -> list[T]:
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r or y_coef_l == y_coef_r:
            thoughts = [T(Operations, ('Sub', x_coef_l, x_coef_r)),
                        T(Operations, ('Sub', y_coef_l, y_coef_r)),
                        T(Operations, ('Sub', const_l, const_r))]

        elif x_coef_l == -x_coef_r or y_coef_l == -y_coef_r:
            thoughts = [T(Operations, ('Add', x_coef_l, x_coef_r)),
                        T(Operations, ('Add', y_coef_l, y_coef_r)),
                        T(Operations, ('Add', const_l, const_r))]
        else:
            thoughts = [T(Mul_both, (x_coef_l, y_coef_l, const_l, abs(x_coef_r))),
                        T(Mul_both, (x_coef_r, y_coef_r, const_r, abs(x_coef_l))),
                        T(Elim,
                         ((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                         (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l)))
                         )
                        ]
        return thoughts","(194, 4)","(213, 29)",N,function_definition,"def answer(args):
        # 5y=0<STOP>
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            ans = make_linear_2d(0, y_coef_l - y_coef_r, const_l - const_r)
        elif x_coef_l == -x_coef_r:
            ans = make_linear_2d(0, y_coef_l + y_coef_r, const_l + const_r)
        elif y_coef_l == y_coef_r:
            ans = make_linear_2d(x_coef_l - x_coef_r, 0, const_l - const_r)
        elif y_coef_l == -y_coef_r:
            ans = make_linear_2d(x_coef_l + x_coef_r, 0, const_l + const_r)
        else:
            ans = make_linear_2d(0,
                                         y_coef_l * abs(x_coef_r) - y_coef_r * abs(x_coef_l),
                                         const_l * abs(x_coef_r) - const_r * abs(x_coef_l))
        return f'{ans}<STOP>'",,255,30c39a14-948b-43a4-af49-7c58035c31b6
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r or y_coef_l == y_coef_r:
            thoughts = [T(Operations, ('Sub', x_coef_l, x_coef_r)),
                        T(Operations, ('Sub', y_coef_l, y_coef_r)),
                        T(Operations, ('Sub', const_l, const_r))]

        elif x_coef_l == -x_coef_r or y_coef_l == -y_coef_r:
            thoughts = [T(Operations, ('Add', x_coef_l, x_coef_r)),
                        T(Operations, ('Add', y_coef_l, y_coef_r)),
                        T(Operations, ('Add', const_l, const_r))]
        else:
            thoughts = [T(Mul_both, (x_coef_l, y_coef_l, const_l, abs(x_coef_r))),
                        T(Mul_both, (x_coef_r, y_coef_r, const_r, abs(x_coef_l))),
                        T(Elim,
                         ((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                         (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l)))
                         )
                        ]
        return thoughts",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Elim/,Elim,"@staticmethod
    def answer(args):
        # 5y=0<STOP>
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            ans = make_linear_2d(0, y_coef_l - y_coef_r, const_l - const_r)
        elif x_coef_l == -x_coef_r:
            ans = make_linear_2d(0, y_coef_l + y_coef_r, const_l + const_r)
        elif y_coef_l == y_coef_r:
            ans = make_linear_2d(x_coef_l - x_coef_r, 0, const_l - const_r)
        elif y_coef_l == -y_coef_r:
            ans = make_linear_2d(x_coef_l + x_coef_r, 0, const_l + const_r)
        else:
            ans = make_linear_2d(0,
                                         y_coef_l * abs(x_coef_r) - y_coef_r * abs(x_coef_l),
                                         const_l * abs(x_coef_r) - const_r * abs(x_coef_l))
        return f'{ans}<STOP>'","@staticmethod
    def get_answer(args):
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            return 'y', y_coef_l - y_coef_r, const_l - const_r
        elif x_coef_l == -x_coef_r:
            return 'y', y_coef_l + y_coef_r, const_l + const_r
        elif y_coef_l == y_coef_r:
            return 'x', x_coef_l - x_coef_r, const_l - const_r
        elif y_coef_l == -y_coef_r:
            return 'x', x_coef_l + x_coef_r, const_l + const_r
        else:
            return Elim.get_answer(((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                                    (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l))))","(215, 4)","(238, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r or y_coef_l == y_coef_r:
            thoughts = [T(Operations, ('Sub', x_coef_l, x_coef_r)),
                        T(Operations, ('Sub', y_coef_l, y_coef_r)),
                        T(Operations, ('Sub', const_l, const_r))]

        elif x_coef_l == -x_coef_r or y_coef_l == -y_coef_r:
            thoughts = [T(Operations, ('Add', x_coef_l, x_coef_r)),
                        T(Operations, ('Add', y_coef_l, y_coef_r)),
                        T(Operations, ('Add', const_l, const_r))]
        else:
            thoughts = [T(Mul_both, (x_coef_l, y_coef_l, const_l, abs(x_coef_r))),
                        T(Mul_both, (x_coef_r, y_coef_r, const_r, abs(x_coef_l))),
                        T(Elim,
                         ((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                         (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l)))
                         )
                        ]
        return thoughts",,304,91e538a0-fcee-4fcb-99e5-e299461d03fe
"@staticmethod
    def get_answer(args):
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            return 'y', y_coef_l - y_coef_r, const_l - const_r
        elif x_coef_l == -x_coef_r:
            return 'y', y_coef_l + y_coef_r, const_l + const_r
        elif y_coef_l == y_coef_r:
            return 'x', x_coef_l - x_coef_r, const_l - const_r
        elif y_coef_l == -y_coef_r:
            return 'x', x_coef_l + x_coef_r, const_l + const_r
        else:
            return Elim.get_answer(((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                                    (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l))))",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Elim/,Elim,"@staticmethod
    def thought(args) -> list[T]:
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r or y_coef_l == y_coef_r:
            thoughts = [T(Operations, ('Sub', x_coef_l, x_coef_r)),
                        T(Operations, ('Sub', y_coef_l, y_coef_r)),
                        T(Operations, ('Sub', const_l, const_r))]

        elif x_coef_l == -x_coef_r or y_coef_l == -y_coef_r:
            thoughts = [T(Operations, ('Add', x_coef_l, x_coef_r)),
                        T(Operations, ('Add', y_coef_l, y_coef_r)),
                        T(Operations, ('Add', const_l, const_r))]
        else:
            thoughts = [T(Mul_both, (x_coef_l, y_coef_l, const_l, abs(x_coef_r))),
                        T(Mul_both, (x_coef_r, y_coef_r, const_r, abs(x_coef_l))),
                        T(Elim,
                         ((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                         (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l)))
                         )
                        ]
        return thoughts",Next sibling does not exist,"(240, 4)","(256, 115)",N,function_definition,"def get_answer(args):
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            return 'y', y_coef_l - y_coef_r, const_l - const_r
        elif x_coef_l == -x_coef_r:
            return 'y', y_coef_l + y_coef_r, const_l + const_r
        elif y_coef_l == y_coef_r:
            return 'x', x_coef_l - x_coef_r, const_l - const_r
        elif y_coef_l == -y_coef_r:
            return 'x', x_coef_l + x_coef_r, const_l + const_r
        else:
            return Elim.get_answer(((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                                    (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l))))",,225,49cdef80-e2a9-444f-9500-ae662fcebc39
"class Substitute(Problem):
    """"""Substitute a variable with a constant in 2d linear equation and solve it
    <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        <GO>2<MUL>13/3=26/3<STOP>
        <GO>5<SUB>26/3=-11/3<STOP>
        3y=-11/3<STOP>
    <GO><SUBSTITUTE>2x+3y=5<SEP>y=13/3<SOLVE>
        <GO>3<MUL>13/3=13<STOP>
        <GO>5<SUB>13=-8<STOP>
        2x=-8<STOP>
    """"""
    name = 'Substitute'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<SUBSTITUTE>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-', '/']

    def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'], 1)
        var = random.sample(('x', 'y'), 1)[0]
        var_value = self.sample_fraction(self.config['max_digits'], reduce=True)
        return x_coef, y_coef, const, var, var_value

    @staticmethod
    def question(args):
        # <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        x_coef, y_coef, const, var, var_value = args

        q_list = ['<GO><SUBSTITUTE>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{var}=',
                  frac_to_str(var_value),
                  '<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 3y=-11/3<STOP>
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            expr = make_linear_2d(0, y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef)))))
        else:
            expr = make_linear_2d(x_coef, 0, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef)))))
        return f'{expr}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            thoughts = [T(Operations, ('Mul', x_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, x_coef))))]
        else:
            thoughts = [T(Operations, ('Mul', y_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, y_coef))))]
        return thoughts

    @staticmethod
    def get_answer(args):
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            return 'y', y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef))))
        else:
            return 'x', x_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef))))",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,"class Elim(Problem):
    """"""
    E.g.,
        # Base case
        <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>
            <GO>1<ADD>2=3<STOP>
            <GO>1<ADD>-1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            3x=13<STOP>
        <GO><ELIM>x+y=5<SEP>2x+y=8<SOLVE>
            <GO>1<SUB>2=-1<STOP>
            <GO>1<SUB>1=0<STOP>
            <GO>5<SUB>8=-3<STOP>
            x=3<STOP>
        <GO><ELIM>-2x-y=5<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>5<ADD>8=13<STOP>
            0=3<STOP>
        <GO><ELIM>-2x-y=-8<SEP>2x+y=8<SOLVE>
            <GO>-2<ADD>2=0<STOP>
            <GO>-1<ADD>1=0<STOP>
            <GO>-8<ADD>8=0<STOP>
            0=0<STOP>
        # Recursion
        <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <GO><MUL_BOTH>-4x+3y=-8<SEP>7<SOLVE>-28x+21y=-56<STOP>
            <GO><MUL_BOTH>7x-4y=14<SEP>4<SOLVE>28x-16y=56<STOP>
            <GO><ELIM>-28x+21y=-56<SEP>28x-16y=56<SOLVE>5y=0<STOP>
    """"""
    name = 'Elim'
    dependencies = {
        Operations: lambda config: config,
        Mul_both: lambda config: config,
    }
    symbols = ['<ELIM>', '<SOLVE>', '<SEP>', 'x', 'y','+' ,'-']

    def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'])
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'])

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()

        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)

    @staticmethod
    def question(args):
        # <GO><ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><ELIM>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 5y=0<STOP>
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            ans = make_linear_2d(0, y_coef_l - y_coef_r, const_l - const_r)
        elif x_coef_l == -x_coef_r:
            ans = make_linear_2d(0, y_coef_l + y_coef_r, const_l + const_r)
        elif y_coef_l == y_coef_r:
            ans = make_linear_2d(x_coef_l - x_coef_r, 0, const_l - const_r)
        elif y_coef_l == -y_coef_r:
            ans = make_linear_2d(x_coef_l + x_coef_r, 0, const_l + const_r)
        else:
            ans = make_linear_2d(0,
                                         y_coef_l * abs(x_coef_r) - y_coef_r * abs(x_coef_l),
                                         const_l * abs(x_coef_r) - const_r * abs(x_coef_l))
        return f'{ans}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r or y_coef_l == y_coef_r:
            thoughts = [T(Operations, ('Sub', x_coef_l, x_coef_r)),
                        T(Operations, ('Sub', y_coef_l, y_coef_r)),
                        T(Operations, ('Sub', const_l, const_r))]

        elif x_coef_l == -x_coef_r or y_coef_l == -y_coef_r:
            thoughts = [T(Operations, ('Add', x_coef_l, x_coef_r)),
                        T(Operations, ('Add', y_coef_l, y_coef_r)),
                        T(Operations, ('Add', const_l, const_r))]
        else:
            thoughts = [T(Mul_both, (x_coef_l, y_coef_l, const_l, abs(x_coef_r))),
                        T(Mul_both, (x_coef_r, y_coef_r, const_r, abs(x_coef_l))),
                        T(Elim,
                         ((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                         (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l)))
                         )
                        ]
        return thoughts

    @staticmethod
    def get_answer(args):
        left, right = args
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l == x_coef_r:
            return 'y', y_coef_l - y_coef_r, const_l - const_r
        elif x_coef_l == -x_coef_r:
            return 'y', y_coef_l + y_coef_r, const_l + const_r
        elif y_coef_l == y_coef_r:
            return 'x', x_coef_l - x_coef_r, const_l - const_r
        elif y_coef_l == -y_coef_r:
            return 'x', x_coef_l + x_coef_r, const_l + const_r
        else:
            return Elim.get_answer(((x_coef_l * abs(x_coef_r), y_coef_l * abs(x_coef_r), const_l * abs(x_coef_r)),
                                    (x_coef_r * abs(x_coef_l), y_coef_r * abs(x_coef_l), const_r * abs(x_coef_l))))","""""""Substitute a variable with a constant in 2d linear equation and solve it
    <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        <GO>2<MUL>13/3=26/3<STOP>
        <GO>5<SUB>26/3=-11/3<STOP>
        3y=-11/3<STOP>
    <GO><SUBSTITUTE>2x+3y=5<SEP>y=13/3<SOLVE>
        <GO>3<MUL>13/3=13<STOP>
        <GO>5<SUB>13=-8<STOP>
        2x=-8<STOP>
    """"""
name = 'Substitute'
dependencies = {
        Operations: lambda config: config,
    }
symbols = ['<SUBSTITUTE>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-', '/']","(259, 0)","(322, 102)",N,class_definition,Substitute,,715,aaea8850-9254-42d1-ae23-dd0507658961
"""""""Substitute a variable with a constant in 2d linear equation and solve it
    <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        <GO>2<MUL>13/3=26/3<STOP>
        <GO>5<SUB>26/3=-11/3<STOP>
        3y=-11/3<STOP>
    <GO><SUBSTITUTE>2x+3y=5<SEP>y=13/3<SOLVE>
        <GO>3<MUL>13/3=13<STOP>
        <GO>5<SUB>13=-8<STOP>
        2x=-8<STOP>
    """"""
name = 'Substitute'
dependencies = {
        Operations: lambda config: config,
    }
symbols = ['<SUBSTITUTE>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-', '/']",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Substitute/,Substitute,Previous sibling does not exist,"def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'], 1)
        var = random.sample(('x', 'y'), 1)[0]
        var_value = self.sample_fraction(self.config['max_digits'], reduce=True)
        return x_coef, y_coef, const, var, var_value","(260, 4)","(274, 75)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,198,7f54a211-ad7b-4aac-bd51-962f4f5f25d9
"def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'], 1)
        var = random.sample(('x', 'y'), 1)[0]
        var_value = self.sample_fraction(self.config['max_digits'], reduce=True)
        return x_coef, y_coef, const, var, var_value",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Substitute/,Substitute,"""""""Substitute a variable with a constant in 2d linear equation and solve it
    <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        <GO>2<MUL>13/3=26/3<STOP>
        <GO>5<SUB>26/3=-11/3<STOP>
        3y=-11/3<STOP>
    <GO><SUBSTITUTE>2x+3y=5<SEP>y=13/3<SOLVE>
        <GO>3<MUL>13/3=13<STOP>
        <GO>5<SUB>13=-8<STOP>
        2x=-8<STOP>
    """"""
name = 'Substitute'
dependencies = {
        Operations: lambda config: config,
    }
symbols = ['<SUBSTITUTE>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-', '/']","@staticmethod
    def question(args):
        # <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        x_coef, y_coef, const, var, var_value = args

        q_list = ['<GO><SUBSTITUTE>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{var}=',
                  frac_to_str(var_value),
                  '<SOLVE>']

        return ''.join(q_list)","(276, 4)","(280, 52)",N,function_definition,generate,,74,d2021cad-941f-4f4f-9604-f579f5401049
"@staticmethod
    def question(args):
        # <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        x_coef, y_coef, const, var, var_value = args

        q_list = ['<GO><SUBSTITUTE>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{var}=',
                  frac_to_str(var_value),
                  '<SOLVE>']

        return ''.join(q_list)",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Substitute/,Substitute,"def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'], 1)
        var = random.sample(('x', 'y'), 1)[0]
        var_value = self.sample_fraction(self.config['max_digits'], reduce=True)
        return x_coef, y_coef, const, var, var_value","@staticmethod
    def answer(args):
        # 3y=-11/3<STOP>
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            expr = make_linear_2d(0, y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef)))))
        else:
            expr = make_linear_2d(x_coef, 0, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef)))))
        return f'{expr}<STOP>'","(282, 4)","(293, 30)",N,function_definition,"def question(args):
        # <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        x_coef, y_coef, const, var, var_value = args

        q_list = ['<GO><SUBSTITUTE>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{var}=',
                  frac_to_str(var_value),
                  '<SOLVE>']

        return ''.join(q_list)",,102,019749ce-876c-4651-9e50-fae5c7e7c095
"@staticmethod
    def answer(args):
        # 3y=-11/3<STOP>
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            expr = make_linear_2d(0, y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef)))))
        else:
            expr = make_linear_2d(x_coef, 0, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef)))))
        return f'{expr}<STOP>'",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Substitute/,Substitute,"@staticmethod
    def question(args):
        # <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        x_coef, y_coef, const, var, var_value = args

        q_list = ['<GO><SUBSTITUTE>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{var}=',
                  frac_to_str(var_value),
                  '<SOLVE>']

        return ''.join(q_list)","@staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            thoughts = [T(Operations, ('Mul', x_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, x_coef))))]
        else:
            thoughts = [T(Operations, ('Mul', y_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, y_coef))))]
        return thoughts","(295, 4)","(303, 30)",N,function_definition,"def answer(args):
        # 3y=-11/3<STOP>
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            expr = make_linear_2d(0, y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef)))))
        else:
            expr = make_linear_2d(x_coef, 0, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef)))))
        return f'{expr}<STOP>'",,118,0deb9746-b977-4cc2-bdc9-ea57c0bb80b9
"@staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            thoughts = [T(Operations, ('Mul', x_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, x_coef))))]
        else:
            thoughts = [T(Operations, ('Mul', y_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, y_coef))))]
        return thoughts",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Substitute/,Substitute,"@staticmethod
    def answer(args):
        # 3y=-11/3<STOP>
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            expr = make_linear_2d(0, y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef)))))
        else:
            expr = make_linear_2d(x_coef, 0, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef)))))
        return f'{expr}<STOP>'","@staticmethod
    def get_answer(args):
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            return 'y', y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef))))
        else:
            return 'x', x_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef))))","(305, 4)","(314, 23)",N,function_definition,"def thought(args) -> list[T]:
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            thoughts = [T(Operations, ('Mul', x_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, x_coef))))]
        else:
            thoughts = [T(Operations, ('Mul', y_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, y_coef))))]
        return thoughts",,119,e93cd2e9-c96b-4ac6-829a-533a435e5833
"@staticmethod
    def get_answer(args):
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            return 'y', y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef))))
        else:
            return 'x', x_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef))))",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Substitute/,Substitute,"@staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            thoughts = [T(Operations, ('Mul', x_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, x_coef))))]
        else:
            thoughts = [T(Operations, ('Mul', y_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, y_coef))))]
        return thoughts",Next sibling does not exist,"(316, 4)","(322, 102)",N,function_definition,"def get_answer(args):
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            return 'y', y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef))))
        else:
            return 'x', x_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef))))",,87,eb3fb2e6-1f6c-4d41-85c0-3c92fa5a3e63
"class Linear_2d(Problem):
    """"""Solve 2D Linear Equation
    E.g.,
        <GO><LINEAR_2D>x+y=5<SEP>2x-y=8<SOLVE>
            <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>3x=13<STOP>
            <GO><LINEAR_1D>3x=13<SOLVE>x=13/3<STOP>
            <GO><SUBSTITUTE>x+y=5<SEP>x=13/3<SOLVE>y=2/3<STOP>
            <GO><LINEAR_1D>y=2/3<SOLVE>y=2/3<STOP>
            x=13/3<SEP>y=2/3<STOP>
        <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>5y=0<STOP>
            <GO><LINEAR_1D>5y=0<SOLVE>y=0<STOP>
            <GO><SUBSTITUTE>-4x+3y=-8<SEP>y=0<SOLVE>-4x=-8<STOP>
            <GO><LINEAR_1D>-4x=-8<SOLVE>x=2<STOP>
            x=2<SEP>y=0<STOP>
        # Impossible
        <GO><LINEAR_2D>-32x+24y=-64<SEP>32x-24y=56<SOLVE>
            <GO><ELIM>-32x+24y=-64<SEP>32x-24y=56<SOLVE>0=-8<STOP>
            <NO_SOL><STOP>
        # Indeterminate
        <GO><LINEAR_2D>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>
            <GO><ELIM>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>0=0<STOP>
            <INDET><STOP>
    """"""
    name = 'Linear_2d'
    dependencies = {
        Linear_1d: lambda config: config,
        Elim: lambda config: config,
        Substitute: lambda config: config,
    }
    symbols = ['<LINEAR_2D>', '<SOLVE>', '<SEP>', 'x', 'y', '<NO_SOL>', '<INDET>', '-']

    def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'], min_num=1)
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'], min_num=1)

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()
        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)

    @staticmethod
    def question(args):
        # <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><LINEAR_2D>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # x=2<SEP>y=3<STOP>
        left, right = args

        if Linear_2d.is_impossible_2d(left, right):
            return '<NO_SOL><STOP>'
        if Linear_2d.is_indeterminate_2d(left, right):
            return '<INDET><STOP>'

        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        x_value = frac_to_str((const_l * y_coef_r - const_r * y_coef_l,
                               x_coef_l * y_coef_r - x_coef_r * y_coef_l),
                              reduce = True)
        y_value = frac_to_str((const_l * x_coef_r - const_r * x_coef_l,
                               y_coef_l * x_coef_r - y_coef_r * x_coef_l),
                              reduce = True)

        return f'x={x_value}<SEP>y={y_value}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Elim, (left, right))]

        if Linear_2d.is_impossible_2d(left, right) or Linear_2d.is_indeterminate_2d(left, right):
            return thoughts

        var, linear, const = Elim.get_answer((left, right))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        var_value = Reduce.get_answer((const, linear))
        x_coef_l, y_coef_l, const_l = left
        thoughts.append(T(Substitute, (x_coef_l, y_coef_l, const_l, var, var_value)))

        var, linear, const = Substitute.get_answer((x_coef_l, y_coef_l, const_l, var, var_value))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        return thoughts

    @staticmethod
    def is_impossible_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r != const_r * x_coef_l:
                return True
        return False

    @staticmethod
    def is_indeterminate_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r == const_r * x_coef_l:
                return True
        return False",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,"class Substitute(Problem):
    """"""Substitute a variable with a constant in 2d linear equation and solve it
    <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        <GO>2<MUL>13/3=26/3<STOP>
        <GO>5<SUB>26/3=-11/3<STOP>
        3y=-11/3<STOP>
    <GO><SUBSTITUTE>2x+3y=5<SEP>y=13/3<SOLVE>
        <GO>3<MUL>13/3=13<STOP>
        <GO>5<SUB>13=-8<STOP>
        2x=-8<STOP>
    """"""
    name = 'Substitute'
    dependencies = {
        Operations: lambda config: config,
    }
    symbols = ['<SUBSTITUTE>', '<SOLVE>', '<SEP>', 'x', 'y', '+', '-', '/']

    def generate(self):
        x_coef, y_coef, const = self.sample_linear_2d(self.config['max_digits'], 1)
        var = random.sample(('x', 'y'), 1)[0]
        var_value = self.sample_fraction(self.config['max_digits'], reduce=True)
        return x_coef, y_coef, const, var, var_value

    @staticmethod
    def question(args):
        # <GO><SUBSTITUTE>2x+3y=5<SEP>x=13/3<SOLVE>
        x_coef, y_coef, const, var, var_value = args

        q_list = ['<GO><SUBSTITUTE>',
                  make_linear_2d(x_coef, y_coef, const),
                  f'<SEP>{var}=',
                  frac_to_str(var_value),
                  '<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # 3y=-11/3<STOP>
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            expr = make_linear_2d(0, y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef)))))
        else:
            expr = make_linear_2d(x_coef, 0, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef)))))
        return f'{expr}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            thoughts = [T(Operations, ('Mul', x_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, x_coef))))]
        else:
            thoughts = [T(Operations, ('Mul', y_coef, var_value)),
                        T(Operations, ('Sub', const, Mul_frac.get_answer((var_value, y_coef))))]
        return thoughts

    @staticmethod
    def get_answer(args):
        x_coef, y_coef, const, var, var_value = args
        if var == 'x':
            return 'y', y_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, x_coef))))
        else:
            return 'x', x_coef, Sub_frac.get_answer((const, Mul_frac.get_answer((var_value, y_coef))))","""""""Solve 2D Linear Equation
    E.g.,
        <GO><LINEAR_2D>x+y=5<SEP>2x-y=8<SOLVE>
            <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>3x=13<STOP>
            <GO><LINEAR_1D>3x=13<SOLVE>x=13/3<STOP>
            <GO><SUBSTITUTE>x+y=5<SEP>x=13/3<SOLVE>y=2/3<STOP>
            <GO><LINEAR_1D>y=2/3<SOLVE>y=2/3<STOP>
            x=13/3<SEP>y=2/3<STOP>
        <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>5y=0<STOP>
            <GO><LINEAR_1D>5y=0<SOLVE>y=0<STOP>
            <GO><SUBSTITUTE>-4x+3y=-8<SEP>y=0<SOLVE>-4x=-8<STOP>
            <GO><LINEAR_1D>-4x=-8<SOLVE>x=2<STOP>
            x=2<SEP>y=0<STOP>
        # Impossible
        <GO><LINEAR_2D>-32x+24y=-64<SEP>32x-24y=56<SOLVE>
            <GO><ELIM>-32x+24y=-64<SEP>32x-24y=56<SOLVE>0=-8<STOP>
            <NO_SOL><STOP>
        # Indeterminate
        <GO><LINEAR_2D>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>
            <GO><ELIM>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>0=0<STOP>
            <INDET><STOP>
    """"""
name = 'Linear_2d'
dependencies = {
        Linear_1d: lambda config: config,
        Elim: lambda config: config,
        Substitute: lambda config: config,
    }","(325, 0)","(440, 20)",N,class_definition,Linear_2d,,1366,8cdc89bc-82b0-4845-8922-4e0cd21d8451
"""""""Solve 2D Linear Equation
    E.g.,
        <GO><LINEAR_2D>x+y=5<SEP>2x-y=8<SOLVE>
            <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>3x=13<STOP>
            <GO><LINEAR_1D>3x=13<SOLVE>x=13/3<STOP>
            <GO><SUBSTITUTE>x+y=5<SEP>x=13/3<SOLVE>y=2/3<STOP>
            <GO><LINEAR_1D>y=2/3<SOLVE>y=2/3<STOP>
            x=13/3<SEP>y=2/3<STOP>
        <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>5y=0<STOP>
            <GO><LINEAR_1D>5y=0<SOLVE>y=0<STOP>
            <GO><SUBSTITUTE>-4x+3y=-8<SEP>y=0<SOLVE>-4x=-8<STOP>
            <GO><LINEAR_1D>-4x=-8<SOLVE>x=2<STOP>
            x=2<SEP>y=0<STOP>
        # Impossible
        <GO><LINEAR_2D>-32x+24y=-64<SEP>32x-24y=56<SOLVE>
            <GO><ELIM>-32x+24y=-64<SEP>32x-24y=56<SOLVE>0=-8<STOP>
            <NO_SOL><STOP>
        # Indeterminate
        <GO><LINEAR_2D>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>
            <GO><ELIM>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>0=0<STOP>
            <INDET><STOP>
    """"""
name = 'Linear_2d'
dependencies = {
        Linear_1d: lambda config: config,
        Elim: lambda config: config,
        Substitute: lambda config: config,
    }",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_2d/,Linear_2d,Previous sibling does not exist,"symbols = ['<LINEAR_2D>', '<SOLVE>', '<SEP>', 'x', 'y', '<NO_SOL>', '<INDET>', '-']","(326, 4)","(354, 5)",N,"expression_statement,expression_statement,expression_statement",expression_statement,,494,00528300-f741-477e-b0db-02fba09563c6
"symbols = ['<LINEAR_2D>', '<SOLVE>', '<SEP>', 'x', 'y', '<NO_SOL>', '<INDET>', '-']",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_2d/,Linear_2d,"dependencies = {
        Linear_1d: lambda config: config,
        Elim: lambda config: config,
        Substitute: lambda config: config,
    }","def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'], min_num=1)
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'], min_num=1)

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()
        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)","(355, 4)","(355, 87)",N,expression_statement,expression_statement,,33,58ba6bf1-157c-4857-ae45-7fa9ad8bc3ef
"def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'], min_num=1)
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'], min_num=1)

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()
        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_2d/,Linear_2d,"symbols = ['<LINEAR_2D>', '<SOLVE>', '<SEP>', 'x', 'y', '<NO_SOL>', '<INDET>', '-']","@staticmethod
    def question(args):
        # <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><LINEAR_2D>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)","(357, 4)","(364, 75)",N,function_definition,generate,,130,34126f92-fdb8-4fc6-bd71-53b3b99990c0
"@staticmethod
    def question(args):
        # <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><LINEAR_2D>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_2d/,Linear_2d,"def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'], min_num=1)
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'], min_num=1)

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()
        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)","@staticmethod
    def answer(args):
        # x=2<SEP>y=3<STOP>
        left, right = args

        if Linear_2d.is_impossible_2d(left, right):
            return '<NO_SOL><STOP>'
        if Linear_2d.is_indeterminate_2d(left, right):
            return '<INDET><STOP>'

        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        x_value = frac_to_str((const_l * y_coef_r - const_r * y_coef_l,
                               x_coef_l * y_coef_r - x_coef_r * y_coef_l),
                              reduce = True)
        y_value = frac_to_str((const_l * x_coef_r - const_r * x_coef_l,
                               y_coef_l * x_coef_r - y_coef_r * x_coef_l),
                              reduce = True)

        return f'x={x_value}<SEP>y={y_value}<STOP>'","(366, 4)","(377, 30)",N,function_definition,"def question(args):
        # <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><LINEAR_2D>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)",,113,f762bcdf-a9ef-48bf-a64c-555f60b1427c
"@staticmethod
    def answer(args):
        # x=2<SEP>y=3<STOP>
        left, right = args

        if Linear_2d.is_impossible_2d(left, right):
            return '<NO_SOL><STOP>'
        if Linear_2d.is_indeterminate_2d(left, right):
            return '<INDET><STOP>'

        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        x_value = frac_to_str((const_l * y_coef_r - const_r * y_coef_l,
                               x_coef_l * y_coef_r - x_coef_r * y_coef_l),
                              reduce = True)
        y_value = frac_to_str((const_l * x_coef_r - const_r * x_coef_l,
                               y_coef_l * x_coef_r - y_coef_r * x_coef_l),
                              reduce = True)

        return f'x={x_value}<SEP>y={y_value}<STOP>'",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_2d/,Linear_2d,"@staticmethod
    def question(args):
        # <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><LINEAR_2D>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)","@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Elim, (left, right))]

        if Linear_2d.is_impossible_2d(left, right) or Linear_2d.is_indeterminate_2d(left, right):
            return thoughts

        var, linear, const = Elim.get_answer((left, right))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        var_value = Reduce.get_answer((const, linear))
        x_coef_l, y_coef_l, const_l = left
        thoughts.append(T(Substitute, (x_coef_l, y_coef_l, const_l, var, var_value)))

        var, linear, const = Substitute.get_answer((x_coef_l, y_coef_l, const_l, var, var_value))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        return thoughts","(379, 4)","(399, 51)",N,function_definition,"def answer(args):
        # x=2<SEP>y=3<STOP>
        left, right = args

        if Linear_2d.is_impossible_2d(left, right):
            return '<NO_SOL><STOP>'
        if Linear_2d.is_indeterminate_2d(left, right):
            return '<INDET><STOP>'

        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        x_value = frac_to_str((const_l * y_coef_r - const_r * y_coef_l,
                               x_coef_l * y_coef_r - x_coef_r * y_coef_l),
                              reduce = True)
        y_value = frac_to_str((const_l * x_coef_r - const_r * x_coef_l,
                               y_coef_l * x_coef_r - y_coef_r * x_coef_l),
                              reduce = True)

        return f'x={x_value}<SEP>y={y_value}<STOP>'",,210,73dabb7a-8fdb-46a8-a422-ae872b203ef4
"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Elim, (left, right))]

        if Linear_2d.is_impossible_2d(left, right) or Linear_2d.is_indeterminate_2d(left, right):
            return thoughts

        var, linear, const = Elim.get_answer((left, right))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        var_value = Reduce.get_answer((const, linear))
        x_coef_l, y_coef_l, const_l = left
        thoughts.append(T(Substitute, (x_coef_l, y_coef_l, const_l, var, var_value)))

        var, linear, const = Substitute.get_answer((x_coef_l, y_coef_l, const_l, var, var_value))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        return thoughts",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_2d/,Linear_2d,"@staticmethod
    def answer(args):
        # x=2<SEP>y=3<STOP>
        left, right = args

        if Linear_2d.is_impossible_2d(left, right):
            return '<NO_SOL><STOP>'
        if Linear_2d.is_indeterminate_2d(left, right):
            return '<INDET><STOP>'

        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        x_value = frac_to_str((const_l * y_coef_r - const_r * y_coef_l,
                               x_coef_l * y_coef_r - x_coef_r * y_coef_l),
                              reduce = True)
        y_value = frac_to_str((const_l * x_coef_r - const_r * x_coef_l,
                               y_coef_l * x_coef_r - y_coef_r * x_coef_l),
                              reduce = True)

        return f'x={x_value}<SEP>y={y_value}<STOP>'","@staticmethod
    def is_impossible_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r != const_r * x_coef_l:
                return True
        return False","(401, 4)","(420, 23)",N,function_definition,"def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Elim, (left, right))]

        if Linear_2d.is_impossible_2d(left, right) or Linear_2d.is_indeterminate_2d(left, right):
            return thoughts

        var, linear, const = Elim.get_answer((left, right))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        var_value = Reduce.get_answer((const, linear))
        x_coef_l, y_coef_l, const_l = left
        thoughts.append(T(Substitute, (x_coef_l, y_coef_l, const_l, var, var_value)))

        var, linear, const = Substitute.get_answer((x_coef_l, y_coef_l, const_l, var, var_value))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        return thoughts",,197,9751e2c9-c6c7-43f5-a080-45ee8d52b8f9
"@staticmethod
    def is_impossible_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r != const_r * x_coef_l:
                return True
        return False",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_2d/,Linear_2d,"@staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Elim, (left, right))]

        if Linear_2d.is_impossible_2d(left, right) or Linear_2d.is_indeterminate_2d(left, right):
            return thoughts

        var, linear, const = Elim.get_answer((left, right))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        var_value = Reduce.get_answer((const, linear))
        x_coef_l, y_coef_l, const_l = left
        thoughts.append(T(Substitute, (x_coef_l, y_coef_l, const_l, var, var_value)))

        var, linear, const = Substitute.get_answer((x_coef_l, y_coef_l, const_l, var, var_value))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        return thoughts","@staticmethod
    def is_indeterminate_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r == const_r * x_coef_l:
                return True
        return False","(422, 4)","(430, 20)",N,function_definition,"def is_impossible_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r != const_r * x_coef_l:
                return True
        return False",,84,5760544e-07e0-45c8-bee3-c0325cd196b1
"@staticmethod
    def is_indeterminate_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r == const_r * x_coef_l:
                return True
        return False",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/class_definition-Linear_2d/,Linear_2d,"@staticmethod
    def is_impossible_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r != const_r * x_coef_l:
                return True
        return False","# class Quadratic_1d(Problem):
#     """"""Solve 2D Linear Equation
#     E.g.,
#         # Base Case: Factorized
#         <GO><QUADRATIC_1D>(x+1)(x+2)=0<SOLVE>
#             <GO><LINEAR_1D>x+1=0<SOLVE>x=-1<STOP>
#             <GO><LINEAR_1D>x+2=0<SOLVE>x=-2<STOP>
#             x=-1<SEP>x=-2<STOP>
#         <GO><QUADRATIC_1D>(2x+1)(3x+2)=0<SOLVE>
#             <GO><LINEAR_1D>2x+1=0<SOLVE>x=-1/2<STOP>
#             <GO><LINEAR_1D>3x+2=0<SOLVE>x=-2/3<STOP>
#             x=-1/2<SEP>x=-2/3<STOP>
#         <GO><QUADRATIC_1D>(2x+1)^2=0<SOLVE>
#             <GO><LINEAR_1D>2x+1=0<SOLVE>x=-1/2<STOP>
#             x=-1/2<STOP>
#         # Solve Recursively: Perfect Square
#         <GO><QUADRATIC_1D>(2x+1)(2x+1)=0<SOLVE>
#             <GO><LINEAR_1D>(2x+1)^2=0<SOLVE>x=-1/2<STOP>
#             x=-1/2<STOP>
#         <GO><QUADRATIC_1D>x^2+2x+1=0<SOLVE>
#             <GO><FACTORIZE>x^2+2x+1<SOLVE>(x+1)^2<STOP>
#             <GO><QUADRATIC_1D>(x+1)^2=0<SOLVE>x=-1<STOP>
#             x=-1<STOP>
#         # Solve Recursively: Factorizable
#         <GO><QUADRATIC_1D>2x^2+3x+1=0<SOLVE>","(432, 4)","(440, 20)",N,function_definition,"def is_indeterminate_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r == const_r * x_coef_l:
                return True
        return False",,84,fb20725e-5a86-4772-9c3e-5500957369f6
"# class Quadratic_1d(Problem):
#     """"""Solve 2D Linear Equation
#     E.g.,
#         # Base Case: Factorized
#         <GO><QUADRATIC_1D>(x+1)(x+2)=0<SOLVE>
#             <GO><LINEAR_1D>x+1=0<SOLVE>x=-1<STOP>
#             <GO><LINEAR_1D>x+2=0<SOLVE>x=-2<STOP>
#             x=-1<SEP>x=-2<STOP>
#         <GO><QUADRATIC_1D>(2x+1)(3x+2)=0<SOLVE>
#             <GO><LINEAR_1D>2x+1=0<SOLVE>x=-1/2<STOP>
#             <GO><LINEAR_1D>3x+2=0<SOLVE>x=-2/3<STOP>
#             x=-1/2<SEP>x=-2/3<STOP>
#         <GO><QUADRATIC_1D>(2x+1)^2=0<SOLVE>
#             <GO><LINEAR_1D>2x+1=0<SOLVE>x=-1/2<STOP>
#             x=-1/2<STOP>
#         # Solve Recursively: Perfect Square
#         <GO><QUADRATIC_1D>(2x+1)(2x+1)=0<SOLVE>
#             <GO><LINEAR_1D>(2x+1)^2=0<SOLVE>x=-1/2<STOP>
#             x=-1/2<STOP>
#         <GO><QUADRATIC_1D>x^2+2x+1=0<SOLVE>
#             <GO><FACTORIZE>x^2+2x+1<SOLVE>(x+1)^2<STOP>
#             <GO><QUADRATIC_1D>(x+1)^2=0<SOLVE>x=-1<STOP>
#             x=-1<STOP>
#         # Solve Recursively: Factorizable
#         <GO><QUADRATIC_1D>2x^2+3x+1=0<SOLVE>",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,"class Linear_2d(Problem):
    """"""Solve 2D Linear Equation
    E.g.,
        <GO><LINEAR_2D>x+y=5<SEP>2x-y=8<SOLVE>
            <GO><ELIM>x+y=5<SEP>2x-y=8<SOLVE>3x=13<STOP>
            <GO><LINEAR_1D>3x=13<SOLVE>x=13/3<STOP>
            <GO><SUBSTITUTE>x+y=5<SEP>x=13/3<SOLVE>y=2/3<STOP>
            <GO><LINEAR_1D>y=2/3<SOLVE>y=2/3<STOP>
            x=13/3<SEP>y=2/3<STOP>
        <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
            <ELIM>-4x+3y=-8<SEP>7x-4y=14<SOLVE>5y=0<STOP>
            <GO><LINEAR_1D>5y=0<SOLVE>y=0<STOP>
            <GO><SUBSTITUTE>-4x+3y=-8<SEP>y=0<SOLVE>-4x=-8<STOP>
            <GO><LINEAR_1D>-4x=-8<SOLVE>x=2<STOP>
            x=2<SEP>y=0<STOP>
        # Impossible
        <GO><LINEAR_2D>-32x+24y=-64<SEP>32x-24y=56<SOLVE>
            <GO><ELIM>-32x+24y=-64<SEP>32x-24y=56<SOLVE>0=-8<STOP>
            <NO_SOL><STOP>
        # Indeterminate
        <GO><LINEAR_2D>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>
            <GO><ELIM>-4x+3y=-8<SEP>-4x+3y=-8<SOLVE>0=0<STOP>
            <INDET><STOP>
    """"""
    name = 'Linear_2d'
    dependencies = {
        Linear_1d: lambda config: config,
        Elim: lambda config: config,
        Substitute: lambda config: config,
    }
    symbols = ['<LINEAR_2D>', '<SOLVE>', '<SEP>', 'x', 'y', '<NO_SOL>', '<INDET>', '-']

    def generate(self):
        x_coef_l, y_coef_l, const_l = self.sample_linear_2d(self.config['max_digits'], min_num=1)
        x_coef_r, y_coef_r, const_r = self.sample_linear_2d(self.config['max_digits'], min_num=1)

        # There should be at least one variable to be eliminated
        if x_coef_l * x_coef_r == 0 and y_coef_l * y_coef_r == 0:
            return self.generate()
        return (x_coef_l, y_coef_l, const_l), (x_coef_r, y_coef_r, const_r)

    @staticmethod
    def question(args):
        # <GO><LINEAR_2D>-4x+3y=-8<SEP>7x-4y=14<SOLVE>
        left, right = args

        q_list = ['<GO><LINEAR_2D>',
                  make_linear_2d(left[0], left[1], left[2]),
                  '<SEP>',
                  make_linear_2d(right[0], right[1], right[2]),
                  '<SOLVE>']

        return ''.join(q_list)

    @staticmethod
    def answer(args):
        # x=2<SEP>y=3<STOP>
        left, right = args

        if Linear_2d.is_impossible_2d(left, right):
            return '<NO_SOL><STOP>'
        if Linear_2d.is_indeterminate_2d(left, right):
            return '<INDET><STOP>'

        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        x_value = frac_to_str((const_l * y_coef_r - const_r * y_coef_l,
                               x_coef_l * y_coef_r - x_coef_r * y_coef_l),
                              reduce = True)
        y_value = frac_to_str((const_l * x_coef_r - const_r * x_coef_l,
                               y_coef_l * x_coef_r - y_coef_r * x_coef_l),
                              reduce = True)

        return f'x={x_value}<SEP>y={y_value}<STOP>'

    @staticmethod
    def thought(args) -> list[T]:
        left, right = args

        thoughts = [T(Elim, (left, right))]

        if Linear_2d.is_impossible_2d(left, right) or Linear_2d.is_indeterminate_2d(left, right):
            return thoughts

        var, linear, const = Elim.get_answer((left, right))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        var_value = Reduce.get_answer((const, linear))
        x_coef_l, y_coef_l, const_l = left
        thoughts.append(T(Substitute, (x_coef_l, y_coef_l, const_l, var, var_value)))

        var, linear, const = Substitute.get_answer((x_coef_l, y_coef_l, const_l, var, var_value))
        thoughts.append(T(Linear_1d, (var, linear, const)))

        return thoughts

    @staticmethod
    def is_impossible_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r != const_r * x_coef_l:
                return True
        return False

    @staticmethod
    def is_indeterminate_2d(left, right):
        x_coef_l, y_coef_l, const_l = left
        x_coef_r, y_coef_r, const_r = right

        if x_coef_l * y_coef_r == x_coef_r * y_coef_l:
            if const_l * x_coef_r == const_r * x_coef_l:
                return True
        return False","#             <GO><FACTORIZE>2x^2+3x+1<SOLVE>(2x+1)(x+1)<STOP>
#             <QUADRATIC_1D>(2x+1)(x+1)=0<SOLVE>x=-1/2<SEP>x=-1<STOP>
#             x=-1/2<SEP>x=-1<STOP>
#         # Base case: Fail to factorize -> Check Discriminant
#         <GO><QUADRATIC_1D>2x^2+3x+2=0<SOLVE>
#             <GO><FACTORIZE>2x^2+3x+2<SOLVE><FAIL><STOP>
#             <GO><DISCRIMINANT>2x^2+3x+2<SOLVE>-7<STOP>
#             <NO_SOL><STOP>
#         # Base case: Call Quadratic Formula
#         <GO><QUADRATIC_1D>x^2+3x+1=0<SOLVE>
#             <GO><FACTORIZE>x^2+3x+1<SOLVE><FAIL><STOP>
#             <GO><DISCRIMINANT>x^2+3x+1<SOLVE>5<STOP>
#             <GO><QUAD_FORMULA>x^2+3x+1=0<SOLVE>x=-3/2+<SQRT>5<SEP>x=-3/2-<SQRT>5<STOP>
#             x=-3/2+<SQRT>5<SEP>x=-3/2-<SQRT>5<STOP>
#     """"""
#     name = 'Quadratic_1d'
#     dependencies = {
#         Linear_1d: lambda config: config,
#         # Factorize: lambda config: config,
#         # Discriminant: lambda config: config,
#         # Quad_formula: lambda config: config,
#     }
#     symbols = ['<QUADRATIC_1D>', '<SOLVE>', '<SEP>', '^', 'x', 'y', '<NO_SOL>', '-', '(', ')']
#
#     def generate(self, log_uniform=True):
#         pass
#     @staticmethod
#     def question(args):
#         pass
#     @staticmethod
#     def answer(args):
#         pass
#     @staticmethod
#     def thought(args) -> list[T]:","(443, 0)","(467, 46)",N,"comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment",comment,,468,7c81979e-bea2-406a-940e-01ac3c4977c7
"#             <GO><FACTORIZE>2x^2+3x+1<SOLVE>(2x+1)(x+1)<STOP>
#             <QUADRATIC_1D>(2x+1)(x+1)=0<SOLVE>x=-1/2<SEP>x=-1<STOP>
#             x=-1/2<SEP>x=-1<STOP>
#         # Base case: Fail to factorize -> Check Discriminant
#         <GO><QUADRATIC_1D>2x^2+3x+2=0<SOLVE>
#             <GO><FACTORIZE>2x^2+3x+2<SOLVE><FAIL><STOP>
#             <GO><DISCRIMINANT>2x^2+3x+2<SOLVE>-7<STOP>
#             <NO_SOL><STOP>
#         # Base case: Call Quadratic Formula
#         <GO><QUADRATIC_1D>x^2+3x+1=0<SOLVE>
#             <GO><FACTORIZE>x^2+3x+1<SOLVE><FAIL><STOP>
#             <GO><DISCRIMINANT>x^2+3x+1<SOLVE>5<STOP>
#             <GO><QUAD_FORMULA>x^2+3x+1=0<SOLVE>x=-3/2+<SQRT>5<SEP>x=-3/2-<SQRT>5<STOP>
#             x=-3/2+<SQRT>5<SEP>x=-3/2-<SQRT>5<STOP>
#     """"""
#     name = 'Quadratic_1d'
#     dependencies = {
#         Linear_1d: lambda config: config,
#         # Factorize: lambda config: config,
#         # Discriminant: lambda config: config,
#         # Quad_formula: lambda config: config,
#     }
#     symbols = ['<QUADRATIC_1D>', '<SOLVE>', '<SEP>', '^', 'x', 'y', '<NO_SOL>', '-', '(', ')']
#
#     def generate(self, log_uniform=True):
#         pass
#     @staticmethod
#     def question(args):
#         pass
#     @staticmethod
#     def answer(args):
#         pass
#     @staticmethod
#     def thought(args) -> list[T]:",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,#         <GO><QUADRATIC_1D>2x^2+3x+1=0<SOLVE>,#         return [],"(468, 0)","(501, 35)",N,"comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment,comment",comment,,499,83087a53-2ed6-469d-b716-73e22b213bbd
#         return [],equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,#     def thought(args) -> list[T]:,"def make_linear_2d(x_coef, y_coef, const):
    """"""Make 2d linear expression with its coefficients""""""
    equation = []

    if x_coef == 0 and y_coef == 0:
        return f'0={frac_to_str(const)}'

    if x_coef != 0:
        if x_coef < 0:
            equation.append('-')
        if abs(x_coef) != 1:
            equation.append(f'{abs(x_coef)}')
        equation.append('x')

    if y_coef != 0:
        if y_coef < 0:
            equation.append('-')
        elif x_coef != 0:
            equation.append('+')
        if abs(y_coef) != 1:
            equation.append(f'{abs(y_coef)}')
        equation.append('y')

    equation.extend([f'={frac_to_str(const)}'])
    return ''.join(equation)","(502, 0)","(502, 19)",N,comment,comment,,4,0f8bad16-a872-42c3-9dfd-4440e05cc68e
"def make_linear_2d(x_coef, y_coef, const):
    """"""Make 2d linear expression with its coefficients""""""
    equation = []

    if x_coef == 0 and y_coef == 0:
        return f'0={frac_to_str(const)}'

    if x_coef != 0:
        if x_coef < 0:
            equation.append('-')
        if abs(x_coef) != 1:
            equation.append(f'{abs(x_coef)}')
        equation.append('x')

    if y_coef != 0:
        if y_coef < 0:
            equation.append('-')
        elif x_coef != 0:
            equation.append('+')
        if abs(y_coef) != 1:
            equation.append(f'{abs(y_coef)}')
        equation.append('y')

    equation.extend([f'={frac_to_str(const)}'])
    return ''.join(equation)",equation.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\equation.py,module/,module,#         return [],Next sibling does not exist,"(504, 0)","(528, 28)",N,function_definition,make_linear_2d,,184,8d7cc5cb-1ff8-4eca-af98-adc47c4447fe
"import random
from functools import lru_cache

from .arithmetic import Compare, Add, Sub
from .problem import Problem, T


class Knapsack(Problem):
    name = 'Knapsack'
    dependencies = {
        Compare: lambda config: config,
        Add: lambda config: config,
        Sub: lambda config: config,
    }
    symbols = ['<KNAPSACK>', '&', ',', '@', '$']

    def generate(self):
        items = tuple(
            (random.randrange(1, self.config['max_value']),
             random.randrange(1, self.config['max_weight']))
            for _ in range(self.config['num']))
        total_weight = sum(weight for _, weight in items)
        min_weight = min(weight for _, weight in items)
        capacity = random.randrange(min_weight, total_weight + 1)
        return items, capacity

    @staticmethod
    def question(args):
        items, capacity = args
        items_text = ','.join(f'{value}&{weight}' for value, weight in items)
        return f'<GO><KNAPSACK>{items_text}@{capacity}='

    @staticmethod
    def thought(args) -> list[T]:
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            return [T(Compare, (weight, capacity))]

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))
        thoughts = [
            T(Knapsack, (items[1:], capacity)),
            T(Compare, (weight, capacity)),
        ]

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            value_incl = value_sub + value
            thoughts.extend([
                T(Sub, (capacity, weight)),
                T(Knapsack, (items[1:], capacity - weight)),
                T(Add, (value_sub, value)),
                T(Compare, (value_incl, value_max)),
            ])

        return thoughts

    @staticmethod
    def answer(args):
        items, value = Knapsack._answer(args)
        items_text = ','.join(f'{v}&{w}' for v, w in items)
        return f'{items_text}${value}<STOP>'

    @staticmethod
    @lru_cache(50000)
    def _answer(args):
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            if weight <= capacity:
                return items, value
            else:
                return (), 0

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            items_incl = (items[0],) + items_sub
            value_incl = value_sub + value
            if value_incl > value_max:
                items_max = items_incl
                value_max = value_incl

        return items_max, value_max
",knapsack.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\knapsack.py,,NA,Previous sibling does not exist,"import random
from functools import lru_cache
from .arithmetic import Compare, Add, Sub
from .problem import Problem, T","(0, 0)","(95, 0)",N,module,module,,697,f55f2e58-0f17-49a4-bc60-ac765112e8cf
"import random
from functools import lru_cache
from .arithmetic import Compare, Add, Sub
from .problem import Problem, T",knapsack.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\knapsack.py,module/,module,Previous sibling does not exist,"class Knapsack(Problem):
    name = 'Knapsack'
    dependencies = {
        Compare: lambda config: config,
        Add: lambda config: config,
        Sub: lambda config: config,
    }
    symbols = ['<KNAPSACK>', '&', ',', '@', '$']

    def generate(self):
        items = tuple(
            (random.randrange(1, self.config['max_value']),
             random.randrange(1, self.config['max_weight']))
            for _ in range(self.config['num']))
        total_weight = sum(weight for _, weight in items)
        min_weight = min(weight for _, weight in items)
        capacity = random.randrange(min_weight, total_weight + 1)
        return items, capacity

    @staticmethod
    def question(args):
        items, capacity = args
        items_text = ','.join(f'{value}&{weight}' for value, weight in items)
        return f'<GO><KNAPSACK>{items_text}@{capacity}='

    @staticmethod
    def thought(args) -> list[T]:
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            return [T(Compare, (weight, capacity))]

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))
        thoughts = [
            T(Knapsack, (items[1:], capacity)),
            T(Compare, (weight, capacity)),
        ]

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            value_incl = value_sub + value
            thoughts.extend([
                T(Sub, (capacity, weight)),
                T(Knapsack, (items[1:], capacity - weight)),
                T(Add, (value_sub, value)),
                T(Compare, (value_incl, value_max)),
            ])

        return thoughts

    @staticmethod
    def answer(args):
        items, value = Knapsack._answer(args)
        items_text = ','.join(f'{v}&{w}' for v, w in items)
        return f'{items_text}${value}<STOP>'

    @staticmethod
    @lru_cache(50000)
    def _answer(args):
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            if weight <= capacity:
                return items, value
            else:
                return (), 0

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            items_incl = (items[0],) + items_sub
            value_incl = value_sub + value
            if value_incl > value_max:
                items_max = items_incl
                value_max = value_incl

        return items_max, value_max","(0, 0)","(4, 31)",N,"import_statement,import_from_statement,import_from_statement,import_from_statement",import_statement,,25,696fe7b4-a9f8-436b-9507-3a7176e532bd
"class Knapsack(Problem):
    name = 'Knapsack'
    dependencies = {
        Compare: lambda config: config,
        Add: lambda config: config,
        Sub: lambda config: config,
    }
    symbols = ['<KNAPSACK>', '&', ',', '@', '$']

    def generate(self):
        items = tuple(
            (random.randrange(1, self.config['max_value']),
             random.randrange(1, self.config['max_weight']))
            for _ in range(self.config['num']))
        total_weight = sum(weight for _, weight in items)
        min_weight = min(weight for _, weight in items)
        capacity = random.randrange(min_weight, total_weight + 1)
        return items, capacity

    @staticmethod
    def question(args):
        items, capacity = args
        items_text = ','.join(f'{value}&{weight}' for value, weight in items)
        return f'<GO><KNAPSACK>{items_text}@{capacity}='

    @staticmethod
    def thought(args) -> list[T]:
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            return [T(Compare, (weight, capacity))]

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))
        thoughts = [
            T(Knapsack, (items[1:], capacity)),
            T(Compare, (weight, capacity)),
        ]

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            value_incl = value_sub + value
            thoughts.extend([
                T(Sub, (capacity, weight)),
                T(Knapsack, (items[1:], capacity - weight)),
                T(Add, (value_sub, value)),
                T(Compare, (value_incl, value_max)),
            ])

        return thoughts

    @staticmethod
    def answer(args):
        items, value = Knapsack._answer(args)
        items_text = ','.join(f'{v}&{w}' for v, w in items)
        return f'{items_text}${value}<STOP>'

    @staticmethod
    @lru_cache(50000)
    def _answer(args):
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            if weight <= capacity:
                return items, value
            else:
                return (), 0

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            items_incl = (items[0],) + items_sub
            value_incl = value_sub + value
            if value_incl > value_max:
                items_max = items_incl
                value_max = value_incl

        return items_max, value_max",knapsack.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\knapsack.py,module/,module,"import random
from functools import lru_cache
from .arithmetic import Compare, Add, Sub
from .problem import Problem, T","name = 'Knapsack'
dependencies = {
        Compare: lambda config: config,
        Add: lambda config: config,
        Sub: lambda config: config,
    }
symbols = ['<KNAPSACK>', '&', ',', '@', '$']","(7, 0)","(94, 35)",N,class_definition,Knapsack,,667,b70b1bab-c304-4ee2-8b68-862a0f899672
"name = 'Knapsack'
dependencies = {
        Compare: lambda config: config,
        Add: lambda config: config,
        Sub: lambda config: config,
    }
symbols = ['<KNAPSACK>', '&', ',', '@', '$']",knapsack.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\knapsack.py,module/class_definition-Knapsack/,Knapsack,Previous sibling does not exist,"def generate(self):
        items = tuple(
            (random.randrange(1, self.config['max_value']),
             random.randrange(1, self.config['max_weight']))
            for _ in range(self.config['num']))
        total_weight = sum(weight for _, weight in items)
        min_weight = min(weight for _, weight in items)
        capacity = random.randrange(min_weight, total_weight + 1)
        return items, capacity","(8, 4)","(14, 48)",N,"expression_statement,expression_statement,expression_statement",expression_statement,,51,a54c2a04-6cfe-4654-97dd-c11d69bcca29
"def generate(self):
        items = tuple(
            (random.randrange(1, self.config['max_value']),
             random.randrange(1, self.config['max_weight']))
            for _ in range(self.config['num']))
        total_weight = sum(weight for _, weight in items)
        min_weight = min(weight for _, weight in items)
        capacity = random.randrange(min_weight, total_weight + 1)
        return items, capacity",knapsack.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\knapsack.py,module/class_definition-Knapsack/,Knapsack,"name = 'Knapsack'
dependencies = {
        Compare: lambda config: config,
        Add: lambda config: config,
        Sub: lambda config: config,
    }
symbols = ['<KNAPSACK>', '&', ',', '@', '$']","@staticmethod
    def question(args):
        items, capacity = args
        items_text = ','.join(f'{value}&{weight}' for value, weight in items)
        return f'<GO><KNAPSACK>{items_text}@{capacity}='","(16, 4)","(24, 30)",N,function_definition,generate,,87,d62d5906-4ad7-46e1-867c-a94870ced71b
"@staticmethod
    def question(args):
        items, capacity = args
        items_text = ','.join(f'{value}&{weight}' for value, weight in items)
        return f'<GO><KNAPSACK>{items_text}@{capacity}='",knapsack.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\knapsack.py,module/class_definition-Knapsack/,Knapsack,"def generate(self):
        items = tuple(
            (random.randrange(1, self.config['max_value']),
             random.randrange(1, self.config['max_weight']))
            for _ in range(self.config['num']))
        total_weight = sum(weight for _, weight in items)
        min_weight = min(weight for _, weight in items)
        capacity = random.randrange(min_weight, total_weight + 1)
        return items, capacity","@staticmethod
    def thought(args) -> list[T]:
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            return [T(Compare, (weight, capacity))]

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))
        thoughts = [
            T(Knapsack, (items[1:], capacity)),
            T(Compare, (weight, capacity)),
        ]

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            value_incl = value_sub + value
            thoughts.extend([
                T(Sub, (capacity, weight)),
                T(Knapsack, (items[1:], capacity - weight)),
                T(Add, (value_sub, value)),
                T(Compare, (value_incl, value_max)),
            ])

        return thoughts","(26, 4)","(30, 56)",N,function_definition,"def question(args):
        items, capacity = args
        items_text = ','.join(f'{value}&{weight}' for value, weight in items)
        return f'<GO><KNAPSACK>{items_text}@{capacity}='",,52,16287c3a-3742-4898-88c4-1e3ab5d64272
"@staticmethod
    def thought(args) -> list[T]:
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            return [T(Compare, (weight, capacity))]

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))
        thoughts = [
            T(Knapsack, (items[1:], capacity)),
            T(Compare, (weight, capacity)),
        ]

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            value_incl = value_sub + value
            thoughts.extend([
                T(Sub, (capacity, weight)),
                T(Knapsack, (items[1:], capacity - weight)),
                T(Add, (value_sub, value)),
                T(Compare, (value_incl, value_max)),
            ])

        return thoughts",knapsack.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\knapsack.py,module/class_definition-Knapsack/,Knapsack,"@staticmethod
    def question(args):
        items, capacity = args
        items_text = ','.join(f'{value}&{weight}' for value, weight in items)
        return f'<GO><KNAPSACK>{items_text}@{capacity}='","@staticmethod
    def answer(args):
        items, value = Knapsack._answer(args)
        items_text = ','.join(f'{v}&{w}' for v, w in items)
        return f'{items_text}${value}<STOP>'","(32, 4)","(60, 23)",N,function_definition,"def thought(args) -> list[T]:
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            return [T(Compare, (weight, capacity))]

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))
        thoughts = [
            T(Knapsack, (items[1:], capacity)),
            T(Compare, (weight, capacity)),
        ]

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            value_incl = value_sub + value
            thoughts.extend([
                T(Sub, (capacity, weight)),
                T(Knapsack, (items[1:], capacity - weight)),
                T(Add, (value_sub, value)),
                T(Compare, (value_incl, value_max)),
            ])

        return thoughts",,217,88eca40b-87a8-4ea7-a0e4-973118d54885
"@staticmethod
    def answer(args):
        items, value = Knapsack._answer(args)
        items_text = ','.join(f'{v}&{w}' for v, w in items)
        return f'{items_text}${value}<STOP>'",knapsack.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\knapsack.py,module/class_definition-Knapsack/,Knapsack,"@staticmethod
    def thought(args) -> list[T]:
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            return [T(Compare, (weight, capacity))]

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))
        thoughts = [
            T(Knapsack, (items[1:], capacity)),
            T(Compare, (weight, capacity)),
        ]

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            value_incl = value_sub + value
            thoughts.extend([
                T(Sub, (capacity, weight)),
                T(Knapsack, (items[1:], capacity - weight)),
                T(Add, (value_sub, value)),
                T(Compare, (value_incl, value_max)),
            ])

        return thoughts","@staticmethod
    @lru_cache(50000)
    def _answer(args):
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            if weight <= capacity:
                return items, value
            else:
                return (), 0

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            items_incl = (items[0],) + items_sub
            value_incl = value_sub + value
            if value_incl > value_max:
                items_max = items_incl
                value_max = value_incl

        return items_max, value_max","(62, 4)","(66, 44)",N,function_definition,"def answer(args):
        items, value = Knapsack._answer(args)
        items_text = ','.join(f'{v}&{w}' for v, w in items)
        return f'{items_text}${value}<STOP>'",,51,1aab1793-b460-490b-b53d-def90b18e172
"@staticmethod
    @lru_cache(50000)
    def _answer(args):
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            if weight <= capacity:
                return items, value
            else:
                return (), 0

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            items_incl = (items[0],) + items_sub
            value_incl = value_sub + value
            if value_incl > value_max:
                items_max = items_incl
                value_max = value_incl

        return items_max, value_max",knapsack.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\knapsack.py,module/class_definition-Knapsack/,Knapsack,"@staticmethod
    def answer(args):
        items, value = Knapsack._answer(args)
        items_text = ','.join(f'{v}&{w}' for v, w in items)
        return f'{items_text}${value}<STOP>'",Next sibling does not exist,"(68, 4)","(94, 35)",N,function_definition,"def _answer(args):
        items, capacity = args
        value, weight = items[0]

        # Base case
        if len(items) == 1:
            if weight <= capacity:
                return items, value
            else:
                return (), 0

        # When excluding the current item
        items_max, value_max = Knapsack._answer((items[1:], capacity))

        # When including the current item
        if weight <= capacity:
            items_sub, value_sub = Knapsack._answer(
                (items[1:], capacity - weight))
            items_incl = (items[0],) + items_sub
            value_incl = value_sub + value
            if value_incl > value_max:
                items_max = items_incl
                value_max = value_incl

        return items_max, value_max",,190,c7448dca-a909-43ec-8f0d-0da379aee370
"import random
from functools import lru_cache

from .problem import Problem, T
from .arithmetic import Compare, Add, Mul


class TernaryMul(Problem):
    name = 'TernaryMul'
    dependencies = {
        Mul: lambda config: config
    }
    symbols = ['*']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO>{""*"".join(str(arg) for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Mul, (a1, a2)),
            T(Mul, (a1 * a2, a3), 'tail')
        ]

    @staticmethod
    def answer(args):
        a1, a2, a3 = args
        return f'{a1 * a2 * a3}<STOP>'


class TernaryAdd(Problem):
    name = 'TernaryAdd'
    dependencies = {
        Add: lambda config: config
    }
    symbols = ['+']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO>{""+"".join(str(arg) for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Add, (a1, a2)),
            T(Add, (a1 + a2, a3), 'tail')
        ]

    @staticmethod
    def answer(args):
        return f'{sum(args)}<STOP>'


class MCM(Problem):
    """"""Matrix Chain Multiplication

    E.g.,
        <GO><MCM>36,67,75,59=
            <GO><MCM>3x6=3x6;0<STOP>
            <GO><MCM>67,75,59=(67,75),59;480<STOP>
            <GO>3*6*9=162<STOP>
            <GO>0+480+162=642<STOP>
            <TAIL><MCM>36,67|75,59<ACC>36((67,75),59);642=
                <GO><MCM>36,67=36,67;126<STOP>
                <GO><MCM>75,59=75,59;315<STOP>
                <GO>3*7*9=189<STOP>
                <GO>126+315+189=630<STOP>
                <GO>642<VS>630=<GT><STOP>
                <TAIL><MCM>36,67,75|59<ACC>(36,67),(75,59);630=
                    <GO><MCM>36,67,75=(36,67),75;231<STOP>
                    <GO><MCM>59=59;0<STOP>
                    <GO>3*5*9=135<STOP>
                    <GO>231+0+135=366<STOP>
                    <GO>630<VS>366=<GT><STOP>
                    ((36,67),75),59;366<STOP>
    """"""
    name = 'MCM'
    dependencies = {
        TernaryMul: lambda config: config,
        TernaryAdd: lambda config: config,
        Compare: lambda config: config,
    }
    symbols = ['<MCM>', ',', '', '(', ')', '|', ';', '<ACC>']

    def generate(self):
        dims = [
            self.log_randrange(1, 10 ** self.config['max_digits'])
            for _ in range(self.config['num'] + 1)
        ]
        mats = tuple(
            (dims[i], dims[i + 1])
            for i in range(self.config['num'])
        )
        return mats, None, None

    @staticmethod
    def question(args):
        mats, min_order, min_cost = args
        if min_order is not None:
            l_mats, r_mats = mats
            l_concat = ','.join([f'{m}{n}' for m, n in l_mats])
            r_concat = ','.join([f'{m}{n}' for m, n in r_mats])
            q = f'<GO><MCM>{l_concat}|{r_concat}' \
                f'<ACC>{MCM.order_text(min_order)};{min_cost}='
        else:
            concat = ','.join([f'{m}{n}' for m, n in mats])
            q = f'<GO><MCM>{concat}='
        return q

    @staticmethod
    def thought(args) -> list[T]:
        mats, min_order, min_cost = args

        # Base cases
        if len(mats) == 1:
            return []

        if min_order is None:
            # Top-level problem
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            # Middle of recursion
            l_mats, r_mats = mats

        l_args = (l_mats, None, None)
        r_args = (r_mats, None, None)
        l_order, l_cost = MCM._answer(l_args)
        r_order, r_cost = MCM._answer(r_args)
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        thoughts = [
            T(MCM, l_args),
            T(MCM, r_args),
            T(TernaryMul, (l_mats[0][0], r_mats[0][0], r_mats[-1][1])),
            T(TernaryAdd, (l_cost, r_cost, agg_cost)),
        ]

        cost = l_cost + r_cost + agg_cost
        if min_cost is not None:
            thoughts.append(T(Compare, (cost, min_cost)))
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) > 1:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            thoughts.append(
                T(MCM, ((new_l_mats, new_r_mats), min_order, min_cost), 'tail'))

        return thoughts

    @staticmethod
    def answer(args):
        order, cost = MCM._answer(args)
        return f'{MCM.order_text(order)};{cost}<STOP>'

    @staticmethod
    @lru_cache(50000)
    def _answer(args):
        mats, min_order, min_cost = args
        if len(mats) == 1:
            assert min_order is None
            return mats, 0
        if min_order is None:
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            l_mats, r_mats = mats
        l_order, l_cost = MCM._answer((l_mats, None, None))
        r_order, r_cost = MCM._answer((r_mats, None, None))
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        cost = l_cost + r_cost + agg_cost
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) == 1:
            return min_order, min_cost
        else:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            return MCM._answer(((new_l_mats, new_r_mats), min_order, min_cost))

    @staticmethod
    @lru_cache(50000)
    def order_text(order):
        if len(order) == 1:
            m, n = order[0]
            return f'{m}{n}'

        order_l, order_r = order
        text_l = MCM.order_text(order_l)
        text_r = MCM.order_text(order_r)
        if len(order_l) > 1:
            text_l = f'({text_l})'
        if len(order_r) > 1:
            text_r = f'({text_r})'
        return f'{text_l},{text_r}'
",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,,NA,Previous sibling does not exist,"import random
from functools import lru_cache
from .problem import Problem, T
from .arithmetic import Compare, Add, Mul","(0, 0)","(206, 0)",N,module,module,,1913,fb403da6-8c66-4c2d-b24c-1c592906b763
"import random
from functools import lru_cache
from .problem import Problem, T
from .arithmetic import Compare, Add, Mul",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/,module,Previous sibling does not exist,"class TernaryMul(Problem):
    name = 'TernaryMul'
    dependencies = {
        Mul: lambda config: config
    }
    symbols = ['*']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO>{""*"".join(str(arg) for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Mul, (a1, a2)),
            T(Mul, (a1 * a2, a3), 'tail')
        ]

    @staticmethod
    def answer(args):
        a1, a2, a3 = args
        return f'{a1 * a2 * a3}<STOP>'","(0, 0)","(4, 41)",N,"import_statement,import_from_statement,import_from_statement,import_from_statement",import_statement,,25,1a037304-8eca-4cd4-8f17-eda586186e03
"class TernaryMul(Problem):
    name = 'TernaryMul'
    dependencies = {
        Mul: lambda config: config
    }
    symbols = ['*']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO>{""*"".join(str(arg) for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Mul, (a1, a2)),
            T(Mul, (a1 * a2, a3), 'tail')
        ]

    @staticmethod
    def answer(args):
        a1, a2, a3 = args
        return f'{a1 * a2 * a3}<STOP>'",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/,module,"import random
from functools import lru_cache
from .problem import Problem, T
from .arithmetic import Compare, Add, Mul","class TernaryAdd(Problem):
    name = 'TernaryAdd'
    dependencies = {
        Add: lambda config: config
    }
    symbols = ['+']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO>{""+"".join(str(arg) for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Add, (a1, a2)),
            T(Add, (a1 + a2, a3), 'tail')
        ]

    @staticmethod
    def answer(args):
        return f'{sum(args)}<STOP>'","(7, 0)","(32, 38)",N,class_definition,TernaryMul,,169,ae29db4b-e2c1-4198-9cf6-35d3fab34931
"def generate(self):
        pass",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-TernaryMul/,TernaryMul,symbols = ['*'],"@staticmethod
    def question(args):
        return f'<GO>{""*"".join(str(arg) for arg in args)}='","(14, 4)","(15, 12)",N,function_definition,generate,,6,5cf82cbe-ff79-4bf4-86e7-cc998bd32ac4
"@staticmethod
    def question(args):
        return f'<GO>{""*"".join(str(arg) for arg in args)}='",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-TernaryMul/,TernaryMul,"def generate(self):
        pass","@staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Mul, (a1, a2)),
            T(Mul, (a1 * a2, a3), 'tail')
        ]","(17, 4)","(19, 59)",N,function_definition,"def question(args):
        return f'<GO>{""*"".join(str(arg) for arg in args)}='",,26,db933e9f-ddd6-429a-8c87-1a35101e13e9
"@staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Mul, (a1, a2)),
            T(Mul, (a1 * a2, a3), 'tail')
        ]",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-TernaryMul/,TernaryMul,"@staticmethod
    def question(args):
        return f'<GO>{""*"".join(str(arg) for arg in args)}='","@staticmethod
    def answer(args):
        a1, a2, a3 = args
        return f'{a1 * a2 * a3}<STOP>'","(21, 4)","(27, 9)",N,function_definition,"def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Mul, (a1, a2)),
            T(Mul, (a1 * a2, a3), 'tail')
        ]",,59,ac0d02ac-0878-4edc-8817-baeea5a4c825
"@staticmethod
    def answer(args):
        a1, a2, a3 = args
        return f'{a1 * a2 * a3}<STOP>'",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-TernaryMul/,TernaryMul,"@staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Mul, (a1, a2)),
            T(Mul, (a1 * a2, a3), 'tail')
        ]",Next sibling does not exist,"(29, 4)","(32, 38)",N,function_definition,"def answer(args):
        a1, a2, a3 = args
        return f'{a1 * a2 * a3}<STOP>'",,35,cb4f847a-9411-42ce-b9c8-5b44f0ca0ecb
"class TernaryAdd(Problem):
    name = 'TernaryAdd'
    dependencies = {
        Add: lambda config: config
    }
    symbols = ['+']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO>{""+"".join(str(arg) for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Add, (a1, a2)),
            T(Add, (a1 + a2, a3), 'tail')
        ]

    @staticmethod
    def answer(args):
        return f'{sum(args)}<STOP>'",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/,module,"class TernaryMul(Problem):
    name = 'TernaryMul'
    dependencies = {
        Mul: lambda config: config
    }
    symbols = ['*']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO>{""*"".join(str(arg) for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Mul, (a1, a2)),
            T(Mul, (a1 * a2, a3), 'tail')
        ]

    @staticmethod
    def answer(args):
        a1, a2, a3 = args
        return f'{a1 * a2 * a3}<STOP>'","class MCM(Problem):
    """"""Matrix Chain Multiplication

    E.g.,
        <GO><MCM>36,67,75,59=
            <GO><MCM>3x6=3x6;0<STOP>
            <GO><MCM>67,75,59=(67,75),59;480<STOP>
            <GO>3*6*9=162<STOP>
            <GO>0+480+162=642<STOP>
            <TAIL><MCM>36,67|75,59<ACC>36((67,75),59);642=
                <GO><MCM>36,67=36,67;126<STOP>
                <GO><MCM>75,59=75,59;315<STOP>
                <GO>3*7*9=189<STOP>
                <GO>126+315+189=630<STOP>
                <GO>642<VS>630=<GT><STOP>
                <TAIL><MCM>36,67,75|59<ACC>(36,67),(75,59);630=
                    <GO><MCM>36,67,75=(36,67),75;231<STOP>
                    <GO><MCM>59=59;0<STOP>
                    <GO>3*5*9=135<STOP>
                    <GO>231+0+135=366<STOP>
                    <GO>630<VS>366=<GT><STOP>
                    ((36,67),75),59;366<STOP>
    """"""
    name = 'MCM'
    dependencies = {
        TernaryMul: lambda config: config,
        TernaryAdd: lambda config: config,
        Compare: lambda config: config,
    }
    symbols = ['<MCM>', ',', '', '(', ')', '|', ';', '<ACC>']

    def generate(self):
        dims = [
            self.log_randrange(1, 10 ** self.config['max_digits'])
            for _ in range(self.config['num'] + 1)
        ]
        mats = tuple(
            (dims[i], dims[i + 1])
            for i in range(self.config['num'])
        )
        return mats, None, None

    @staticmethod
    def question(args):
        mats, min_order, min_cost = args
        if min_order is not None:
            l_mats, r_mats = mats
            l_concat = ','.join([f'{m}{n}' for m, n in l_mats])
            r_concat = ','.join([f'{m}{n}' for m, n in r_mats])
            q = f'<GO><MCM>{l_concat}|{r_concat}' \
                f'<ACC>{MCM.order_text(min_order)};{min_cost}='
        else:
            concat = ','.join([f'{m}{n}' for m, n in mats])
            q = f'<GO><MCM>{concat}='
        return q

    @staticmethod
    def thought(args) -> list[T]:
        mats, min_order, min_cost = args

        # Base cases
        if len(mats) == 1:
            return []

        if min_order is None:
            # Top-level problem
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            # Middle of recursion
            l_mats, r_mats = mats

        l_args = (l_mats, None, None)
        r_args = (r_mats, None, None)
        l_order, l_cost = MCM._answer(l_args)
        r_order, r_cost = MCM._answer(r_args)
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        thoughts = [
            T(MCM, l_args),
            T(MCM, r_args),
            T(TernaryMul, (l_mats[0][0], r_mats[0][0], r_mats[-1][1])),
            T(TernaryAdd, (l_cost, r_cost, agg_cost)),
        ]

        cost = l_cost + r_cost + agg_cost
        if min_cost is not None:
            thoughts.append(T(Compare, (cost, min_cost)))
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) > 1:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            thoughts.append(
                T(MCM, ((new_l_mats, new_r_mats), min_order, min_cost), 'tail'))

        return thoughts

    @staticmethod
    def answer(args):
        order, cost = MCM._answer(args)
        return f'{MCM.order_text(order)};{cost}<STOP>'

    @staticmethod
    @lru_cache(50000)
    def _answer(args):
        mats, min_order, min_cost = args
        if len(mats) == 1:
            assert min_order is None
            return mats, 0
        if min_order is None:
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            l_mats, r_mats = mats
        l_order, l_cost = MCM._answer((l_mats, None, None))
        r_order, r_cost = MCM._answer((r_mats, None, None))
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        cost = l_cost + r_cost + agg_cost
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) == 1:
            return min_order, min_cost
        else:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            return MCM._answer(((new_l_mats, new_r_mats), min_order, min_cost))

    @staticmethod
    @lru_cache(50000)
    def order_text(order):
        if len(order) == 1:
            m, n = order[0]
            return f'{m}{n}'

        order_l, order_r = order
        text_l = MCM.order_text(order_l)
        text_r = MCM.order_text(order_r)
        if len(order_l) > 1:
            text_l = f'({text_l})'
        if len(order_r) > 1:
            text_r = f'({text_r})'
        return f'{text_l},{text_r}'","(35, 0)","(59, 35)",N,class_definition,TernaryAdd,,151,b99191a2-f9e0-4ea1-8546-f39cd6328445
"def generate(self):
        pass",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-TernaryAdd/,TernaryAdd,symbols = ['+'],"@staticmethod
    def question(args):
        return f'<GO>{""+"".join(str(arg) for arg in args)}='","(42, 4)","(43, 12)",N,function_definition,generate,,6,7cef1d2f-ec5b-45ab-bbba-e47df71cf38b
"@staticmethod
    def question(args):
        return f'<GO>{""+"".join(str(arg) for arg in args)}='",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-TernaryAdd/,TernaryAdd,"def generate(self):
        pass","@staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Add, (a1, a2)),
            T(Add, (a1 + a2, a3), 'tail')
        ]","(45, 4)","(47, 59)",N,function_definition,"def question(args):
        return f'<GO>{""+"".join(str(arg) for arg in args)}='",,25,78bfa7cb-f2d4-4b4e-9459-1deb4ab89747
"@staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Add, (a1, a2)),
            T(Add, (a1 + a2, a3), 'tail')
        ]",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-TernaryAdd/,TernaryAdd,"@staticmethod
    def question(args):
        return f'<GO>{""+"".join(str(arg) for arg in args)}='","@staticmethod
    def answer(args):
        return f'{sum(args)}<STOP>'","(49, 4)","(55, 9)",N,function_definition,"def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Add, (a1, a2)),
            T(Add, (a1 + a2, a3), 'tail')
        ]",,59,0d6f759a-c7fc-4b90-aa3c-d2b9588a2057
"@staticmethod
    def answer(args):
        return f'{sum(args)}<STOP>'",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-TernaryAdd/,TernaryAdd,"@staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Add, (a1, a2)),
            T(Add, (a1 + a2, a3), 'tail')
        ]",Next sibling does not exist,"(57, 4)","(59, 35)",N,function_definition,"def answer(args):
        return f'{sum(args)}<STOP>'",,18,9d6550c3-10ca-45a4-8e14-30eac27a1a7b
"class MCM(Problem):
    """"""Matrix Chain Multiplication

    E.g.,
        <GO><MCM>36,67,75,59=
            <GO><MCM>3x6=3x6;0<STOP>
            <GO><MCM>67,75,59=(67,75),59;480<STOP>
            <GO>3*6*9=162<STOP>
            <GO>0+480+162=642<STOP>
            <TAIL><MCM>36,67|75,59<ACC>36((67,75),59);642=
                <GO><MCM>36,67=36,67;126<STOP>
                <GO><MCM>75,59=75,59;315<STOP>
                <GO>3*7*9=189<STOP>
                <GO>126+315+189=630<STOP>
                <GO>642<VS>630=<GT><STOP>
                <TAIL><MCM>36,67,75|59<ACC>(36,67),(75,59);630=
                    <GO><MCM>36,67,75=(36,67),75;231<STOP>
                    <GO><MCM>59=59;0<STOP>
                    <GO>3*5*9=135<STOP>
                    <GO>231+0+135=366<STOP>
                    <GO>630<VS>366=<GT><STOP>
                    ((36,67),75),59;366<STOP>
    """"""
    name = 'MCM'
    dependencies = {
        TernaryMul: lambda config: config,
        TernaryAdd: lambda config: config,
        Compare: lambda config: config,
    }
    symbols = ['<MCM>', ',', '', '(', ')', '|', ';', '<ACC>']

    def generate(self):
        dims = [
            self.log_randrange(1, 10 ** self.config['max_digits'])
            for _ in range(self.config['num'] + 1)
        ]
        mats = tuple(
            (dims[i], dims[i + 1])
            for i in range(self.config['num'])
        )
        return mats, None, None

    @staticmethod
    def question(args):
        mats, min_order, min_cost = args
        if min_order is not None:
            l_mats, r_mats = mats
            l_concat = ','.join([f'{m}{n}' for m, n in l_mats])
            r_concat = ','.join([f'{m}{n}' for m, n in r_mats])
            q = f'<GO><MCM>{l_concat}|{r_concat}' \
                f'<ACC>{MCM.order_text(min_order)};{min_cost}='
        else:
            concat = ','.join([f'{m}{n}' for m, n in mats])
            q = f'<GO><MCM>{concat}='
        return q

    @staticmethod
    def thought(args) -> list[T]:
        mats, min_order, min_cost = args

        # Base cases
        if len(mats) == 1:
            return []

        if min_order is None:
            # Top-level problem
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            # Middle of recursion
            l_mats, r_mats = mats

        l_args = (l_mats, None, None)
        r_args = (r_mats, None, None)
        l_order, l_cost = MCM._answer(l_args)
        r_order, r_cost = MCM._answer(r_args)
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        thoughts = [
            T(MCM, l_args),
            T(MCM, r_args),
            T(TernaryMul, (l_mats[0][0], r_mats[0][0], r_mats[-1][1])),
            T(TernaryAdd, (l_cost, r_cost, agg_cost)),
        ]

        cost = l_cost + r_cost + agg_cost
        if min_cost is not None:
            thoughts.append(T(Compare, (cost, min_cost)))
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) > 1:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            thoughts.append(
                T(MCM, ((new_l_mats, new_r_mats), min_order, min_cost), 'tail'))

        return thoughts

    @staticmethod
    def answer(args):
        order, cost = MCM._answer(args)
        return f'{MCM.order_text(order)};{cost}<STOP>'

    @staticmethod
    @lru_cache(50000)
    def _answer(args):
        mats, min_order, min_cost = args
        if len(mats) == 1:
            assert min_order is None
            return mats, 0
        if min_order is None:
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            l_mats, r_mats = mats
        l_order, l_cost = MCM._answer((l_mats, None, None))
        r_order, r_cost = MCM._answer((r_mats, None, None))
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        cost = l_cost + r_cost + agg_cost
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) == 1:
            return min_order, min_cost
        else:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            return MCM._answer(((new_l_mats, new_r_mats), min_order, min_cost))

    @staticmethod
    @lru_cache(50000)
    def order_text(order):
        if len(order) == 1:
            m, n = order[0]
            return f'{m}{n}'

        order_l, order_r = order
        text_l = MCM.order_text(order_l)
        text_r = MCM.order_text(order_r)
        if len(order_l) > 1:
            text_l = f'({text_l})'
        if len(order_r) > 1:
            text_r = f'({text_r})'
        return f'{text_l},{text_r}'",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/,module,"class TernaryAdd(Problem):
    name = 'TernaryAdd'
    dependencies = {
        Add: lambda config: config
    }
    symbols = ['+']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO>{""+"".join(str(arg) for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        a1, a2, a3 = args
        return [
            T(Add, (a1, a2)),
            T(Add, (a1 + a2, a3), 'tail')
        ]

    @staticmethod
    def answer(args):
        return f'{sum(args)}<STOP>'","""""""Matrix Chain Multiplication

    E.g.,
        <GO><MCM>36,67,75,59=
            <GO><MCM>3x6=3x6;0<STOP>
            <GO><MCM>67,75,59=(67,75),59;480<STOP>
            <GO>3*6*9=162<STOP>
            <GO>0+480+162=642<STOP>
            <TAIL><MCM>36,67|75,59<ACC>36((67,75),59);642=
                <GO><MCM>36,67=36,67;126<STOP>
                <GO><MCM>75,59=75,59;315<STOP>
                <GO>3*7*9=189<STOP>
                <GO>126+315+189=630<STOP>
                <GO>642<VS>630=<GT><STOP>
                <TAIL><MCM>36,67,75|59<ACC>(36,67),(75,59);630=
                    <GO><MCM>36,67,75=(36,67),75;231<STOP>
                    <GO><MCM>59=59;0<STOP>
                    <GO>3*5*9=135<STOP>
                    <GO>231+0+135=366<STOP>
                    <GO>630<VS>366=<GT><STOP>
                    ((36,67),75),59;366<STOP>
    """"""
name = 'MCM'
dependencies = {
        TernaryMul: lambda config: config,
        TernaryAdd: lambda config: config,
        Compare: lambda config: config,
    }
symbols = ['<MCM>', ',', '', '(', ')', '|', ';', '<ACC>']","(62, 0)","(205, 35)",N,class_definition,MCM,,1562,64baae90-a493-4749-8a7a-6824c242f977
"""""""Matrix Chain Multiplication

    E.g.,
        <GO><MCM>36,67,75,59=
            <GO><MCM>3x6=3x6;0<STOP>
            <GO><MCM>67,75,59=(67,75),59;480<STOP>
            <GO>3*6*9=162<STOP>
            <GO>0+480+162=642<STOP>
            <TAIL><MCM>36,67|75,59<ACC>36((67,75),59);642=
                <GO><MCM>36,67=36,67;126<STOP>
                <GO><MCM>75,59=75,59;315<STOP>
                <GO>3*7*9=189<STOP>
                <GO>126+315+189=630<STOP>
                <GO>642<VS>630=<GT><STOP>
                <TAIL><MCM>36,67,75|59<ACC>(36,67),(75,59);630=
                    <GO><MCM>36,67,75=(36,67),75;231<STOP>
                    <GO><MCM>59=59;0<STOP>
                    <GO>3*5*9=135<STOP>
                    <GO>231+0+135=366<STOP>
                    <GO>630<VS>366=<GT><STOP>
                    ((36,67),75),59;366<STOP>
    """"""
name = 'MCM'
dependencies = {
        TernaryMul: lambda config: config,
        TernaryAdd: lambda config: config,
        Compare: lambda config: config,
    }
symbols = ['<MCM>', ',', '', '(', ')', '|', ';', '<ACC>']",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-MCM/,MCM,Previous sibling does not exist,"def generate(self):
        dims = [
            self.log_randrange(1, 10 ** self.config['max_digits'])
            for _ in range(self.config['num'] + 1)
        ]
        mats = tuple(
            (dims[i], dims[i + 1])
            for i in range(self.config['num'])
        )
        return mats, None, None","(63, 4)","(91, 63)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,481,28e5b5fa-2d75-40c4-960b-34b7f89bc9e6
"def generate(self):
        dims = [
            self.log_randrange(1, 10 ** self.config['max_digits'])
            for _ in range(self.config['num'] + 1)
        ]
        mats = tuple(
            (dims[i], dims[i + 1])
            for i in range(self.config['num'])
        )
        return mats, None, None",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-MCM/,MCM,"""""""Matrix Chain Multiplication

    E.g.,
        <GO><MCM>36,67,75,59=
            <GO><MCM>3x6=3x6;0<STOP>
            <GO><MCM>67,75,59=(67,75),59;480<STOP>
            <GO>3*6*9=162<STOP>
            <GO>0+480+162=642<STOP>
            <TAIL><MCM>36,67|75,59<ACC>36((67,75),59);642=
                <GO><MCM>36,67=36,67;126<STOP>
                <GO><MCM>75,59=75,59;315<STOP>
                <GO>3*7*9=189<STOP>
                <GO>126+315+189=630<STOP>
                <GO>642<VS>630=<GT><STOP>
                <TAIL><MCM>36,67,75|59<ACC>(36,67),(75,59);630=
                    <GO><MCM>36,67,75=(36,67),75;231<STOP>
                    <GO><MCM>59=59;0<STOP>
                    <GO>3*5*9=135<STOP>
                    <GO>231+0+135=366<STOP>
                    <GO>630<VS>366=<GT><STOP>
                    ((36,67),75),59;366<STOP>
    """"""
name = 'MCM'
dependencies = {
        TernaryMul: lambda config: config,
        TernaryAdd: lambda config: config,
        Compare: lambda config: config,
    }
symbols = ['<MCM>', ',', '', '(', ')', '|', ';', '<ACC>']","@staticmethod
    def question(args):
        mats, min_order, min_cost = args
        if min_order is not None:
            l_mats, r_mats = mats
            l_concat = ','.join([f'{m}{n}' for m, n in l_mats])
            r_concat = ','.join([f'{m}{n}' for m, n in r_mats])
            q = f'<GO><MCM>{l_concat}|{r_concat}' \
                f'<ACC>{MCM.order_text(min_order)};{min_cost}='
        else:
            concat = ','.join([f'{m}{n}' for m, n in mats])
            q = f'<GO><MCM>{concat}='
        return q","(93, 4)","(102, 31)",N,function_definition,generate,,76,c9de0025-6473-4487-a09d-f36693c45943
"@staticmethod
    def question(args):
        mats, min_order, min_cost = args
        if min_order is not None:
            l_mats, r_mats = mats
            l_concat = ','.join([f'{m}{n}' for m, n in l_mats])
            r_concat = ','.join([f'{m}{n}' for m, n in r_mats])
            q = f'<GO><MCM>{l_concat}|{r_concat}' \
                f'<ACC>{MCM.order_text(min_order)};{min_cost}='
        else:
            concat = ','.join([f'{m}{n}' for m, n in mats])
            q = f'<GO><MCM>{concat}='
        return q",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-MCM/,MCM,"def generate(self):
        dims = [
            self.log_randrange(1, 10 ** self.config['max_digits'])
            for _ in range(self.config['num'] + 1)
        ]
        mats = tuple(
            (dims[i], dims[i + 1])
            for i in range(self.config['num'])
        )
        return mats, None, None","@staticmethod
    def thought(args) -> list[T]:
        mats, min_order, min_cost = args

        # Base cases
        if len(mats) == 1:
            return []

        if min_order is None:
            # Top-level problem
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            # Middle of recursion
            l_mats, r_mats = mats

        l_args = (l_mats, None, None)
        r_args = (r_mats, None, None)
        l_order, l_cost = MCM._answer(l_args)
        r_order, r_cost = MCM._answer(r_args)
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        thoughts = [
            T(MCM, l_args),
            T(MCM, r_args),
            T(TernaryMul, (l_mats[0][0], r_mats[0][0], r_mats[-1][1])),
            T(TernaryAdd, (l_cost, r_cost, agg_cost)),
        ]

        cost = l_cost + r_cost + agg_cost
        if min_cost is not None:
            thoughts.append(T(Compare, (cost, min_cost)))
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) > 1:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            thoughts.append(
                T(MCM, ((new_l_mats, new_r_mats), min_order, min_cost), 'tail'))

        return thoughts","(104, 4)","(116, 16)",N,function_definition,"def question(args):
        mats, min_order, min_cost = args
        if min_order is not None:
            l_mats, r_mats = mats
            l_concat = ','.join([f'{m}{n}' for m, n in l_mats])
            r_concat = ','.join([f'{m}{n}' for m, n in r_mats])
            q = f'<GO><MCM>{l_concat}|{r_concat}' \
                f'<ACC>{MCM.order_text(min_order)};{min_cost}='
        else:
            concat = ','.join([f'{m}{n}' for m, n in mats])
            q = f'<GO><MCM>{concat}='
        return q",,164,13617cbe-b310-4013-9c6e-c0028730a431
"@staticmethod
    def thought(args) -> list[T]:
        mats, min_order, min_cost = args

        # Base cases
        if len(mats) == 1:
            return []

        if min_order is None:
            # Top-level problem
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            # Middle of recursion
            l_mats, r_mats = mats

        l_args = (l_mats, None, None)
        r_args = (r_mats, None, None)
        l_order, l_cost = MCM._answer(l_args)
        r_order, r_cost = MCM._answer(r_args)
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        thoughts = [
            T(MCM, l_args),
            T(MCM, r_args),
            T(TernaryMul, (l_mats[0][0], r_mats[0][0], r_mats[-1][1])),
            T(TernaryAdd, (l_cost, r_cost, agg_cost)),
        ]

        cost = l_cost + r_cost + agg_cost
        if min_cost is not None:
            thoughts.append(T(Compare, (cost, min_cost)))
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) > 1:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            thoughts.append(
                T(MCM, ((new_l_mats, new_r_mats), min_order, min_cost), 'tail'))

        return thoughts",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-MCM/,MCM,"@staticmethod
    def question(args):
        mats, min_order, min_cost = args
        if min_order is not None:
            l_mats, r_mats = mats
            l_concat = ','.join([f'{m}{n}' for m, n in l_mats])
            r_concat = ','.join([f'{m}{n}' for m, n in r_mats])
            q = f'<GO><MCM>{l_concat}|{r_concat}' \
                f'<ACC>{MCM.order_text(min_order)};{min_cost}='
        else:
            concat = ','.join([f'{m}{n}' for m, n in mats])
            q = f'<GO><MCM>{concat}='
        return q","@staticmethod
    def answer(args):
        order, cost = MCM._answer(args)
        return f'{MCM.order_text(order)};{cost}<STOP>'","(118, 4)","(158, 23)",N,function_definition,"def thought(args) -> list[T]:
        mats, min_order, min_cost = args

        # Base cases
        if len(mats) == 1:
            return []

        if min_order is None:
            # Top-level problem
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            # Middle of recursion
            l_mats, r_mats = mats

        l_args = (l_mats, None, None)
        r_args = (r_mats, None, None)
        l_order, l_cost = MCM._answer(l_args)
        r_order, r_cost = MCM._answer(r_args)
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        thoughts = [
            T(MCM, l_args),
            T(MCM, r_args),
            T(TernaryMul, (l_mats[0][0], r_mats[0][0], r_mats[-1][1])),
            T(TernaryAdd, (l_cost, r_cost, agg_cost)),
        ]

        cost = l_cost + r_cost + agg_cost
        if min_cost is not None:
            thoughts.append(T(Compare, (cost, min_cost)))
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) > 1:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            thoughts.append(
                T(MCM, ((new_l_mats, new_r_mats), min_order, min_cost), 'tail'))

        return thoughts",,380,2d70dd85-31f6-4bf1-97f6-a55fb8e1097f
"@staticmethod
    def answer(args):
        order, cost = MCM._answer(args)
        return f'{MCM.order_text(order)};{cost}<STOP>'",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-MCM/,MCM,"@staticmethod
    def thought(args) -> list[T]:
        mats, min_order, min_cost = args

        # Base cases
        if len(mats) == 1:
            return []

        if min_order is None:
            # Top-level problem
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            # Middle of recursion
            l_mats, r_mats = mats

        l_args = (l_mats, None, None)
        r_args = (r_mats, None, None)
        l_order, l_cost = MCM._answer(l_args)
        r_order, r_cost = MCM._answer(r_args)
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        thoughts = [
            T(MCM, l_args),
            T(MCM, r_args),
            T(TernaryMul, (l_mats[0][0], r_mats[0][0], r_mats[-1][1])),
            T(TernaryAdd, (l_cost, r_cost, agg_cost)),
        ]

        cost = l_cost + r_cost + agg_cost
        if min_cost is not None:
            thoughts.append(T(Compare, (cost, min_cost)))
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) > 1:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            thoughts.append(
                T(MCM, ((new_l_mats, new_r_mats), min_order, min_cost), 'tail'))

        return thoughts","@staticmethod
    @lru_cache(50000)
    def _answer(args):
        mats, min_order, min_cost = args
        if len(mats) == 1:
            assert min_order is None
            return mats, 0
        if min_order is None:
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            l_mats, r_mats = mats
        l_order, l_cost = MCM._answer((l_mats, None, None))
        r_order, r_cost = MCM._answer((r_mats, None, None))
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        cost = l_cost + r_cost + agg_cost
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) == 1:
            return min_order, min_cost
        else:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            return MCM._answer(((new_l_mats, new_r_mats), min_order, min_cost))","(160, 4)","(163, 54)",N,function_definition,"def answer(args):
        order, cost = MCM._answer(args)
        return f'{MCM.order_text(order)};{cost}<STOP>'",,35,7554c524-13fc-406e-9224-81227a607fa7
"@staticmethod
    @lru_cache(50000)
    def _answer(args):
        mats, min_order, min_cost = args
        if len(mats) == 1:
            assert min_order is None
            return mats, 0
        if min_order is None:
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            l_mats, r_mats = mats
        l_order, l_cost = MCM._answer((l_mats, None, None))
        r_order, r_cost = MCM._answer((r_mats, None, None))
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        cost = l_cost + r_cost + agg_cost
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) == 1:
            return min_order, min_cost
        else:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            return MCM._answer(((new_l_mats, new_r_mats), min_order, min_cost))",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-MCM/,MCM,"@staticmethod
    def answer(args):
        order, cost = MCM._answer(args)
        return f'{MCM.order_text(order)};{cost}<STOP>'","@staticmethod
    @lru_cache(50000)
    def order_text(order):
        if len(order) == 1:
            m, n = order[0]
            return f'{m}{n}'

        order_l, order_r = order
        text_l = MCM.order_text(order_l)
        text_r = MCM.order_text(order_r)
        if len(order_l) > 1:
            text_l = f'({text_l})'
        if len(order_r) > 1:
            text_r = f'({text_r})'
        return f'{text_l},{text_r}'","(165, 4)","(189, 79)",N,function_definition,"def _answer(args):
        mats, min_order, min_cost = args
        if len(mats) == 1:
            assert min_order is None
            return mats, 0
        if min_order is None:
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            l_mats, r_mats = mats
        l_order, l_cost = MCM._answer((l_mats, None, None))
        r_order, r_cost = MCM._answer((r_mats, None, None))
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        cost = l_cost + r_cost + agg_cost
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) == 1:
            return min_order, min_cost
        else:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            return MCM._answer(((new_l_mats, new_r_mats), min_order, min_cost))",,276,fec9a539-b019-4937-9a7f-815fff492e50
"@staticmethod
    @lru_cache(50000)
    def order_text(order):
        if len(order) == 1:
            m, n = order[0]
            return f'{m}{n}'

        order_l, order_r = order
        text_l = MCM.order_text(order_l)
        text_r = MCM.order_text(order_r)
        if len(order_l) > 1:
            text_l = f'({text_l})'
        if len(order_r) > 1:
            text_r = f'({text_r})'
        return f'{text_l},{text_r}'",mcm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\mcm.py,module/class_definition-MCM/,MCM,"@staticmethod
    @lru_cache(50000)
    def _answer(args):
        mats, min_order, min_cost = args
        if len(mats) == 1:
            assert min_order is None
            return mats, 0
        if min_order is None:
            l_mats, r_mats = mats[:1], mats[1:]
        else:
            l_mats, r_mats = mats
        l_order, l_cost = MCM._answer((l_mats, None, None))
        r_order, r_cost = MCM._answer((r_mats, None, None))
        agg_cost = l_mats[0][0] * r_mats[0][0] * r_mats[-1][1]
        cost = l_cost + r_cost + agg_cost
        if min_cost is None or cost < min_cost:
            min_cost = cost
            min_order = l_order, r_order

        if len(r_mats) == 1:
            return min_order, min_cost
        else:
            new_l_mats = l_mats + (r_mats[0],)
            new_r_mats = r_mats[1:]
            return MCM._answer(((new_l_mats, new_r_mats), min_order, min_cost))",Next sibling does not exist,"(191, 4)","(205, 35)",N,function_definition,"def order_text(order):
        if len(order) == 1:
            m, n = order[0]
            return f'{m}{n}'

        order_l, order_r = order
        text_l = MCM.order_text(order_l)
        text_r = MCM.order_text(order_r)
        if len(order_l) > 1:
            text_l = f'({text_l})'
        if len(order_r) > 1:
            text_r = f'({text_r})'
        return f'{text_l},{text_r}'",,130,a2a8a35c-006c-4ea9-9720-d3426f7ae421
"import math
import random
from abc import abstractmethod
from collections import namedtuple
from itertools import chain, product
from typing import Union

import torch
from torch import Tensor
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import IterableDataset, DataLoader, Dataset
from torchtext.vocab import build_vocab_from_iterator

from .tokenizer import Label, tokenizer


def collate_simple(data):
    x, y, label = zip(*data)
    return [(
        pad_sequence([torch.tensor(s) for s in x]),
        pad_sequence([torch.tensor(s) for s in y]),
        pad_sequence([torch.tensor(s) for s in label])
    )]


def collate_by_len(data, budget=256 ** 2 * 64):
    sorted_data = sorted(data, key=lambda d: len(d[0]), reverse=True)
    idx = 0
    splits = []
    while idx < len(data):
        x = sorted_data[idx][0]
        cost_each = len(x) ** 2
        split_size = max(budget // cost_each, 16)

        last_idx = min(len(data), idx + split_size)
        splits.append(sorted_data[idx:last_idx])
        idx += split_size

    result = []
    for split in splits:
        x, y, label = zip(*split)
        result.append((
            pad_sequence([torch.tensor(s) for s in x]),
            pad_sequence([torch.tensor(s) for s in y]),
            pad_sequence([torch.tensor(s) for s in label])
        ))
    return result


T = namedtuple('Thought', ['prob_cls', 'args', 'type'], defaults=[''])


class Problem(IterableDataset):
    name = NotImplemented
    dependencies = {}
    symbols = ['<PAD>', '<GO>', '<STOP>', '=']

    def __init__(self, paradigm, vocab, config):
        super().__init__()
        assert paradigm is not None
        self.paradigm = paradigm
        self.vocab = vocab
        self.config = config

    def __iter__(self):
        return self

    def __next__(self):
        x, y, label = self.solve(self.generate(), self.paradigm)
        return self.vocab(x), self.vocab(y), label

    def __repr__(self):
        r = f'{self.__class__.__name__}('
        r += ', '.join([f'{k}={v}' for k, v in self.config.items()])
        r += ')'
        return r

    @abstractmethod
    def generate(self):
        pass

    @staticmethod
    @abstractmethod
    def question(args):
        pass

    @staticmethod
    @abstractmethod
    def thought(args) -> list[T]:
        pass

    @staticmethod
    @abstractmethod
    def answer(args):
        pass

    @staticmethod
    def max_config(config1, config2):
        if config1 is None or config1['max_digits'] < config2['max_digits']:
            return config2
        else:
            return config1

    @classmethod
    def solve(cls, args, paradigm):
        # Question
        x, y, label = Problem._init_question_xyl(cls.question(args))

        # Thought
        tail_recursion = False
        if paradigm == 'wt':
            pass
        elif paradigm == 'rot':
            for sub_cls, sub_args, t_type in cls.thought(args):
                t_q = sub_cls.question(sub_args)
                if t_type == 'tail':
                    tail_recursion = True
                    t_a = None
                else:
                    assert not tail_recursion, 'Tail thought is not at the end'
                    t_a = sub_cls.answer(sub_args)
                Problem._add_thought_xyl(t_q, t_a, x, y, label)
        elif paradigm == 'cot':
            t = _flatten_thought(cls, args)
            x.extend(t)
            y.extend(t)
            label.extend([Label.T] * len(t))
        else:
            raise ValueError(f'Unsupported paradigm {paradigm}')

        # Answer
        if not tail_recursion:
            Problem._add_answer_xyl(cls.answer(args), x, y, label)

        return x, y, label

    @staticmethod
    def _init_question_xyl(question) \
            -> tuple[list[str], list[str], list[int]]:
        x = tokenizer(question)
        y = x[1:]
        label = [Label.Q] * len(y)
        return x, y, label

    @staticmethod
    def _add_answer_xyl(answer, x, y, label):
        answer = tokenizer(answer)
        x += answer[:-1]
        y += answer
        label += [Label.A] * len(answer)

    @staticmethod
    def _add_thought_xyl(t_q, t_a, x, y, label):
        t_q = tokenizer(t_q)
        if t_a is None:
            # Tail recursion
            t_q[0] = '<TAIL>'
        x += t_q
        y += t_q + ['<THINK>']
        label += [Label.T] * (len(t_q) + 1)
        if t_a is not None:
            t_a = tokenizer(t_a)
            x += t_a
            y += ['<PAD>'] * (len(t_a) - 1)
            label += [Label.PAD] * (len(t_a) - 1)

    def get_train_loader(self, batch_size, num_workers=1,
                         collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        return product(range(max_num), range(max_num))

    def get_unique_args(self, size):
        unique_args = set()
        for _ in range(size * 1000):
            if len(unique_args) == size:
                break
            unique_args.add(self.generate())
        return unique_args

    @staticmethod
    def split_qta(x: Union[list, Tensor], y: Union[list, Tensor],
                  label: Union[list, Tensor]):
        if not isinstance(label, Tensor):
            label = torch.tensor(label)
        len_q = (label == Label.Q).sum() + 1
        len_a = (label == Label.A).sum()
        question = x[:len_q]
        thought = x[len_q:-len_a + 1]
        answer = y[-len_a:]
        return question, thought, answer

    @staticmethod
    def log10_uniform(log10_a, log10_b):
        """"""Sample from log10-uniform distribution

        X is sampled s.t. log10(X) ~ Uniform[log10(a), log10(b)).
        X is optionally transformed to range [trans_a, trans_b).
        """"""
        return 10 ** (random.random() * (log10_b - log10_a) + log10_a)

    @staticmethod
    def log_randrange(a, b, offset=3):
        """"""Sample random int in range [a, b)""""""
        return int(Problem.log10_uniform(
            math.log10(a + offset), math.log10(b + offset)
        ) - offset)

    @staticmethod
    def sample_positive_fraction(max_digit, reduce=False, zero=False):
        """"""Sample a positive fraction""""""
        if zero:
            numer = Problem.log_randrange(0, max_digit)
        else:
            numer = Problem.log_randrange(1, max_digit)
        denom = Problem.log_randrange(1, max_digit)

        if reduce:
            gcd = math.gcd(numer, denom)
            numer = numer // gcd
            denom = denom // gcd

        return numer, denom

    @staticmethod
    def sample_fraction(max_digit, reduce=False, zero=False):
        """"""Sample positive or negative fraction""""""
        numer, denom = Problem.sample_positive_fraction(max_digit, reduce, zero)
        if random.random() < 0.5:
            numer = -numer
        return numer, denom
    
    @staticmethod
    def sample_linear_2d(max_digit, min_num=0):
        """"""Sample coefficients of 2d linear equation""""""
        max_coef = 10 ** max_digit

        x_coef = Problem.log_randrange(min_num, max_coef)
        x_coef = Problem.assign_sign(x_coef)

        y_coef = Problem.log_randrange(min_num, max_coef)
        y_coef = Problem.assign_sign(y_coef)

        if x_coef == 0 and y_coef == 0:
            return Problem.sample_linear_2d(max_digit)

        const = Problem.log_randrange(0, max_coef)
        const = Problem.assign_sign(const)

        return x_coef, y_coef, const

    @staticmethod
    def assign_sign(arg):
        if random.random() < 0.5:
            return arg
        else:
            return -arg

    @classmethod
    def required_symbols(cls, recurse=True):
        dep_symbols = []
        dep_symbols.extend(cls.symbols)
        if recurse:
            for dep in cls.dependencies:
                dep_symbols.extend(dep.required_symbols(recurse=True))
        return dep_symbols

    @classmethod
    def recursive_dependencies(cls):
        dep = [dep.recursive_dependencies() for dep in cls.dependencies]
        return list(dict.fromkeys(chain(*dep, cls.dependencies)))


def build_vocab(prob_classes: list[type[Problem]], paradigm):
    if paradigm == 'rot':
        paradigm_specials = ['<THINK>', '<TAIL>']
    elif paradigm == 'cot':
        paradigm_specials = ['<TAIL>']
    else:
        paradigm_specials = []
    specials = chain(
        Problem.symbols,
        paradigm_specials,
        *[prob_cls.required_symbols(recurse=paradigm in ['cot', 'rot'])
          for prob_cls in prob_classes])
    specials = sorted(set(specials))
    return build_vocab_from_iterator('0123456789', specials=specials)


class FixedProblemSet(Dataset):
    def __init__(self, probs: list[tuple[type[Problem], tuple]],
                 paradigm, vocab):
        self.probs = probs
        self.paradigm = paradigm
        self.vocab = vocab

    def __getitem__(self, item):
        prob_cls, args = self.probs[item]
        x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
        return self.vocab(x), self.vocab(y), label

    def __len__(self):
        return len(self.probs)


class ProbGraph(dict):
    def extend(self, probs):
        for prob in probs:
            if prob in self:
                continue
            prob_cls, args = prob
            subprobs = [t[:2] for t in prob_cls.thought(args)]
            self[prob] = subprobs
            if len(subprobs) > 0:
                self.extend(subprobs)


class ProblemSet(IterableDataset):
    class Iterator:
        def __init__(self, problem_set):
            self.problem_set = problem_set
            self.paradigm = problem_set.paradigm
            self.vocab = problem_set.vocab
            self.ammo = []
            self.magazine = []
            self.magazine_size = 1000

        def __next__(self):
            if len(self.magazine) == 0:
                # Reload
                while len(self.ammo) < 10000:
                    problem = random.choices(self.problem_set.problems)[0]
                    args = problem.generate()
                    if self.paradigm == 'rot':
                        graph = ProbGraph()
                        graph.extend([(problem.__class__, args)])
                        self.ammo.extend(graph.keys())
                    else:
                        self.ammo.append((problem.__class__, args))

                random.shuffle(self.ammo)
                self.magazine = self.ammo[:self.magazine_size]
                self.ammo = self.ammo[self.magazine_size:]

            prob_cls, args = self.magazine.pop()
            x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
            return self.vocab(x), self.vocab(y), label

    def __init__(self, problems: list[Problem], paradigm, vocab):
        super().__init__()
        self.problems = problems
        self.paradigm = paradigm
        self.vocab = vocab

    def __iter__(self):
        return self.Iterator(self)

    def get_data_loader(self, batch_size, num_workers=1,
                        collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)


def _flatten_thought(cls, args):
    flat_t = []
    for sub_cls, sub_args, t_type in cls.thought(args):
        q = tokenizer(sub_cls.question(sub_args))
        if t_type == 'tail':
            q[0] = '<TAIL>'
        flat_t.extend(q)
        flat_t.extend(_flatten_thought(sub_cls, sub_args))
        if t_type != 'tail':
            flat_t.extend(tokenizer(sub_cls.answer(sub_args)))
    return flat_t
",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,,NA,Previous sibling does not exist,"import math
import random
from abc import abstractmethod
from collections import namedtuple
from itertools import chain, product
from typing import Union
import torch
from torch import Tensor
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import IterableDataset, DataLoader, Dataset
from torchtext.vocab import build_vocab_from_iterator
from .tokenizer import Label, tokenizer","(0, 0)","(379, 0)",N,module,module,,2746,494b575c-e911-4ae9-806a-0d8af137fb2f
"import math
import random
from abc import abstractmethod
from collections import namedtuple
from itertools import chain, product
from typing import Union
import torch
from torch import Tensor
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import IterableDataset, DataLoader, Dataset
from torchtext.vocab import build_vocab_from_iterator
from .tokenizer import Label, tokenizer",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,Previous sibling does not exist,"def collate_simple(data):
    x, y, label = zip(*data)
    return [(
        pad_sequence([torch.tensor(s) for s in x]),
        pad_sequence([torch.tensor(s) for s in y]),
        pad_sequence([torch.tensor(s) for s in label])
    )]","(0, 0)","(13, 39)",N,"import_statement,import_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement",import_statement,,64,c62c13b1-4b33-4f5e-8b06-bb17ba53daa6
"def collate_simple(data):
    x, y, label = zip(*data)
    return [(
        pad_sequence([torch.tensor(s) for s in x]),
        pad_sequence([torch.tensor(s) for s in y]),
        pad_sequence([torch.tensor(s) for s in label])
    )]",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,"import math
import random
from abc import abstractmethod
from collections import namedtuple
from itertools import chain, product
from typing import Union
import torch
from torch import Tensor
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import IterableDataset, DataLoader, Dataset
from torchtext.vocab import build_vocab_from_iterator
from .tokenizer import Label, tokenizer","def collate_by_len(data, budget=256 ** 2 * 64):
    sorted_data = sorted(data, key=lambda d: len(d[0]), reverse=True)
    idx = 0
    splits = []
    while idx < len(data):
        x = sorted_data[idx][0]
        cost_each = len(x) ** 2
        split_size = max(budget // cost_each, 16)

        last_idx = min(len(data), idx + split_size)
        splits.append(sorted_data[idx:last_idx])
        idx += split_size

    result = []
    for split in splits:
        x, y, label = zip(*split)
        result.append((
            pad_sequence([torch.tensor(s) for s in x]),
            pad_sequence([torch.tensor(s) for s in y]),
            pad_sequence([torch.tensor(s) for s in label])
        ))
    return result","(16, 0)","(22, 6)",N,function_definition,collate_simple,,63,86751857-9c17-4664-99d7-3cefb48d2316
"def collate_by_len(data, budget=256 ** 2 * 64):
    sorted_data = sorted(data, key=lambda d: len(d[0]), reverse=True)
    idx = 0
    splits = []
    while idx < len(data):
        x = sorted_data[idx][0]
        cost_each = len(x) ** 2
        split_size = max(budget // cost_each, 16)

        last_idx = min(len(data), idx + split_size)
        splits.append(sorted_data[idx:last_idx])
        idx += split_size

    result = []
    for split in splits:
        x, y, label = zip(*split)
        result.append((
            pad_sequence([torch.tensor(s) for s in x]),
            pad_sequence([torch.tensor(s) for s in y]),
            pad_sequence([torch.tensor(s) for s in label])
        ))
    return result",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,"def collate_simple(data):
    x, y, label = zip(*data)
    return [(
        pad_sequence([torch.tensor(s) for s in x]),
        pad_sequence([torch.tensor(s) for s in y]),
        pad_sequence([torch.tensor(s) for s in label])
    )]","T = namedtuple('Thought', ['prob_cls', 'args', 'type'], defaults=[''])","(25, 0)","(46, 17)",N,function_definition,collate_by_len,,184,d6303208-7eb8-4d57-be5e-c5a56af575ca
"T = namedtuple('Thought', ['prob_cls', 'args', 'type'], defaults=[''])",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,"def collate_by_len(data, budget=256 ** 2 * 64):
    sorted_data = sorted(data, key=lambda d: len(d[0]), reverse=True)
    idx = 0
    splits = []
    while idx < len(data):
        x = sorted_data[idx][0]
        cost_each = len(x) ** 2
        split_size = max(budget // cost_each, 16)

        last_idx = min(len(data), idx + split_size)
        splits.append(sorted_data[idx:last_idx])
        idx += split_size

    result = []
    for split in splits:
        x, y, label = zip(*split)
        result.append((
            pad_sequence([torch.tensor(s) for s in x]),
            pad_sequence([torch.tensor(s) for s in y]),
            pad_sequence([torch.tensor(s) for s in label])
        ))
    return result","class Problem(IterableDataset):
    name = NotImplemented
    dependencies = {}
    symbols = ['<PAD>', '<GO>', '<STOP>', '=']

    def __init__(self, paradigm, vocab, config):
        super().__init__()
        assert paradigm is not None
        self.paradigm = paradigm
        self.vocab = vocab
        self.config = config

    def __iter__(self):
        return self

    def __next__(self):
        x, y, label = self.solve(self.generate(), self.paradigm)
        return self.vocab(x), self.vocab(y), label

    def __repr__(self):
        r = f'{self.__class__.__name__}('
        r += ', '.join([f'{k}={v}' for k, v in self.config.items()])
        r += ')'
        return r

    @abstractmethod
    def generate(self):
        pass

    @staticmethod
    @abstractmethod
    def question(args):
        pass

    @staticmethod
    @abstractmethod
    def thought(args) -> list[T]:
        pass

    @staticmethod
    @abstractmethod
    def answer(args):
        pass

    @staticmethod
    def max_config(config1, config2):
        if config1 is None or config1['max_digits'] < config2['max_digits']:
            return config2
        else:
            return config1

    @classmethod
    def solve(cls, args, paradigm):
        # Question
        x, y, label = Problem._init_question_xyl(cls.question(args))

        # Thought
        tail_recursion = False
        if paradigm == 'wt':
            pass
        elif paradigm == 'rot':
            for sub_cls, sub_args, t_type in cls.thought(args):
                t_q = sub_cls.question(sub_args)
                if t_type == 'tail':
                    tail_recursion = True
                    t_a = None
                else:
                    assert not tail_recursion, 'Tail thought is not at the end'
                    t_a = sub_cls.answer(sub_args)
                Problem._add_thought_xyl(t_q, t_a, x, y, label)
        elif paradigm == 'cot':
            t = _flatten_thought(cls, args)
            x.extend(t)
            y.extend(t)
            label.extend([Label.T] * len(t))
        else:
            raise ValueError(f'Unsupported paradigm {paradigm}')

        # Answer
        if not tail_recursion:
            Problem._add_answer_xyl(cls.answer(args), x, y, label)

        return x, y, label

    @staticmethod
    def _init_question_xyl(question) \
            -> tuple[list[str], list[str], list[int]]:
        x = tokenizer(question)
        y = x[1:]
        label = [Label.Q] * len(y)
        return x, y, label

    @staticmethod
    def _add_answer_xyl(answer, x, y, label):
        answer = tokenizer(answer)
        x += answer[:-1]
        y += answer
        label += [Label.A] * len(answer)

    @staticmethod
    def _add_thought_xyl(t_q, t_a, x, y, label):
        t_q = tokenizer(t_q)
        if t_a is None:
            # Tail recursion
            t_q[0] = '<TAIL>'
        x += t_q
        y += t_q + ['<THINK>']
        label += [Label.T] * (len(t_q) + 1)
        if t_a is not None:
            t_a = tokenizer(t_a)
            x += t_a
            y += ['<PAD>'] * (len(t_a) - 1)
            label += [Label.PAD] * (len(t_a) - 1)

    def get_train_loader(self, batch_size, num_workers=1,
                         collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        return product(range(max_num), range(max_num))

    def get_unique_args(self, size):
        unique_args = set()
        for _ in range(size * 1000):
            if len(unique_args) == size:
                break
            unique_args.add(self.generate())
        return unique_args

    @staticmethod
    def split_qta(x: Union[list, Tensor], y: Union[list, Tensor],
                  label: Union[list, Tensor]):
        if not isinstance(label, Tensor):
            label = torch.tensor(label)
        len_q = (label == Label.Q).sum() + 1
        len_a = (label == Label.A).sum()
        question = x[:len_q]
        thought = x[len_q:-len_a + 1]
        answer = y[-len_a:]
        return question, thought, answer

    @staticmethod
    def log10_uniform(log10_a, log10_b):
        """"""Sample from log10-uniform distribution

        X is sampled s.t. log10(X) ~ Uniform[log10(a), log10(b)).
        X is optionally transformed to range [trans_a, trans_b).
        """"""
        return 10 ** (random.random() * (log10_b - log10_a) + log10_a)

    @staticmethod
    def log_randrange(a, b, offset=3):
        """"""Sample random int in range [a, b)""""""
        return int(Problem.log10_uniform(
            math.log10(a + offset), math.log10(b + offset)
        ) - offset)

    @staticmethod
    def sample_positive_fraction(max_digit, reduce=False, zero=False):
        """"""Sample a positive fraction""""""
        if zero:
            numer = Problem.log_randrange(0, max_digit)
        else:
            numer = Problem.log_randrange(1, max_digit)
        denom = Problem.log_randrange(1, max_digit)

        if reduce:
            gcd = math.gcd(numer, denom)
            numer = numer // gcd
            denom = denom // gcd

        return numer, denom

    @staticmethod
    def sample_fraction(max_digit, reduce=False, zero=False):
        """"""Sample positive or negative fraction""""""
        numer, denom = Problem.sample_positive_fraction(max_digit, reduce, zero)
        if random.random() < 0.5:
            numer = -numer
        return numer, denom
    
    @staticmethod
    def sample_linear_2d(max_digit, min_num=0):
        """"""Sample coefficients of 2d linear equation""""""
        max_coef = 10 ** max_digit

        x_coef = Problem.log_randrange(min_num, max_coef)
        x_coef = Problem.assign_sign(x_coef)

        y_coef = Problem.log_randrange(min_num, max_coef)
        y_coef = Problem.assign_sign(y_coef)

        if x_coef == 0 and y_coef == 0:
            return Problem.sample_linear_2d(max_digit)

        const = Problem.log_randrange(0, max_coef)
        const = Problem.assign_sign(const)

        return x_coef, y_coef, const

    @staticmethod
    def assign_sign(arg):
        if random.random() < 0.5:
            return arg
        else:
            return -arg

    @classmethod
    def required_symbols(cls, recurse=True):
        dep_symbols = []
        dep_symbols.extend(cls.symbols)
        if recurse:
            for dep in cls.dependencies:
                dep_symbols.extend(dep.required_symbols(recurse=True))
        return dep_symbols

    @classmethod
    def recursive_dependencies(cls):
        dep = [dep.recursive_dependencies() for dep in cls.dependencies]
        return list(dict.fromkeys(chain(*dep, cls.dependencies)))","(49, 0)","(49, 70)",N,expression_statement,expression_statement,,19,d1f24838-f0a5-41c7-b0c3-a43b5ff4b362
"class Problem(IterableDataset):
    name = NotImplemented
    dependencies = {}
    symbols = ['<PAD>', '<GO>', '<STOP>', '=']

    def __init__(self, paradigm, vocab, config):
        super().__init__()
        assert paradigm is not None
        self.paradigm = paradigm
        self.vocab = vocab
        self.config = config

    def __iter__(self):
        return self

    def __next__(self):
        x, y, label = self.solve(self.generate(), self.paradigm)
        return self.vocab(x), self.vocab(y), label

    def __repr__(self):
        r = f'{self.__class__.__name__}('
        r += ', '.join([f'{k}={v}' for k, v in self.config.items()])
        r += ')'
        return r

    @abstractmethod
    def generate(self):
        pass

    @staticmethod
    @abstractmethod
    def question(args):
        pass

    @staticmethod
    @abstractmethod
    def thought(args) -> list[T]:
        pass

    @staticmethod
    @abstractmethod
    def answer(args):
        pass

    @staticmethod
    def max_config(config1, config2):
        if config1 is None or config1['max_digits'] < config2['max_digits']:
            return config2
        else:
            return config1

    @classmethod
    def solve(cls, args, paradigm):
        # Question
        x, y, label = Problem._init_question_xyl(cls.question(args))

        # Thought
        tail_recursion = False
        if paradigm == 'wt':
            pass
        elif paradigm == 'rot':
            for sub_cls, sub_args, t_type in cls.thought(args):
                t_q = sub_cls.question(sub_args)
                if t_type == 'tail':
                    tail_recursion = True
                    t_a = None
                else:
                    assert not tail_recursion, 'Tail thought is not at the end'
                    t_a = sub_cls.answer(sub_args)
                Problem._add_thought_xyl(t_q, t_a, x, y, label)
        elif paradigm == 'cot':
            t = _flatten_thought(cls, args)
            x.extend(t)
            y.extend(t)
            label.extend([Label.T] * len(t))
        else:
            raise ValueError(f'Unsupported paradigm {paradigm}')

        # Answer
        if not tail_recursion:
            Problem._add_answer_xyl(cls.answer(args), x, y, label)

        return x, y, label

    @staticmethod
    def _init_question_xyl(question) \
            -> tuple[list[str], list[str], list[int]]:
        x = tokenizer(question)
        y = x[1:]
        label = [Label.Q] * len(y)
        return x, y, label

    @staticmethod
    def _add_answer_xyl(answer, x, y, label):
        answer = tokenizer(answer)
        x += answer[:-1]
        y += answer
        label += [Label.A] * len(answer)

    @staticmethod
    def _add_thought_xyl(t_q, t_a, x, y, label):
        t_q = tokenizer(t_q)
        if t_a is None:
            # Tail recursion
            t_q[0] = '<TAIL>'
        x += t_q
        y += t_q + ['<THINK>']
        label += [Label.T] * (len(t_q) + 1)
        if t_a is not None:
            t_a = tokenizer(t_a)
            x += t_a
            y += ['<PAD>'] * (len(t_a) - 1)
            label += [Label.PAD] * (len(t_a) - 1)

    def get_train_loader(self, batch_size, num_workers=1,
                         collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        return product(range(max_num), range(max_num))

    def get_unique_args(self, size):
        unique_args = set()
        for _ in range(size * 1000):
            if len(unique_args) == size:
                break
            unique_args.add(self.generate())
        return unique_args

    @staticmethod
    def split_qta(x: Union[list, Tensor], y: Union[list, Tensor],
                  label: Union[list, Tensor]):
        if not isinstance(label, Tensor):
            label = torch.tensor(label)
        len_q = (label == Label.Q).sum() + 1
        len_a = (label == Label.A).sum()
        question = x[:len_q]
        thought = x[len_q:-len_a + 1]
        answer = y[-len_a:]
        return question, thought, answer

    @staticmethod
    def log10_uniform(log10_a, log10_b):
        """"""Sample from log10-uniform distribution

        X is sampled s.t. log10(X) ~ Uniform[log10(a), log10(b)).
        X is optionally transformed to range [trans_a, trans_b).
        """"""
        return 10 ** (random.random() * (log10_b - log10_a) + log10_a)

    @staticmethod
    def log_randrange(a, b, offset=3):
        """"""Sample random int in range [a, b)""""""
        return int(Problem.log10_uniform(
            math.log10(a + offset), math.log10(b + offset)
        ) - offset)

    @staticmethod
    def sample_positive_fraction(max_digit, reduce=False, zero=False):
        """"""Sample a positive fraction""""""
        if zero:
            numer = Problem.log_randrange(0, max_digit)
        else:
            numer = Problem.log_randrange(1, max_digit)
        denom = Problem.log_randrange(1, max_digit)

        if reduce:
            gcd = math.gcd(numer, denom)
            numer = numer // gcd
            denom = denom // gcd

        return numer, denom

    @staticmethod
    def sample_fraction(max_digit, reduce=False, zero=False):
        """"""Sample positive or negative fraction""""""
        numer, denom = Problem.sample_positive_fraction(max_digit, reduce, zero)
        if random.random() < 0.5:
            numer = -numer
        return numer, denom
    
    @staticmethod
    def sample_linear_2d(max_digit, min_num=0):
        """"""Sample coefficients of 2d linear equation""""""
        max_coef = 10 ** max_digit

        x_coef = Problem.log_randrange(min_num, max_coef)
        x_coef = Problem.assign_sign(x_coef)

        y_coef = Problem.log_randrange(min_num, max_coef)
        y_coef = Problem.assign_sign(y_coef)

        if x_coef == 0 and y_coef == 0:
            return Problem.sample_linear_2d(max_digit)

        const = Problem.log_randrange(0, max_coef)
        const = Problem.assign_sign(const)

        return x_coef, y_coef, const

    @staticmethod
    def assign_sign(arg):
        if random.random() < 0.5:
            return arg
        else:
            return -arg

    @classmethod
    def required_symbols(cls, recurse=True):
        dep_symbols = []
        dep_symbols.extend(cls.symbols)
        if recurse:
            for dep in cls.dependencies:
                dep_symbols.extend(dep.required_symbols(recurse=True))
        return dep_symbols

    @classmethod
    def recursive_dependencies(cls):
        dep = [dep.recursive_dependencies() for dep in cls.dependencies]
        return list(dict.fromkeys(chain(*dep, cls.dependencies)))",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,"T = namedtuple('Thought', ['prob_cls', 'args', 'type'], defaults=[''])","name = NotImplemented
dependencies = {}
symbols = ['<PAD>', '<GO>', '<STOP>', '=']","(52, 0)","(274, 65)",N,class_definition,Problem,,1618,62a97650-eb2d-4d64-a301-030fef670633
"name = NotImplemented
dependencies = {}
symbols = ['<PAD>', '<GO>', '<STOP>', '=']",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,Previous sibling does not exist,"def __init__(self, paradigm, vocab, config):
        super().__init__()
        assert paradigm is not None
        self.paradigm = paradigm
        self.vocab = vocab
        self.config = config","(53, 4)","(55, 46)",N,"expression_statement,expression_statement,expression_statement",expression_statement,,20,57413660-9b3b-4148-b4ca-bb3c9b8b631a
"def __init__(self, paradigm, vocab, config):
        super().__init__()
        assert paradigm is not None
        self.paradigm = paradigm
        self.vocab = vocab
        self.config = config",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"name = NotImplemented
dependencies = {}
symbols = ['<PAD>', '<GO>', '<STOP>', '=']","def __iter__(self):
        return self","(57, 4)","(62, 28)",N,function_definition,__init__,,43,89e73d49-be72-4b1f-a399-5707e1d34644
"def __iter__(self):
        return self",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"def __init__(self, paradigm, vocab, config):
        super().__init__()
        assert paradigm is not None
        self.paradigm = paradigm
        self.vocab = vocab
        self.config = config","def __next__(self):
        x, y, label = self.solve(self.generate(), self.paradigm)
        return self.vocab(x), self.vocab(y), label","(64, 4)","(65, 19)",N,function_definition,__iter__,,9,771d3a3d-9922-498b-9520-88466f70b14c
"def __next__(self):
        x, y, label = self.solve(self.generate(), self.paradigm)
        return self.vocab(x), self.vocab(y), label",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"def __iter__(self):
        return self","def __repr__(self):
        r = f'{self.__class__.__name__}('
        r += ', '.join([f'{k}={v}' for k, v in self.config.items()])
        r += ')'
        return r","(67, 4)","(69, 50)",N,function_definition,__next__,,34,8e7a8efa-5781-412e-9d54-3ab38fb710bb
"def __repr__(self):
        r = f'{self.__class__.__name__}('
        r += ', '.join([f'{k}={v}' for k, v in self.config.items()])
        r += ')'
        return r",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"def __next__(self):
        x, y, label = self.solve(self.generate(), self.paradigm)
        return self.vocab(x), self.vocab(y), label","@abstractmethod
    def generate(self):
        pass","(71, 4)","(75, 16)",N,function_definition,__repr__,,51,1d7554a6-893d-49b9-8579-0677e6a6ece5
"@abstractmethod
    def generate(self):
        pass",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"def __repr__(self):
        r = f'{self.__class__.__name__}('
        r += ', '.join([f'{k}={v}' for k, v in self.config.items()])
        r += ')'
        return r","@staticmethod
    @abstractmethod
    def question(args):
        pass","(77, 4)","(79, 12)",N,function_definition,"def generate(self):
        pass",,10,81be05ef-f8c7-4d77-8f57-0ea900f96165
"@staticmethod
    @abstractmethod
    def question(args):
        pass",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@abstractmethod
    def generate(self):
        pass","@staticmethod
    @abstractmethod
    def thought(args) -> list[T]:
        pass","(81, 4)","(84, 12)",N,function_definition,"def question(args):
        pass",,14,e67fe020-6e1f-4ff7-bc9c-df2b0503f7cf
"@staticmethod
    @abstractmethod
    def thought(args) -> list[T]:
        pass",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    @abstractmethod
    def question(args):
        pass","@staticmethod
    @abstractmethod
    def answer(args):
        pass","(86, 4)","(89, 12)",N,function_definition,"def thought(args) -> list[T]:
        pass",,18,9e054e59-1348-4e91-8ec8-c1aee01901b1
"@staticmethod
    @abstractmethod
    def answer(args):
        pass",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    @abstractmethod
    def thought(args) -> list[T]:
        pass","@staticmethod
    def max_config(config1, config2):
        if config1 is None or config1['max_digits'] < config2['max_digits']:
            return config2
        else:
            return config1","(91, 4)","(94, 12)",N,function_definition,"def answer(args):
        pass",,14,d3d444fe-d354-4bdf-9b76-977844481b9a
"@staticmethod
    def max_config(config1, config2):
        if config1 is None or config1['max_digits'] < config2['max_digits']:
            return config2
        else:
            return config1",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    @abstractmethod
    def answer(args):
        pass","@classmethod
    def solve(cls, args, paradigm):
        # Question
        x, y, label = Problem._init_question_xyl(cls.question(args))

        # Thought
        tail_recursion = False
        if paradigm == 'wt':
            pass
        elif paradigm == 'rot':
            for sub_cls, sub_args, t_type in cls.thought(args):
                t_q = sub_cls.question(sub_args)
                if t_type == 'tail':
                    tail_recursion = True
                    t_a = None
                else:
                    assert not tail_recursion, 'Tail thought is not at the end'
                    t_a = sub_cls.answer(sub_args)
                Problem._add_thought_xyl(t_q, t_a, x, y, label)
        elif paradigm == 'cot':
            t = _flatten_thought(cls, args)
            x.extend(t)
            y.extend(t)
            label.extend([Label.T] * len(t))
        else:
            raise ValueError(f'Unsupported paradigm {paradigm}')

        # Answer
        if not tail_recursion:
            Problem._add_answer_xyl(cls.answer(args), x, y, label)

        return x, y, label","(96, 4)","(101, 26)",N,function_definition,"def max_config(config1, config2):
        if config1 is None or config1['max_digits'] < config2['max_digits']:
            return config2
        else:
            return config1",,45,6f37c2b7-b9c8-4c24-bdaa-70a3d8975c42
"@classmethod
    def solve(cls, args, paradigm):
        # Question
        x, y, label = Problem._init_question_xyl(cls.question(args))

        # Thought
        tail_recursion = False
        if paradigm == 'wt':
            pass
        elif paradigm == 'rot':
            for sub_cls, sub_args, t_type in cls.thought(args):
                t_q = sub_cls.question(sub_args)
                if t_type == 'tail':
                    tail_recursion = True
                    t_a = None
                else:
                    assert not tail_recursion, 'Tail thought is not at the end'
                    t_a = sub_cls.answer(sub_args)
                Problem._add_thought_xyl(t_q, t_a, x, y, label)
        elif paradigm == 'cot':
            t = _flatten_thought(cls, args)
            x.extend(t)
            y.extend(t)
            label.extend([Label.T] * len(t))
        else:
            raise ValueError(f'Unsupported paradigm {paradigm}')

        # Answer
        if not tail_recursion:
            Problem._add_answer_xyl(cls.answer(args), x, y, label)

        return x, y, label",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def max_config(config1, config2):
        if config1 is None or config1['max_digits'] < config2['max_digits']:
            return config2
        else:
            return config1","@staticmethod
    def _init_question_xyl(question) \
            -> tuple[list[str], list[str], list[int]]:
        x = tokenizer(question)
        y = x[1:]
        label = [Label.Q] * len(y)
        return x, y, label","(103, 4)","(134, 26)",N,function_definition,"def solve(cls, args, paradigm):
        # Question
        x, y, label = Problem._init_question_xyl(cls.question(args))

        # Thought
        tail_recursion = False
        if paradigm == 'wt':
            pass
        elif paradigm == 'rot':
            for sub_cls, sub_args, t_type in cls.thought(args):
                t_q = sub_cls.question(sub_args)
                if t_type == 'tail':
                    tail_recursion = True
                    t_a = None
                else:
                    assert not tail_recursion, 'Tail thought is not at the end'
                    t_a = sub_cls.answer(sub_args)
                Problem._add_thought_xyl(t_q, t_a, x, y, label)
        elif paradigm == 'cot':
            t = _flatten_thought(cls, args)
            x.extend(t)
            y.extend(t)
            label.extend([Label.T] * len(t))
        else:
            raise ValueError(f'Unsupported paradigm {paradigm}')

        # Answer
        if not tail_recursion:
            Problem._add_answer_xyl(cls.answer(args), x, y, label)

        return x, y, label",,246,73b059bc-7e32-4f6c-8bad-bc49ec93cb4f
"@staticmethod
    def _init_question_xyl(question) \
            -> tuple[list[str], list[str], list[int]]:
        x = tokenizer(question)
        y = x[1:]
        label = [Label.Q] * len(y)
        return x, y, label",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@classmethod
    def solve(cls, args, paradigm):
        # Question
        x, y, label = Problem._init_question_xyl(cls.question(args))

        # Thought
        tail_recursion = False
        if paradigm == 'wt':
            pass
        elif paradigm == 'rot':
            for sub_cls, sub_args, t_type in cls.thought(args):
                t_q = sub_cls.question(sub_args)
                if t_type == 'tail':
                    tail_recursion = True
                    t_a = None
                else:
                    assert not tail_recursion, 'Tail thought is not at the end'
                    t_a = sub_cls.answer(sub_args)
                Problem._add_thought_xyl(t_q, t_a, x, y, label)
        elif paradigm == 'cot':
            t = _flatten_thought(cls, args)
            x.extend(t)
            y.extend(t)
            label.extend([Label.T] * len(t))
        else:
            raise ValueError(f'Unsupported paradigm {paradigm}')

        # Answer
        if not tail_recursion:
            Problem._add_answer_xyl(cls.answer(args), x, y, label)

        return x, y, label","@staticmethod
    def _add_answer_xyl(answer, x, y, label):
        answer = tokenizer(answer)
        x += answer[:-1]
        y += answer
        label += [Label.A] * len(answer)","(136, 4)","(142, 26)",N,function_definition,"def _init_question_xyl(question) \
            -> tuple[list[str], list[str], list[int]]:
        x = tokenizer(question)
        y = x[1:]
        label = [Label.Q] * len(y)
        return x, y, label",,56,0a8deba6-7df5-4700-ab58-0d12358e4e46
"@staticmethod
    def _add_answer_xyl(answer, x, y, label):
        answer = tokenizer(answer)
        x += answer[:-1]
        y += answer
        label += [Label.A] * len(answer)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def _init_question_xyl(question) \
            -> tuple[list[str], list[str], list[int]]:
        x = tokenizer(question)
        y = x[1:]
        label = [Label.Q] * len(y)
        return x, y, label","@staticmethod
    def _add_thought_xyl(t_q, t_a, x, y, label):
        t_q = tokenizer(t_q)
        if t_a is None:
            # Tail recursion
            t_q[0] = '<TAIL>'
        x += t_q
        y += t_q + ['<THINK>']
        label += [Label.T] * (len(t_q) + 1)
        if t_a is not None:
            t_a = tokenizer(t_a)
            x += t_a
            y += ['<PAD>'] * (len(t_a) - 1)
            label += [Label.PAD] * (len(t_a) - 1)","(144, 4)","(149, 40)",N,function_definition,"def _add_answer_xyl(answer, x, y, label):
        answer = tokenizer(answer)
        x += answer[:-1]
        y += answer
        label += [Label.A] * len(answer)",,47,c68e7fab-acb2-4c55-9a73-1ba988de6056
"@staticmethod
    def _add_thought_xyl(t_q, t_a, x, y, label):
        t_q = tokenizer(t_q)
        if t_a is None:
            # Tail recursion
            t_q[0] = '<TAIL>'
        x += t_q
        y += t_q + ['<THINK>']
        label += [Label.T] * (len(t_q) + 1)
        if t_a is not None:
            t_a = tokenizer(t_a)
            x += t_a
            y += ['<PAD>'] * (len(t_a) - 1)
            label += [Label.PAD] * (len(t_a) - 1)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def _add_answer_xyl(answer, x, y, label):
        answer = tokenizer(answer)
        x += answer[:-1]
        y += answer
        label += [Label.A] * len(answer)","def get_train_loader(self, batch_size, num_workers=1,
                         collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)","(151, 4)","(164, 49)",N,function_definition,"def _add_thought_xyl(t_q, t_a, x, y, label):
        t_q = tokenizer(t_q)
        if t_a is None:
            # Tail recursion
            t_q[0] = '<TAIL>'
        x += t_q
        y += t_q + ['<THINK>']
        label += [Label.T] * (len(t_q) + 1)
        if t_a is not None:
            t_a = tokenizer(t_a)
            x += t_a
            y += ['<PAD>'] * (len(t_a) - 1)
            label += [Label.PAD] * (len(t_a) - 1)",,146,f4b00df2-9533-462b-9bee-eb10e891eaf4
"def get_train_loader(self, batch_size, num_workers=1,
                         collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def _add_thought_xyl(t_q, t_a, x, y, label):
        t_q = tokenizer(t_q)
        if t_a is None:
            # Tail recursion
            t_q[0] = '<TAIL>'
        x += t_q
        y += t_q + ['<THINK>']
        label += [Label.T] * (len(t_q) + 1)
        if t_a is not None:
            t_a = tokenizer(t_a)
            x += t_a
            y += ['<PAD>'] * (len(t_a) - 1)
            label += [Label.PAD] * (len(t_a) - 1)","def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        return product(range(max_num), range(max_num))","(166, 4)","(170, 53)",N,function_definition,get_train_loader,,52,aaf24ac5-aa97-4b24-bae7-7200f6d633dd
"def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        return product(range(max_num), range(max_num))",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"def get_train_loader(self, batch_size, num_workers=1,
                         collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)","def get_unique_args(self, size):
        unique_args = set()
        for _ in range(size * 1000):
            if len(unique_args) == size:
                break
            unique_args.add(self.generate())
        return unique_args","(172, 4)","(174, 54)",N,function_definition,enum_args,,29,6fe7a4e7-5142-416a-83e6-4e17759582ec
"def get_unique_args(self, size):
        unique_args = set()
        for _ in range(size * 1000):
            if len(unique_args) == size:
                break
            unique_args.add(self.generate())
        return unique_args",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        return product(range(max_num), range(max_num))","@staticmethod
    def split_qta(x: Union[list, Tensor], y: Union[list, Tensor],
                  label: Union[list, Tensor]):
        if not isinstance(label, Tensor):
            label = torch.tensor(label)
        len_q = (label == Label.Q).sum() + 1
        len_a = (label == Label.A).sum()
        question = x[:len_q]
        thought = x[len_q:-len_a + 1]
        answer = y[-len_a:]
        return question, thought, answer","(176, 4)","(182, 26)",N,function_definition,get_unique_args,,48,dfe342b0-68dc-4213-8c72-1e37612cae72
"@staticmethod
    def split_qta(x: Union[list, Tensor], y: Union[list, Tensor],
                  label: Union[list, Tensor]):
        if not isinstance(label, Tensor):
            label = torch.tensor(label)
        len_q = (label == Label.Q).sum() + 1
        len_a = (label == Label.A).sum()
        question = x[:len_q]
        thought = x[len_q:-len_a + 1]
        answer = y[-len_a:]
        return question, thought, answer",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"def get_unique_args(self, size):
        unique_args = set()
        for _ in range(size * 1000):
            if len(unique_args) == size:
                break
            unique_args.add(self.generate())
        return unique_args","@staticmethod
    def log10_uniform(log10_a, log10_b):
        """"""Sample from log10-uniform distribution

        X is sampled s.t. log10(X) ~ Uniform[log10(a), log10(b)).
        X is optionally transformed to range [trans_a, trans_b).
        """"""
        return 10 ** (random.random() * (log10_b - log10_a) + log10_a)","(184, 4)","(194, 40)",N,function_definition,"def split_qta(x: Union[list, Tensor], y: Union[list, Tensor],
                  label: Union[list, Tensor]):
        if not isinstance(label, Tensor):
            label = torch.tensor(label)
        len_q = (label == Label.Q).sum() + 1
        len_a = (label == Label.A).sum()
        question = x[:len_q]
        thought = x[len_q:-len_a + 1]
        answer = y[-len_a:]
        return question, thought, answer",,109,5f5f72d1-e6f3-4c93-9aa0-b73ab29aee4f
"@staticmethod
    def log10_uniform(log10_a, log10_b):
        """"""Sample from log10-uniform distribution

        X is sampled s.t. log10(X) ~ Uniform[log10(a), log10(b)).
        X is optionally transformed to range [trans_a, trans_b).
        """"""
        return 10 ** (random.random() * (log10_b - log10_a) + log10_a)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def split_qta(x: Union[list, Tensor], y: Union[list, Tensor],
                  label: Union[list, Tensor]):
        if not isinstance(label, Tensor):
            label = torch.tensor(label)
        len_q = (label == Label.Q).sum() + 1
        len_a = (label == Label.A).sum()
        question = x[:len_q]
        thought = x[len_q:-len_a + 1]
        answer = y[-len_a:]
        return question, thought, answer","@staticmethod
    def log_randrange(a, b, offset=3):
        """"""Sample random int in range [a, b)""""""
        return int(Problem.log10_uniform(
            math.log10(a + offset), math.log10(b + offset)
        ) - offset)","(196, 4)","(203, 70)",N,function_definition,"def log10_uniform(log10_a, log10_b):
        """"""Sample from log10-uniform distribution

        X is sampled s.t. log10(X) ~ Uniform[log10(a), log10(b)).
        X is optionally transformed to range [trans_a, trans_b).
        """"""
        return 10 ** (random.random() * (log10_b - log10_a) + log10_a)",,88,38c25444-4610-4728-815b-0c8645e5c43f
"@staticmethod
    def log_randrange(a, b, offset=3):
        """"""Sample random int in range [a, b)""""""
        return int(Problem.log10_uniform(
            math.log10(a + offset), math.log10(b + offset)
        ) - offset)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def log10_uniform(log10_a, log10_b):
        """"""Sample from log10-uniform distribution

        X is sampled s.t. log10(X) ~ Uniform[log10(a), log10(b)).
        X is optionally transformed to range [trans_a, trans_b).
        """"""
        return 10 ** (random.random() * (log10_b - log10_a) + log10_a)","@staticmethod
    def sample_positive_fraction(max_digit, reduce=False, zero=False):
        """"""Sample a positive fraction""""""
        if zero:
            numer = Problem.log_randrange(0, max_digit)
        else:
            numer = Problem.log_randrange(1, max_digit)
        denom = Problem.log_randrange(1, max_digit)

        if reduce:
            gcd = math.gcd(numer, denom)
            numer = numer // gcd
            denom = denom // gcd

        return numer, denom","(205, 4)","(210, 19)",N,function_definition,"def log_randrange(a, b, offset=3):
        """"""Sample random int in range [a, b)""""""
        return int(Problem.log10_uniform(
            math.log10(a + offset), math.log10(b + offset)
        ) - offset)",,58,03da4351-2585-45e7-bc9e-562aba11caab
"@staticmethod
    def sample_positive_fraction(max_digit, reduce=False, zero=False):
        """"""Sample a positive fraction""""""
        if zero:
            numer = Problem.log_randrange(0, max_digit)
        else:
            numer = Problem.log_randrange(1, max_digit)
        denom = Problem.log_randrange(1, max_digit)

        if reduce:
            gcd = math.gcd(numer, denom)
            numer = numer // gcd
            denom = denom // gcd

        return numer, denom",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def log_randrange(a, b, offset=3):
        """"""Sample random int in range [a, b)""""""
        return int(Problem.log10_uniform(
            math.log10(a + offset), math.log10(b + offset)
        ) - offset)","@staticmethod
    def sample_fraction(max_digit, reduce=False, zero=False):
        """"""Sample positive or negative fraction""""""
        numer, denom = Problem.sample_positive_fraction(max_digit, reduce, zero)
        if random.random() < 0.5:
            numer = -numer
        return numer, denom","(212, 4)","(226, 27)",N,function_definition,"def sample_positive_fraction(max_digit, reduce=False, zero=False):
        """"""Sample a positive fraction""""""
        if zero:
            numer = Problem.log_randrange(0, max_digit)
        else:
            numer = Problem.log_randrange(1, max_digit)
        denom = Problem.log_randrange(1, max_digit)

        if reduce:
            gcd = math.gcd(numer, denom)
            numer = numer // gcd
            denom = denom // gcd

        return numer, denom",,104,e6b14d87-c58b-46c2-910f-854a28b50b0f
"@staticmethod
    def sample_fraction(max_digit, reduce=False, zero=False):
        """"""Sample positive or negative fraction""""""
        numer, denom = Problem.sample_positive_fraction(max_digit, reduce, zero)
        if random.random() < 0.5:
            numer = -numer
        return numer, denom",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def sample_positive_fraction(max_digit, reduce=False, zero=False):
        """"""Sample a positive fraction""""""
        if zero:
            numer = Problem.log_randrange(0, max_digit)
        else:
            numer = Problem.log_randrange(1, max_digit)
        denom = Problem.log_randrange(1, max_digit)

        if reduce:
            gcd = math.gcd(numer, denom)
            numer = numer // gcd
            denom = denom // gcd

        return numer, denom","@staticmethod
    def sample_linear_2d(max_digit, min_num=0):
        """"""Sample coefficients of 2d linear equation""""""
        max_coef = 10 ** max_digit

        x_coef = Problem.log_randrange(min_num, max_coef)
        x_coef = Problem.assign_sign(x_coef)

        y_coef = Problem.log_randrange(min_num, max_coef)
        y_coef = Problem.assign_sign(y_coef)

        if x_coef == 0 and y_coef == 0:
            return Problem.sample_linear_2d(max_digit)

        const = Problem.log_randrange(0, max_coef)
        const = Problem.assign_sign(const)

        return x_coef, y_coef, const","(228, 4)","(234, 27)",N,function_definition,"def sample_fraction(max_digit, reduce=False, zero=False):
        """"""Sample positive or negative fraction""""""
        numer, denom = Problem.sample_positive_fraction(max_digit, reduce, zero)
        if random.random() < 0.5:
            numer = -numer
        return numer, denom",,62,c3efddd7-0816-4bdd-8f56-124a97976d64
"@staticmethod
    def sample_linear_2d(max_digit, min_num=0):
        """"""Sample coefficients of 2d linear equation""""""
        max_coef = 10 ** max_digit

        x_coef = Problem.log_randrange(min_num, max_coef)
        x_coef = Problem.assign_sign(x_coef)

        y_coef = Problem.log_randrange(min_num, max_coef)
        y_coef = Problem.assign_sign(y_coef)

        if x_coef == 0 and y_coef == 0:
            return Problem.sample_linear_2d(max_digit)

        const = Problem.log_randrange(0, max_coef)
        const = Problem.assign_sign(const)

        return x_coef, y_coef, const",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def sample_fraction(max_digit, reduce=False, zero=False):
        """"""Sample positive or negative fraction""""""
        numer, denom = Problem.sample_positive_fraction(max_digit, reduce, zero)
        if random.random() < 0.5:
            numer = -numer
        return numer, denom","@staticmethod
    def assign_sign(arg):
        if random.random() < 0.5:
            return arg
        else:
            return -arg","(236, 4)","(253, 36)",N,function_definition,"def sample_linear_2d(max_digit, min_num=0):
        """"""Sample coefficients of 2d linear equation""""""
        max_coef = 10 ** max_digit

        x_coef = Problem.log_randrange(min_num, max_coef)
        x_coef = Problem.assign_sign(x_coef)

        y_coef = Problem.log_randrange(min_num, max_coef)
        y_coef = Problem.assign_sign(y_coef)

        if x_coef == 0 and y_coef == 0:
            return Problem.sample_linear_2d(max_digit)

        const = Problem.log_randrange(0, max_coef)
        const = Problem.assign_sign(const)

        return x_coef, y_coef, const",,142,1b5a1c0b-4ed0-4afd-afd0-c6c1583a6c68
"@staticmethod
    def assign_sign(arg):
        if random.random() < 0.5:
            return arg
        else:
            return -arg",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def sample_linear_2d(max_digit, min_num=0):
        """"""Sample coefficients of 2d linear equation""""""
        max_coef = 10 ** max_digit

        x_coef = Problem.log_randrange(min_num, max_coef)
        x_coef = Problem.assign_sign(x_coef)

        y_coef = Problem.log_randrange(min_num, max_coef)
        y_coef = Problem.assign_sign(y_coef)

        if x_coef == 0 and y_coef == 0:
            return Problem.sample_linear_2d(max_digit)

        const = Problem.log_randrange(0, max_coef)
        const = Problem.assign_sign(const)

        return x_coef, y_coef, const","@classmethod
    def required_symbols(cls, recurse=True):
        dep_symbols = []
        dep_symbols.extend(cls.symbols)
        if recurse:
            for dep in cls.dependencies:
                dep_symbols.extend(dep.required_symbols(recurse=True))
        return dep_symbols","(255, 4)","(260, 23)",N,function_definition,"def assign_sign(arg):
        if random.random() < 0.5:
            return arg
        else:
            return -arg",,31,db41cc91-e1d2-4382-80d3-a4555d2d7b01
"@classmethod
    def required_symbols(cls, recurse=True):
        dep_symbols = []
        dep_symbols.extend(cls.symbols)
        if recurse:
            for dep in cls.dependencies:
                dep_symbols.extend(dep.required_symbols(recurse=True))
        return dep_symbols",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@staticmethod
    def assign_sign(arg):
        if random.random() < 0.5:
            return arg
        else:
            return -arg","@classmethod
    def recursive_dependencies(cls):
        dep = [dep.recursive_dependencies() for dep in cls.dependencies]
        return list(dict.fromkeys(chain(*dep, cls.dependencies)))","(262, 4)","(269, 26)",N,function_definition,"def required_symbols(cls, recurse=True):
        dep_symbols = []
        dep_symbols.extend(cls.symbols)
        if recurse:
            for dep in cls.dependencies:
                dep_symbols.extend(dep.required_symbols(recurse=True))
        return dep_symbols",,52,af6945f9-2ae7-4ba4-8f3e-e218c6d395e6
"@classmethod
    def recursive_dependencies(cls):
        dep = [dep.recursive_dependencies() for dep in cls.dependencies]
        return list(dict.fromkeys(chain(*dep, cls.dependencies)))",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-Problem/,Problem,"@classmethod
    def required_symbols(cls, recurse=True):
        dep_symbols = []
        dep_symbols.extend(cls.symbols)
        if recurse:
            for dep in cls.dependencies:
                dep_symbols.extend(dep.required_symbols(recurse=True))
        return dep_symbols",Next sibling does not exist,"(271, 4)","(274, 65)",N,function_definition,"def recursive_dependencies(cls):
        dep = [dep.recursive_dependencies() for dep in cls.dependencies]
        return list(dict.fromkeys(chain(*dep, cls.dependencies)))",,37,7988aebc-6a79-4a9b-b197-b571e241366b
"def build_vocab(prob_classes: list[type[Problem]], paradigm):
    if paradigm == 'rot':
        paradigm_specials = ['<THINK>', '<TAIL>']
    elif paradigm == 'cot':
        paradigm_specials = ['<TAIL>']
    else:
        paradigm_specials = []
    specials = chain(
        Problem.symbols,
        paradigm_specials,
        *[prob_cls.required_symbols(recurse=paradigm in ['cot', 'rot'])
          for prob_cls in prob_classes])
    specials = sorted(set(specials))
    return build_vocab_from_iterator('0123456789', specials=specials)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,"class Problem(IterableDataset):
    name = NotImplemented
    dependencies = {}
    symbols = ['<PAD>', '<GO>', '<STOP>', '=']

    def __init__(self, paradigm, vocab, config):
        super().__init__()
        assert paradigm is not None
        self.paradigm = paradigm
        self.vocab = vocab
        self.config = config

    def __iter__(self):
        return self

    def __next__(self):
        x, y, label = self.solve(self.generate(), self.paradigm)
        return self.vocab(x), self.vocab(y), label

    def __repr__(self):
        r = f'{self.__class__.__name__}('
        r += ', '.join([f'{k}={v}' for k, v in self.config.items()])
        r += ')'
        return r

    @abstractmethod
    def generate(self):
        pass

    @staticmethod
    @abstractmethod
    def question(args):
        pass

    @staticmethod
    @abstractmethod
    def thought(args) -> list[T]:
        pass

    @staticmethod
    @abstractmethod
    def answer(args):
        pass

    @staticmethod
    def max_config(config1, config2):
        if config1 is None or config1['max_digits'] < config2['max_digits']:
            return config2
        else:
            return config1

    @classmethod
    def solve(cls, args, paradigm):
        # Question
        x, y, label = Problem._init_question_xyl(cls.question(args))

        # Thought
        tail_recursion = False
        if paradigm == 'wt':
            pass
        elif paradigm == 'rot':
            for sub_cls, sub_args, t_type in cls.thought(args):
                t_q = sub_cls.question(sub_args)
                if t_type == 'tail':
                    tail_recursion = True
                    t_a = None
                else:
                    assert not tail_recursion, 'Tail thought is not at the end'
                    t_a = sub_cls.answer(sub_args)
                Problem._add_thought_xyl(t_q, t_a, x, y, label)
        elif paradigm == 'cot':
            t = _flatten_thought(cls, args)
            x.extend(t)
            y.extend(t)
            label.extend([Label.T] * len(t))
        else:
            raise ValueError(f'Unsupported paradigm {paradigm}')

        # Answer
        if not tail_recursion:
            Problem._add_answer_xyl(cls.answer(args), x, y, label)

        return x, y, label

    @staticmethod
    def _init_question_xyl(question) \
            -> tuple[list[str], list[str], list[int]]:
        x = tokenizer(question)
        y = x[1:]
        label = [Label.Q] * len(y)
        return x, y, label

    @staticmethod
    def _add_answer_xyl(answer, x, y, label):
        answer = tokenizer(answer)
        x += answer[:-1]
        y += answer
        label += [Label.A] * len(answer)

    @staticmethod
    def _add_thought_xyl(t_q, t_a, x, y, label):
        t_q = tokenizer(t_q)
        if t_a is None:
            # Tail recursion
            t_q[0] = '<TAIL>'
        x += t_q
        y += t_q + ['<THINK>']
        label += [Label.T] * (len(t_q) + 1)
        if t_a is not None:
            t_a = tokenizer(t_a)
            x += t_a
            y += ['<PAD>'] * (len(t_a) - 1)
            label += [Label.PAD] * (len(t_a) - 1)

    def get_train_loader(self, batch_size, num_workers=1,
                         collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)

    def enum_args(self):
        max_num = 10 ** self.config['max_digits']
        return product(range(max_num), range(max_num))

    def get_unique_args(self, size):
        unique_args = set()
        for _ in range(size * 1000):
            if len(unique_args) == size:
                break
            unique_args.add(self.generate())
        return unique_args

    @staticmethod
    def split_qta(x: Union[list, Tensor], y: Union[list, Tensor],
                  label: Union[list, Tensor]):
        if not isinstance(label, Tensor):
            label = torch.tensor(label)
        len_q = (label == Label.Q).sum() + 1
        len_a = (label == Label.A).sum()
        question = x[:len_q]
        thought = x[len_q:-len_a + 1]
        answer = y[-len_a:]
        return question, thought, answer

    @staticmethod
    def log10_uniform(log10_a, log10_b):
        """"""Sample from log10-uniform distribution

        X is sampled s.t. log10(X) ~ Uniform[log10(a), log10(b)).
        X is optionally transformed to range [trans_a, trans_b).
        """"""
        return 10 ** (random.random() * (log10_b - log10_a) + log10_a)

    @staticmethod
    def log_randrange(a, b, offset=3):
        """"""Sample random int in range [a, b)""""""
        return int(Problem.log10_uniform(
            math.log10(a + offset), math.log10(b + offset)
        ) - offset)

    @staticmethod
    def sample_positive_fraction(max_digit, reduce=False, zero=False):
        """"""Sample a positive fraction""""""
        if zero:
            numer = Problem.log_randrange(0, max_digit)
        else:
            numer = Problem.log_randrange(1, max_digit)
        denom = Problem.log_randrange(1, max_digit)

        if reduce:
            gcd = math.gcd(numer, denom)
            numer = numer // gcd
            denom = denom // gcd

        return numer, denom

    @staticmethod
    def sample_fraction(max_digit, reduce=False, zero=False):
        """"""Sample positive or negative fraction""""""
        numer, denom = Problem.sample_positive_fraction(max_digit, reduce, zero)
        if random.random() < 0.5:
            numer = -numer
        return numer, denom
    
    @staticmethod
    def sample_linear_2d(max_digit, min_num=0):
        """"""Sample coefficients of 2d linear equation""""""
        max_coef = 10 ** max_digit

        x_coef = Problem.log_randrange(min_num, max_coef)
        x_coef = Problem.assign_sign(x_coef)

        y_coef = Problem.log_randrange(min_num, max_coef)
        y_coef = Problem.assign_sign(y_coef)

        if x_coef == 0 and y_coef == 0:
            return Problem.sample_linear_2d(max_digit)

        const = Problem.log_randrange(0, max_coef)
        const = Problem.assign_sign(const)

        return x_coef, y_coef, const

    @staticmethod
    def assign_sign(arg):
        if random.random() < 0.5:
            return arg
        else:
            return -arg

    @classmethod
    def required_symbols(cls, recurse=True):
        dep_symbols = []
        dep_symbols.extend(cls.symbols)
        if recurse:
            for dep in cls.dependencies:
                dep_symbols.extend(dep.required_symbols(recurse=True))
        return dep_symbols

    @classmethod
    def recursive_dependencies(cls):
        dep = [dep.recursive_dependencies() for dep in cls.dependencies]
        return list(dict.fromkeys(chain(*dep, cls.dependencies)))","class FixedProblemSet(Dataset):
    def __init__(self, probs: list[tuple[type[Problem], tuple]],
                 paradigm, vocab):
        self.probs = probs
        self.paradigm = paradigm
        self.vocab = vocab

    def __getitem__(self, item):
        prob_cls, args = self.probs[item]
        x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
        return self.vocab(x), self.vocab(y), label

    def __len__(self):
        return len(self.probs)","(277, 0)","(290, 69)",N,function_definition,build_vocab,,129,578531d4-298a-433d-b8a2-40e16a938abd
"class FixedProblemSet(Dataset):
    def __init__(self, probs: list[tuple[type[Problem], tuple]],
                 paradigm, vocab):
        self.probs = probs
        self.paradigm = paradigm
        self.vocab = vocab

    def __getitem__(self, item):
        prob_cls, args = self.probs[item]
        x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
        return self.vocab(x), self.vocab(y), label

    def __len__(self):
        return len(self.probs)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,"def build_vocab(prob_classes: list[type[Problem]], paradigm):
    if paradigm == 'rot':
        paradigm_specials = ['<THINK>', '<TAIL>']
    elif paradigm == 'cot':
        paradigm_specials = ['<TAIL>']
    else:
        paradigm_specials = []
    specials = chain(
        Problem.symbols,
        paradigm_specials,
        *[prob_cls.required_symbols(recurse=paradigm in ['cot', 'rot'])
          for prob_cls in prob_classes])
    specials = sorted(set(specials))
    return build_vocab_from_iterator('0123456789', specials=specials)","class ProbGraph(dict):
    def extend(self, probs):
        for prob in probs:
            if prob in self:
                continue
            prob_cls, args = prob
            subprobs = [t[:2] for t in prob_cls.thought(args)]
            self[prob] = subprobs
            if len(subprobs) > 0:
                self.extend(subprobs)","(293, 0)","(306, 30)",N,class_definition,FixedProblemSet,,115,4e17ae96-ba6e-4f1c-bc8f-6544f1bc0e24
"def __init__(self, probs: list[tuple[type[Problem], tuple]],
                 paradigm, vocab):
        self.probs = probs
        self.paradigm = paradigm
        self.vocab = vocab",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-FixedProblemSet/,FixedProblemSet,Previous sibling does not exist,"def __getitem__(self, item):
        prob_cls, args = self.probs[item]
        x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
        return self.vocab(x), self.vocab(y), label","(294, 4)","(298, 26)",N,function_definition,__init__,,42,242bc242-22b9-41bd-81ca-07112de73eb6
"def __getitem__(self, item):
        prob_cls, args = self.probs[item]
        x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
        return self.vocab(x), self.vocab(y), label",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-FixedProblemSet/,FixedProblemSet,"def __init__(self, probs: list[tuple[type[Problem], tuple]],
                 paradigm, vocab):
        self.probs = probs
        self.paradigm = paradigm
        self.vocab = vocab","def __len__(self):
        return len(self.probs)","(300, 4)","(303, 50)",N,function_definition,__getitem__,,48,502bcfe7-3a00-48e8-802e-a73a2ff4d2f6
"def __len__(self):
        return len(self.probs)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-FixedProblemSet/,FixedProblemSet,"def __getitem__(self, item):
        prob_cls, args = self.probs[item]
        x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
        return self.vocab(x), self.vocab(y), label",Next sibling does not exist,"(305, 4)","(306, 30)",N,function_definition,__len__,,13,48c78122-52cd-47f8-aa52-7f79fcf675b2
"class ProbGraph(dict):
    def extend(self, probs):
        for prob in probs:
            if prob in self:
                continue
            prob_cls, args = prob
            subprobs = [t[:2] for t in prob_cls.thought(args)]
            self[prob] = subprobs
            if len(subprobs) > 0:
                self.extend(subprobs)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,"class FixedProblemSet(Dataset):
    def __init__(self, probs: list[tuple[type[Problem], tuple]],
                 paradigm, vocab):
        self.probs = probs
        self.paradigm = paradigm
        self.vocab = vocab

    def __getitem__(self, item):
        prob_cls, args = self.probs[item]
        x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
        return self.vocab(x), self.vocab(y), label

    def __len__(self):
        return len(self.probs)","class ProblemSet(IterableDataset):
    class Iterator:
        def __init__(self, problem_set):
            self.problem_set = problem_set
            self.paradigm = problem_set.paradigm
            self.vocab = problem_set.vocab
            self.ammo = []
            self.magazine = []
            self.magazine_size = 1000

        def __next__(self):
            if len(self.magazine) == 0:
                # Reload
                while len(self.ammo) < 10000:
                    problem = random.choices(self.problem_set.problems)[0]
                    args = problem.generate()
                    if self.paradigm == 'rot':
                        graph = ProbGraph()
                        graph.extend([(problem.__class__, args)])
                        self.ammo.extend(graph.keys())
                    else:
                        self.ammo.append((problem.__class__, args))

                random.shuffle(self.ammo)
                self.magazine = self.ammo[:self.magazine_size]
                self.ammo = self.ammo[self.magazine_size:]

            prob_cls, args = self.magazine.pop()
            x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
            return self.vocab(x), self.vocab(y), label

    def __init__(self, problems: list[Problem], paradigm, vocab):
        super().__init__()
        self.problems = problems
        self.paradigm = paradigm
        self.vocab = vocab

    def __iter__(self):
        return self.Iterator(self)

    def get_data_loader(self, batch_size, num_workers=1,
                        collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)","(309, 0)","(318, 37)",N,class_definition,ProbGraph,,82,0788bc2f-8bfb-463d-941c-bcb9df82911d
"def extend(self, probs):
        for prob in probs:
            if prob in self:
                continue
            prob_cls, args = prob
            subprobs = [t[:2] for t in prob_cls.thought(args)]
            self[prob] = subprobs
            if len(subprobs) > 0:
                self.extend(subprobs)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-ProbGraph/,ProbGraph,Previous sibling does not exist,Next sibling does not exist,"(310, 4)","(318, 37)",N,function_definition,extend,,76,6bb5e2e1-d7d4-4edb-a164-f06823bad634
"class ProblemSet(IterableDataset):
    class Iterator:
        def __init__(self, problem_set):
            self.problem_set = problem_set
            self.paradigm = problem_set.paradigm
            self.vocab = problem_set.vocab
            self.ammo = []
            self.magazine = []
            self.magazine_size = 1000

        def __next__(self):
            if len(self.magazine) == 0:
                # Reload
                while len(self.ammo) < 10000:
                    problem = random.choices(self.problem_set.problems)[0]
                    args = problem.generate()
                    if self.paradigm == 'rot':
                        graph = ProbGraph()
                        graph.extend([(problem.__class__, args)])
                        self.ammo.extend(graph.keys())
                    else:
                        self.ammo.append((problem.__class__, args))

                random.shuffle(self.ammo)
                self.magazine = self.ammo[:self.magazine_size]
                self.ammo = self.ammo[self.magazine_size:]

            prob_cls, args = self.magazine.pop()
            x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
            return self.vocab(x), self.vocab(y), label

    def __init__(self, problems: list[Problem], paradigm, vocab):
        super().__init__()
        self.problems = problems
        self.paradigm = paradigm
        self.vocab = vocab

    def __iter__(self):
        return self.Iterator(self)

    def get_data_loader(self, batch_size, num_workers=1,
                        collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,"class ProbGraph(dict):
    def extend(self, probs):
        for prob in probs:
            if prob in self:
                continue
            prob_cls, args = prob
            subprobs = [t[:2] for t in prob_cls.thought(args)]
            self[prob] = subprobs
            if len(subprobs) > 0:
                self.extend(subprobs)","def _flatten_thought(cls, args):
    flat_t = []
    for sub_cls, sub_args, t_type in cls.thought(args):
        q = tokenizer(sub_cls.question(sub_args))
        if t_type == 'tail':
            q[0] = '<TAIL>'
        flat_t.extend(q)
        flat_t.extend(_flatten_thought(sub_cls, sub_args))
        if t_type != 'tail':
            flat_t.extend(tokenizer(sub_cls.answer(sub_args)))
    return flat_t","(321, 0)","(365, 53)",N,class_definition,ProblemSet,,357,83562e99-215e-47b3-9847-a96c3b3912ea
"class Iterator:
        def __init__(self, problem_set):
            self.problem_set = problem_set
            self.paradigm = problem_set.paradigm
            self.vocab = problem_set.vocab
            self.ammo = []
            self.magazine = []
            self.magazine_size = 1000

        def __next__(self):
            if len(self.magazine) == 0:
                # Reload
                while len(self.ammo) < 10000:
                    problem = random.choices(self.problem_set.problems)[0]
                    args = problem.generate()
                    if self.paradigm == 'rot':
                        graph = ProbGraph()
                        graph.extend([(problem.__class__, args)])
                        self.ammo.extend(graph.keys())
                    else:
                        self.ammo.append((problem.__class__, args))

                random.shuffle(self.ammo)
                self.magazine = self.ammo[:self.magazine_size]
                self.ammo = self.ammo[self.magazine_size:]

            prob_cls, args = self.magazine.pop()
            x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
            return self.vocab(x), self.vocab(y), label",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-ProblemSet/,ProblemSet,Previous sibling does not exist,"def __init__(self, problems: list[Problem], paradigm, vocab):
        super().__init__()
        self.problems = problems
        self.paradigm = paradigm
        self.vocab = vocab","(322, 4)","(350, 54)",N,class_definition,Iterator,,239,f4a57c37-ccfa-4a98-a16c-f6f02a879123
"def __init__(self, problem_set):
            self.problem_set = problem_set
            self.paradigm = problem_set.paradigm
            self.vocab = problem_set.vocab
            self.ammo = []
            self.magazine = []
            self.magazine_size = 1000",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-ProblemSet/class_definition-Iterator/,Iterator,Previous sibling does not exist,"def __next__(self):
            if len(self.magazine) == 0:
                # Reload
                while len(self.ammo) < 10000:
                    problem = random.choices(self.problem_set.problems)[0]
                    args = problem.generate()
                    if self.paradigm == 'rot':
                        graph = ProbGraph()
                        graph.extend([(problem.__class__, args)])
                        self.ammo.extend(graph.keys())
                    else:
                        self.ammo.append((problem.__class__, args))

                random.shuffle(self.ammo)
                self.magazine = self.ammo[:self.magazine_size]
                self.ammo = self.ammo[self.magazine_size:]

            prob_cls, args = self.magazine.pop()
            x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
            return self.vocab(x), self.vocab(y), label","(323, 8)","(329, 37)",N,function_definition,__init__,,58,c874ca7b-b905-48ba-abac-b4d5f5f1c53d
"def __next__(self):
            if len(self.magazine) == 0:
                # Reload
                while len(self.ammo) < 10000:
                    problem = random.choices(self.problem_set.problems)[0]
                    args = problem.generate()
                    if self.paradigm == 'rot':
                        graph = ProbGraph()
                        graph.extend([(problem.__class__, args)])
                        self.ammo.extend(graph.keys())
                    else:
                        self.ammo.append((problem.__class__, args))

                random.shuffle(self.ammo)
                self.magazine = self.ammo[:self.magazine_size]
                self.ammo = self.ammo[self.magazine_size:]

            prob_cls, args = self.magazine.pop()
            x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
            return self.vocab(x), self.vocab(y), label",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-ProblemSet/class_definition-Iterator/,Iterator,"def __init__(self, problem_set):
            self.problem_set = problem_set
            self.paradigm = problem_set.paradigm
            self.vocab = problem_set.vocab
            self.ammo = []
            self.magazine = []
            self.magazine_size = 1000",Next sibling does not exist,"(331, 8)","(350, 54)",N,function_definition,__next__,,175,569337f0-10b4-4820-93af-d50ed9594424
"def __init__(self, problems: list[Problem], paradigm, vocab):
        super().__init__()
        self.problems = problems
        self.paradigm = paradigm
        self.vocab = vocab",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-ProblemSet/,ProblemSet,"class Iterator:
        def __init__(self, problem_set):
            self.problem_set = problem_set
            self.paradigm = problem_set.paradigm
            self.vocab = problem_set.vocab
            self.ammo = []
            self.magazine = []
            self.magazine_size = 1000

        def __next__(self):
            if len(self.magazine) == 0:
                # Reload
                while len(self.ammo) < 10000:
                    problem = random.choices(self.problem_set.problems)[0]
                    args = problem.generate()
                    if self.paradigm == 'rot':
                        graph = ProbGraph()
                        graph.extend([(problem.__class__, args)])
                        self.ammo.extend(graph.keys())
                    else:
                        self.ammo.append((problem.__class__, args))

                random.shuffle(self.ammo)
                self.magazine = self.ammo[:self.magazine_size]
                self.ammo = self.ammo[self.magazine_size:]

            prob_cls, args = self.magazine.pop()
            x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
            return self.vocab(x), self.vocab(y), label","def __iter__(self):
        return self.Iterator(self)","(352, 4)","(356, 26)",N,function_definition,__init__,,41,087f1c11-e0e6-4bca-a694-43c466c0a5cd
"def __iter__(self):
        return self.Iterator(self)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-ProblemSet/,ProblemSet,"def __init__(self, problems: list[Problem], paradigm, vocab):
        super().__init__()
        self.problems = problems
        self.paradigm = paradigm
        self.vocab = vocab","def get_data_loader(self, batch_size, num_workers=1,
                        collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)","(358, 4)","(359, 34)",N,function_definition,__iter__,,12,416634ec-859d-4230-8f5d-02d946e47537
"def get_data_loader(self, batch_size, num_workers=1,
                        collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/class_definition-ProblemSet/,ProblemSet,"def __iter__(self):
        return self.Iterator(self)",Next sibling does not exist,"(361, 4)","(365, 53)",N,function_definition,get_data_loader,,52,5133da36-8bce-4acc-96d9-5cbaed9799f9
"def _flatten_thought(cls, args):
    flat_t = []
    for sub_cls, sub_args, t_type in cls.thought(args):
        q = tokenizer(sub_cls.question(sub_args))
        if t_type == 'tail':
            q[0] = '<TAIL>'
        flat_t.extend(q)
        flat_t.extend(_flatten_thought(sub_cls, sub_args))
        if t_type != 'tail':
            flat_t.extend(tokenizer(sub_cls.answer(sub_args)))
    return flat_t",problem.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\problem.py,module/,module,"class ProblemSet(IterableDataset):
    class Iterator:
        def __init__(self, problem_set):
            self.problem_set = problem_set
            self.paradigm = problem_set.paradigm
            self.vocab = problem_set.vocab
            self.ammo = []
            self.magazine = []
            self.magazine_size = 1000

        def __next__(self):
            if len(self.magazine) == 0:
                # Reload
                while len(self.ammo) < 10000:
                    problem = random.choices(self.problem_set.problems)[0]
                    args = problem.generate()
                    if self.paradigm == 'rot':
                        graph = ProbGraph()
                        graph.extend([(problem.__class__, args)])
                        self.ammo.extend(graph.keys())
                    else:
                        self.ammo.append((problem.__class__, args))

                random.shuffle(self.ammo)
                self.magazine = self.ammo[:self.magazine_size]
                self.ammo = self.ammo[self.magazine_size:]

            prob_cls, args = self.magazine.pop()
            x, y, label = prob_cls.solve(args, paradigm=self.paradigm)
            return self.vocab(x), self.vocab(y), label

    def __init__(self, problems: list[Problem], paradigm, vocab):
        super().__init__()
        self.problems = problems
        self.paradigm = paradigm
        self.vocab = vocab

    def __iter__(self):
        return self.Iterator(self)

    def get_data_loader(self, batch_size, num_workers=1,
                        collate_fn=collate_by_len):
        return DataLoader(
            self, batch_size, collate_fn=collate_fn,
            pin_memory=True, num_workers=num_workers)",Next sibling does not exist,"(368, 0)","(378, 17)",N,function_definition,_flatten_thought,,101,f957b148-5703-4529-9c59-ca5ab065e16a
"import random
from functools import lru_cache

from .problem import Problem, T
from .arithmetic import Compare, Add


class Equal(Problem):
    name = 'Equal'
    dependencies = {}
    symbols = ['<EQUAL>', ',', '<TRUE>', '<FALSE>']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO><EQUAL>{"","".join(arg for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        return []

    @staticmethod
    def answer(args):
        l, r = args
        if l == r:
            return '<TRUE><STOP>'
        else:
            return '<FALSE><STOP>'


class Maximum(Problem):
    name = 'Maximum'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<MAXIMUM>', ',']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO><MAXIMUM>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        return [T(Compare, args)]

    @staticmethod
    def answer(args):
        return f'{max(args)}<STOP>'


class LCS(Problem):
    """"""Length of the Longest Common Subsequence""""""
    name = 'LCS'
    dependencies = {
        Equal: lambda config: {},
        Maximum: lambda config: {'max_digits': len(str(config['digits']))},
    }
    symbols = ['<LCS>', ';']

    def generate(self):
        l = tuple(random.choices('0123456789', k=self.config['digits']))
        r = tuple(random.choices('0123456789', k=self.config['digits']))
        return l, r

    @staticmethod
    def question(args):
        l, r = args
        return f'<GO>{"""".join(l)}<LCS>{"""".join(r)}='

    @staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Equal, (l[-1], r[-1]))]
        if l[-1] == r[-1]:
            thoughts.append(T(LCS, (l[:-1], r[:-1])))
            return thoughts

        lcs1_args = (l[:-1], r)
        lcs2_args = (l, r[:-1])
        lcs1 = LCS._answer(lcs1_args)
        lcs2 = LCS._answer(lcs2_args)
        thoughts.extend([
            T(LCS, lcs1_args),
            T(LCS, lcs2_args),
            T(Compare, (len(lcs1), len(lcs2)))
        ])
        return thoughts

    @staticmethod
    def answer(args):
        lcs = LCS._answer(args)
        return f'{"""".join(lcs)};{len(lcs)}<STOP>'

    @staticmethod
    @lru_cache(30000)
    def _answer(args):
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return ()
        if l[-1] == r[-1]:
            return LCS._answer((l[:-1], r[:-1])) + (l[-1],)
        else:
            lcs1 = LCS._answer((l[:-1], r))
            lcs2 = LCS._answer((l, r[:-1]))
            return lcs1 if len(lcs1) >= len(lcs2) else lcs2


class LPS(Problem):
    """"""Longest Palindromic Subsequence""""""

    name = 'LPS'
    dependencies = {
        Add: lambda config: config,
        Equal: lambda config: config,
        Compare: lambda config: config,
    }
    symbols = ['<LPS>', ';']

    def generate(self):
        return tuple(random.choices('0123456789', k=self.config['digits']))

    @staticmethod
    def question(args):
        return f'<GO><LPS>{"""".join(args)}='

    @staticmethod
    def thought(args) -> list[T]:
        # Base cases
        if len(args) == 1:
            return []
        elif len(args) == 2:
            return [T(Equal, args)]

        thoughts = [T(Equal, (args[0], args[-1]))]
        if args[0] == args[-1]:
            sub_lps = LPS._answer(args[1:-1])
            thoughts.extend([
                T(LPS, args[1:-1]),
                T(Add, (len(sub_lps), 2))
            ])
        else:
            lps1_args = args[:-1]
            lps2_args = args[1:]
            lps1 = LPS._answer(lps1_args)
            lps2 = LPS._answer(lps2_args)
            thoughts.extend([
                T(LPS, lps1_args),
                T(LPS, lps2_args),
                T(Compare, (len(lps1), len(lps2)))
            ])
        return thoughts

    @staticmethod
    def answer(args):
        lps = LPS._answer(args)
        return f'{"""".join(lps)};{len(lps)}<STOP>'

    @staticmethod
    @lru_cache(30000)
    def _answer(args):
        # Base cases
        if len(args) == 1:
            return args
        elif len(args) == 2:
            if args[0] == args[1]:
                return args
            else:
                return args[:1]

        if args[0] == args[-1]:
            return args[:1] + LPS._answer(args[1:-1]) + args[-1:]

        lps1 = LPS._answer(args[:-1])
        lps2 = LPS._answer(args[1:])
        if len(lps1) >= len(lps2):
            return lps1
        else:
            return lps2
",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,,NA,Previous sibling does not exist,"import random
from functools import lru_cache
from .problem import Problem, T
from .arithmetic import Compare, Add","(0, 0)","(186, 0)",N,module,module,,1290,0fce554b-c07c-4299-a123-08d563ff2de6
"import random
from functools import lru_cache
from .problem import Problem, T
from .arithmetic import Compare, Add",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/,module,Previous sibling does not exist,"class Equal(Problem):
    name = 'Equal'
    dependencies = {}
    symbols = ['<EQUAL>', ',', '<TRUE>', '<FALSE>']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO><EQUAL>{"","".join(arg for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        return []

    @staticmethod
    def answer(args):
        l, r = args
        if l == r:
            return '<TRUE><STOP>'
        else:
            return '<FALSE><STOP>'","(0, 0)","(4, 36)",N,"import_statement,import_from_statement,import_from_statement,import_from_statement",import_statement,,23,b902ebe2-c657-44cd-a37d-eea75b697a92
"class Equal(Problem):
    name = 'Equal'
    dependencies = {}
    symbols = ['<EQUAL>', ',', '<TRUE>', '<FALSE>']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO><EQUAL>{"","".join(arg for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        return []

    @staticmethod
    def answer(args):
        l, r = args
        if l == r:
            return '<TRUE><STOP>'
        else:
            return '<FALSE><STOP>'",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/,module,"import random
from functools import lru_cache
from .problem import Problem, T
from .arithmetic import Compare, Add","class Maximum(Problem):
    name = 'Maximum'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<MAXIMUM>', ',']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO><MAXIMUM>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        return [T(Compare, args)]

    @staticmethod
    def answer(args):
        return f'{max(args)}<STOP>'","(7, 0)","(29, 34)",N,class_definition,Equal,,121,d68fcfcf-419a-4acc-a4d0-af2281e6ed9e
"def generate(self):
        pass",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-Equal/,Equal,"symbols = ['<EQUAL>', ',', '<TRUE>', '<FALSE>']","@staticmethod
    def question(args):
        return f'<GO><EQUAL>{"","".join(arg for arg in args)}='","(12, 4)","(13, 12)",N,function_definition,generate,,6,add01555-7800-4a19-8734-90a6da2b9d9f
"@staticmethod
    def question(args):
        return f'<GO><EQUAL>{"","".join(arg for arg in args)}='",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-Equal/,Equal,"def generate(self):
        pass","@staticmethod
    def thought(args) -> list[T]:
        return []","(15, 4)","(17, 61)",N,function_definition,"def question(args):
        return f'<GO><EQUAL>{"","".join(arg for arg in args)}='",,26,a3c98920-7f12-4fd8-a440-3d214e5dc711
"@staticmethod
    def thought(args) -> list[T]:
        return []",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-Equal/,Equal,"@staticmethod
    def question(args):
        return f'<GO><EQUAL>{"","".join(arg for arg in args)}='","@staticmethod
    def answer(args):
        l, r = args
        if l == r:
            return '<TRUE><STOP>'
        else:
            return '<FALSE><STOP>'","(19, 4)","(21, 17)",N,function_definition,"def thought(args) -> list[T]:
        return []",,15,4f084c8b-c0b7-469a-ae10-371423b86422
"@staticmethod
    def answer(args):
        l, r = args
        if l == r:
            return '<TRUE><STOP>'
        else:
            return '<FALSE><STOP>'",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-Equal/,Equal,"@staticmethod
    def thought(args) -> list[T]:
        return []",Next sibling does not exist,"(23, 4)","(29, 34)",N,function_definition,"def answer(args):
        l, r = args
        if l == r:
            return '<TRUE><STOP>'
        else:
            return '<FALSE><STOP>'",,38,9b95a372-bfb8-4222-b915-b5806a3f91f8
"class Maximum(Problem):
    name = 'Maximum'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<MAXIMUM>', ',']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO><MAXIMUM>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        return [T(Compare, args)]

    @staticmethod
    def answer(args):
        return f'{max(args)}<STOP>'",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/,module,"class Equal(Problem):
    name = 'Equal'
    dependencies = {}
    symbols = ['<EQUAL>', ',', '<TRUE>', '<FALSE>']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO><EQUAL>{"","".join(arg for arg in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        return []

    @staticmethod
    def answer(args):
        l, r = args
        if l == r:
            return '<TRUE><STOP>'
        else:
            return '<FALSE><STOP>'","class LCS(Problem):
    """"""Length of the Longest Common Subsequence""""""
    name = 'LCS'
    dependencies = {
        Equal: lambda config: {},
        Maximum: lambda config: {'max_digits': len(str(config['digits']))},
    }
    symbols = ['<LCS>', ';']

    def generate(self):
        l = tuple(random.choices('0123456789', k=self.config['digits']))
        r = tuple(random.choices('0123456789', k=self.config['digits']))
        return l, r

    @staticmethod
    def question(args):
        l, r = args
        return f'<GO>{"""".join(l)}<LCS>{"""".join(r)}='

    @staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Equal, (l[-1], r[-1]))]
        if l[-1] == r[-1]:
            thoughts.append(T(LCS, (l[:-1], r[:-1])))
            return thoughts

        lcs1_args = (l[:-1], r)
        lcs2_args = (l, r[:-1])
        lcs1 = LCS._answer(lcs1_args)
        lcs2 = LCS._answer(lcs2_args)
        thoughts.extend([
            T(LCS, lcs1_args),
            T(LCS, lcs2_args),
            T(Compare, (len(lcs1), len(lcs2)))
        ])
        return thoughts

    @staticmethod
    def answer(args):
        lcs = LCS._answer(args)
        return f'{"""".join(lcs)};{len(lcs)}<STOP>'

    @staticmethod
    @lru_cache(30000)
    def _answer(args):
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return ()
        if l[-1] == r[-1]:
            return LCS._answer((l[:-1], r[:-1])) + (l[-1],)
        else:
            lcs1 = LCS._answer((l[:-1], r))
            lcs2 = LCS._answer((l, r[:-1]))
            return lcs1 if len(lcs1) >= len(lcs2) else lcs2","(32, 0)","(52, 35)",N,class_definition,Maximum,,117,3db75ae3-950e-4920-af97-dccce62ff181
"def generate(self):
        pass",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-Maximum/,Maximum,"symbols = ['<MAXIMUM>', ',']","@staticmethod
    def question(args):
        return f'<GO><MAXIMUM>{"","".join([str(arg) for arg in args])}='","(39, 4)","(40, 12)",N,function_definition,generate,,6,473c5037-5c4d-46e7-99c4-94b3d55276a3
"@staticmethod
    def question(args):
        return f'<GO><MAXIMUM>{"","".join([str(arg) for arg in args])}='",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-Maximum/,Maximum,"def generate(self):
        pass","@staticmethod
    def thought(args) -> list[T]:
        return [T(Compare, args)]","(42, 4)","(44, 70)",N,function_definition,"def question(args):
        return f'<GO><MAXIMUM>{"","".join([str(arg) for arg in args])}='",,31,ff1ea831-c03a-4bba-967f-c8ff607006ae
"@staticmethod
    def thought(args) -> list[T]:
        return [T(Compare, args)]",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-Maximum/,Maximum,"@staticmethod
    def question(args):
        return f'<GO><MAXIMUM>{"","".join([str(arg) for arg in args])}='","@staticmethod
    def answer(args):
        return f'{max(args)}<STOP>'","(46, 4)","(48, 33)",N,function_definition,"def thought(args) -> list[T]:
        return [T(Compare, args)]",,21,120f98c3-5278-4172-a88c-c03c20b56b7e
"@staticmethod
    def answer(args):
        return f'{max(args)}<STOP>'",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-Maximum/,Maximum,"@staticmethod
    def thought(args) -> list[T]:
        return [T(Compare, args)]",Next sibling does not exist,"(50, 4)","(52, 35)",N,function_definition,"def answer(args):
        return f'{max(args)}<STOP>'",,18,0058992e-fab2-4faf-a320-9d5955f8bb35
"class LCS(Problem):
    """"""Length of the Longest Common Subsequence""""""
    name = 'LCS'
    dependencies = {
        Equal: lambda config: {},
        Maximum: lambda config: {'max_digits': len(str(config['digits']))},
    }
    symbols = ['<LCS>', ';']

    def generate(self):
        l = tuple(random.choices('0123456789', k=self.config['digits']))
        r = tuple(random.choices('0123456789', k=self.config['digits']))
        return l, r

    @staticmethod
    def question(args):
        l, r = args
        return f'<GO>{"""".join(l)}<LCS>{"""".join(r)}='

    @staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Equal, (l[-1], r[-1]))]
        if l[-1] == r[-1]:
            thoughts.append(T(LCS, (l[:-1], r[:-1])))
            return thoughts

        lcs1_args = (l[:-1], r)
        lcs2_args = (l, r[:-1])
        lcs1 = LCS._answer(lcs1_args)
        lcs2 = LCS._answer(lcs2_args)
        thoughts.extend([
            T(LCS, lcs1_args),
            T(LCS, lcs2_args),
            T(Compare, (len(lcs1), len(lcs2)))
        ])
        return thoughts

    @staticmethod
    def answer(args):
        lcs = LCS._answer(args)
        return f'{"""".join(lcs)};{len(lcs)}<STOP>'

    @staticmethod
    @lru_cache(30000)
    def _answer(args):
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return ()
        if l[-1] == r[-1]:
            return LCS._answer((l[:-1], r[:-1])) + (l[-1],)
        else:
            lcs1 = LCS._answer((l[:-1], r))
            lcs2 = LCS._answer((l, r[:-1]))
            return lcs1 if len(lcs1) >= len(lcs2) else lcs2",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/,module,"class Maximum(Problem):
    name = 'Maximum'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<MAXIMUM>', ',']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<GO><MAXIMUM>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        return [T(Compare, args)]

    @staticmethod
    def answer(args):
        return f'{max(args)}<STOP>'","class LPS(Problem):
    """"""Longest Palindromic Subsequence""""""

    name = 'LPS'
    dependencies = {
        Add: lambda config: config,
        Equal: lambda config: config,
        Compare: lambda config: config,
    }
    symbols = ['<LPS>', ';']

    def generate(self):
        return tuple(random.choices('0123456789', k=self.config['digits']))

    @staticmethod
    def question(args):
        return f'<GO><LPS>{"""".join(args)}='

    @staticmethod
    def thought(args) -> list[T]:
        # Base cases
        if len(args) == 1:
            return []
        elif len(args) == 2:
            return [T(Equal, args)]

        thoughts = [T(Equal, (args[0], args[-1]))]
        if args[0] == args[-1]:
            sub_lps = LPS._answer(args[1:-1])
            thoughts.extend([
                T(LPS, args[1:-1]),
                T(Add, (len(sub_lps), 2))
            ])
        else:
            lps1_args = args[:-1]
            lps2_args = args[1:]
            lps1 = LPS._answer(lps1_args)
            lps2 = LPS._answer(lps2_args)
            thoughts.extend([
                T(LPS, lps1_args),
                T(LPS, lps2_args),
                T(Compare, (len(lps1), len(lps2)))
            ])
        return thoughts

    @staticmethod
    def answer(args):
        lps = LPS._answer(args)
        return f'{"""".join(lps)};{len(lps)}<STOP>'

    @staticmethod
    @lru_cache(30000)
    def _answer(args):
        # Base cases
        if len(args) == 1:
            return args
        elif len(args) == 2:
            if args[0] == args[1]:
                return args
            else:
                return args[:1]

        if args[0] == args[-1]:
            return args[:1] + LPS._answer(args[1:-1]) + args[-1:]

        lps1 = LPS._answer(args[:-1])
        lps2 = LPS._answer(args[1:])
        if len(lps1) >= len(lps2):
            return lps1
        else:
            return lps2","(55, 0)","(112, 59)",N,class_definition,LCS,,499,8046b83c-8dfc-4728-b00b-4b77afd08634
"def generate(self):
        l = tuple(random.choices('0123456789', k=self.config['digits']))
        r = tuple(random.choices('0123456789', k=self.config['digits']))
        return l, r",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LCS/,LCS,"symbols = ['<LCS>', ';']","@staticmethod
    def question(args):
        l, r = args
        return f'<GO>{"""".join(l)}<LCS>{"""".join(r)}='","(64, 4)","(67, 19)",N,function_definition,generate,,45,5aca9d1f-25b5-4b52-a722-f59a08d3b8cd
"@staticmethod
    def question(args):
        l, r = args
        return f'<GO>{"""".join(l)}<LCS>{"""".join(r)}='",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LCS/,LCS,"def generate(self):
        l = tuple(random.choices('0123456789', k=self.config['digits']))
        r = tuple(random.choices('0123456789', k=self.config['digits']))
        return l, r","@staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Equal, (l[-1], r[-1]))]
        if l[-1] == r[-1]:
            thoughts.append(T(LCS, (l[:-1], r[:-1])))
            return thoughts

        lcs1_args = (l[:-1], r)
        lcs2_args = (l, r[:-1])
        lcs1 = LCS._answer(lcs1_args)
        lcs2 = LCS._answer(lcs2_args)
        thoughts.extend([
            T(LCS, lcs1_args),
            T(LCS, lcs2_args),
            T(Compare, (len(lcs1), len(lcs2)))
        ])
        return thoughts","(69, 4)","(72, 52)",N,function_definition,"def question(args):
        l, r = args
        return f'<GO>{"""".join(l)}<LCS>{"""".join(r)}='",,34,f257ec56-403e-4d3b-98b1-cd3452bb183b
"@staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Equal, (l[-1], r[-1]))]
        if l[-1] == r[-1]:
            thoughts.append(T(LCS, (l[:-1], r[:-1])))
            return thoughts

        lcs1_args = (l[:-1], r)
        lcs2_args = (l, r[:-1])
        lcs1 = LCS._answer(lcs1_args)
        lcs2 = LCS._answer(lcs2_args)
        thoughts.extend([
            T(LCS, lcs1_args),
            T(LCS, lcs2_args),
            T(Compare, (len(lcs1), len(lcs2)))
        ])
        return thoughts",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LCS/,LCS,"@staticmethod
    def question(args):
        l, r = args
        return f'<GO>{"""".join(l)}<LCS>{"""".join(r)}='","@staticmethod
    def answer(args):
        lcs = LCS._answer(args)
        return f'{"""".join(lcs)};{len(lcs)}<STOP>'","(74, 4)","(94, 23)",N,function_definition,"def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Equal, (l[-1], r[-1]))]
        if l[-1] == r[-1]:
            thoughts.append(T(LCS, (l[:-1], r[:-1])))
            return thoughts

        lcs1_args = (l[:-1], r)
        lcs2_args = (l, r[:-1])
        lcs1 = LCS._answer(lcs1_args)
        lcs2 = LCS._answer(lcs2_args)
        thoughts.extend([
            T(LCS, lcs1_args),
            T(LCS, lcs2_args),
            T(Compare, (len(lcs1), len(lcs2)))
        ])
        return thoughts",,183,8610cfcd-d899-4a59-b75a-a4ee57784122
"@staticmethod
    def answer(args):
        lcs = LCS._answer(args)
        return f'{"""".join(lcs)};{len(lcs)}<STOP>'",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LCS/,LCS,"@staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Equal, (l[-1], r[-1]))]
        if l[-1] == r[-1]:
            thoughts.append(T(LCS, (l[:-1], r[:-1])))
            return thoughts

        lcs1_args = (l[:-1], r)
        lcs2_args = (l, r[:-1])
        lcs1 = LCS._answer(lcs1_args)
        lcs2 = LCS._answer(lcs2_args)
        thoughts.extend([
            T(LCS, lcs1_args),
            T(LCS, lcs2_args),
            T(Compare, (len(lcs1), len(lcs2)))
        ])
        return thoughts","@staticmethod
    @lru_cache(30000)
    def _answer(args):
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return ()
        if l[-1] == r[-1]:
            return LCS._answer((l[:-1], r[:-1])) + (l[-1],)
        else:
            lcs1 = LCS._answer((l[:-1], r))
            lcs2 = LCS._answer((l, r[:-1]))
            return lcs1 if len(lcs1) >= len(lcs2) else lcs2","(96, 4)","(99, 49)",N,function_definition,"def answer(args):
        lcs = LCS._answer(args)
        return f'{"""".join(lcs)};{len(lcs)}<STOP>'",,35,bcc3d4d6-cf11-4a26-a555-72b0dfba709e
"@staticmethod
    @lru_cache(30000)
    def _answer(args):
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return ()
        if l[-1] == r[-1]:
            return LCS._answer((l[:-1], r[:-1])) + (l[-1],)
        else:
            lcs1 = LCS._answer((l[:-1], r))
            lcs2 = LCS._answer((l, r[:-1]))
            return lcs1 if len(lcs1) >= len(lcs2) else lcs2",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LCS/,LCS,"@staticmethod
    def answer(args):
        lcs = LCS._answer(args)
        return f'{"""".join(lcs)};{len(lcs)}<STOP>'",Next sibling does not exist,"(101, 4)","(112, 59)",N,function_definition,"def _answer(args):
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return ()
        if l[-1] == r[-1]:
            return LCS._answer((l[:-1], r[:-1])) + (l[-1],)
        else:
            lcs1 = LCS._answer((l[:-1], r))
            lcs2 = LCS._answer((l, r[:-1]))
            return lcs1 if len(lcs1) >= len(lcs2) else lcs2",,130,46e3022f-a2ef-47a1-a536-6c0cbe7bff47
"class LPS(Problem):
    """"""Longest Palindromic Subsequence""""""

    name = 'LPS'
    dependencies = {
        Add: lambda config: config,
        Equal: lambda config: config,
        Compare: lambda config: config,
    }
    symbols = ['<LPS>', ';']

    def generate(self):
        return tuple(random.choices('0123456789', k=self.config['digits']))

    @staticmethod
    def question(args):
        return f'<GO><LPS>{"""".join(args)}='

    @staticmethod
    def thought(args) -> list[T]:
        # Base cases
        if len(args) == 1:
            return []
        elif len(args) == 2:
            return [T(Equal, args)]

        thoughts = [T(Equal, (args[0], args[-1]))]
        if args[0] == args[-1]:
            sub_lps = LPS._answer(args[1:-1])
            thoughts.extend([
                T(LPS, args[1:-1]),
                T(Add, (len(sub_lps), 2))
            ])
        else:
            lps1_args = args[:-1]
            lps2_args = args[1:]
            lps1 = LPS._answer(lps1_args)
            lps2 = LPS._answer(lps2_args)
            thoughts.extend([
                T(LPS, lps1_args),
                T(LPS, lps2_args),
                T(Compare, (len(lps1), len(lps2)))
            ])
        return thoughts

    @staticmethod
    def answer(args):
        lps = LPS._answer(args)
        return f'{"""".join(lps)};{len(lps)}<STOP>'

    @staticmethod
    @lru_cache(30000)
    def _answer(args):
        # Base cases
        if len(args) == 1:
            return args
        elif len(args) == 2:
            if args[0] == args[1]:
                return args
            else:
                return args[:1]

        if args[0] == args[-1]:
            return args[:1] + LPS._answer(args[1:-1]) + args[-1:]

        lps1 = LPS._answer(args[:-1])
        lps2 = LPS._answer(args[1:])
        if len(lps1) >= len(lps2):
            return lps1
        else:
            return lps2",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/,module,"class LCS(Problem):
    """"""Length of the Longest Common Subsequence""""""
    name = 'LCS'
    dependencies = {
        Equal: lambda config: {},
        Maximum: lambda config: {'max_digits': len(str(config['digits']))},
    }
    symbols = ['<LCS>', ';']

    def generate(self):
        l = tuple(random.choices('0123456789', k=self.config['digits']))
        r = tuple(random.choices('0123456789', k=self.config['digits']))
        return l, r

    @staticmethod
    def question(args):
        l, r = args
        return f'<GO>{"""".join(l)}<LCS>{"""".join(r)}='

    @staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Equal, (l[-1], r[-1]))]
        if l[-1] == r[-1]:
            thoughts.append(T(LCS, (l[:-1], r[:-1])))
            return thoughts

        lcs1_args = (l[:-1], r)
        lcs2_args = (l, r[:-1])
        lcs1 = LCS._answer(lcs1_args)
        lcs2 = LCS._answer(lcs2_args)
        thoughts.extend([
            T(LCS, lcs1_args),
            T(LCS, lcs2_args),
            T(Compare, (len(lcs1), len(lcs2)))
        ])
        return thoughts

    @staticmethod
    def answer(args):
        lcs = LCS._answer(args)
        return f'{"""".join(lcs)};{len(lcs)}<STOP>'

    @staticmethod
    @lru_cache(30000)
    def _answer(args):
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return ()
        if l[-1] == r[-1]:
            return LCS._answer((l[:-1], r[:-1])) + (l[-1],)
        else:
            lcs1 = LCS._answer((l[:-1], r))
            lcs2 = LCS._answer((l, r[:-1]))
            return lcs1 if len(lcs1) >= len(lcs2) else lcs2","""""""Longest Palindromic Subsequence""""""
name = 'LPS'
dependencies = {
        Add: lambda config: config,
        Equal: lambda config: config,
        Compare: lambda config: config,
    }
symbols = ['<LPS>', ';']","(115, 0)","(185, 23)",N,class_definition,LPS,,522,90116cdf-1618-45fb-9e4e-20ff8017a985
"""""""Longest Palindromic Subsequence""""""
name = 'LPS'
dependencies = {
        Add: lambda config: config,
        Equal: lambda config: config,
        Compare: lambda config: config,
    }
symbols = ['<LPS>', ';']",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LPS/,LPS,Previous sibling does not exist,"def generate(self):
        return tuple(random.choices('0123456789', k=self.config['digits']))","(116, 4)","(124, 28)",N,"expression_statement,expression_statement,expression_statement,expression_statement",expression_statement,,54,3565f3dd-11f5-4d20-b615-1fa9733e6c63
"def generate(self):
        return tuple(random.choices('0123456789', k=self.config['digits']))",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LPS/,LPS,"""""""Longest Palindromic Subsequence""""""
name = 'LPS'
dependencies = {
        Add: lambda config: config,
        Equal: lambda config: config,
        Compare: lambda config: config,
    }
symbols = ['<LPS>', ';']","@staticmethod
    def question(args):
        return f'<GO><LPS>{"""".join(args)}='","(126, 4)","(127, 75)",N,function_definition,generate,,21,39efbf7c-f5e5-4a02-8d58-9ecbc4bf894e
"@staticmethod
    def question(args):
        return f'<GO><LPS>{"""".join(args)}='",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LPS/,LPS,"def generate(self):
        return tuple(random.choices('0123456789', k=self.config['digits']))","@staticmethod
    def thought(args) -> list[T]:
        # Base cases
        if len(args) == 1:
            return []
        elif len(args) == 2:
            return [T(Equal, args)]

        thoughts = [T(Equal, (args[0], args[-1]))]
        if args[0] == args[-1]:
            sub_lps = LPS._answer(args[1:-1])
            thoughts.extend([
                T(LPS, args[1:-1]),
                T(Add, (len(sub_lps), 2))
            ])
        else:
            lps1_args = args[:-1]
            lps2_args = args[1:]
            lps1 = LPS._answer(lps1_args)
            lps2 = LPS._answer(lps2_args)
            thoughts.extend([
                T(LPS, lps1_args),
                T(LPS, lps2_args),
                T(Compare, (len(lps1), len(lps2)))
            ])
        return thoughts","(129, 4)","(131, 43)",N,function_definition,"def question(args):
        return f'<GO><LPS>{"""".join(args)}='",,22,039dafbf-e6da-4627-a6f4-39421724e2f6
"@staticmethod
    def thought(args) -> list[T]:
        # Base cases
        if len(args) == 1:
            return []
        elif len(args) == 2:
            return [T(Equal, args)]

        thoughts = [T(Equal, (args[0], args[-1]))]
        if args[0] == args[-1]:
            sub_lps = LPS._answer(args[1:-1])
            thoughts.extend([
                T(LPS, args[1:-1]),
                T(Add, (len(sub_lps), 2))
            ])
        else:
            lps1_args = args[:-1]
            lps2_args = args[1:]
            lps1 = LPS._answer(lps1_args)
            lps2 = LPS._answer(lps2_args)
            thoughts.extend([
                T(LPS, lps1_args),
                T(LPS, lps2_args),
                T(Compare, (len(lps1), len(lps2)))
            ])
        return thoughts",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LPS/,LPS,"@staticmethod
    def question(args):
        return f'<GO><LPS>{"""".join(args)}='","@staticmethod
    def answer(args):
        lps = LPS._answer(args)
        return f'{"""".join(lps)};{len(lps)}<STOP>'","(133, 4)","(158, 23)",N,function_definition,"def thought(args) -> list[T]:
        # Base cases
        if len(args) == 1:
            return []
        elif len(args) == 2:
            return [T(Equal, args)]

        thoughts = [T(Equal, (args[0], args[-1]))]
        if args[0] == args[-1]:
            sub_lps = LPS._answer(args[1:-1])
            thoughts.extend([
                T(LPS, args[1:-1]),
                T(Add, (len(sub_lps), 2))
            ])
        else:
            lps1_args = args[:-1]
            lps2_args = args[1:]
            lps1 = LPS._answer(lps1_args)
            lps2 = LPS._answer(lps2_args)
            thoughts.extend([
                T(LPS, lps1_args),
                T(LPS, lps2_args),
                T(Compare, (len(lps1), len(lps2)))
            ])
        return thoughts",,216,8df05ac9-abc6-435c-b5dd-b20a01665cdb
"@staticmethod
    def answer(args):
        lps = LPS._answer(args)
        return f'{"""".join(lps)};{len(lps)}<STOP>'",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LPS/,LPS,"@staticmethod
    def thought(args) -> list[T]:
        # Base cases
        if len(args) == 1:
            return []
        elif len(args) == 2:
            return [T(Equal, args)]

        thoughts = [T(Equal, (args[0], args[-1]))]
        if args[0] == args[-1]:
            sub_lps = LPS._answer(args[1:-1])
            thoughts.extend([
                T(LPS, args[1:-1]),
                T(Add, (len(sub_lps), 2))
            ])
        else:
            lps1_args = args[:-1]
            lps2_args = args[1:]
            lps1 = LPS._answer(lps1_args)
            lps2 = LPS._answer(lps2_args)
            thoughts.extend([
                T(LPS, lps1_args),
                T(LPS, lps2_args),
                T(Compare, (len(lps1), len(lps2)))
            ])
        return thoughts","@staticmethod
    @lru_cache(30000)
    def _answer(args):
        # Base cases
        if len(args) == 1:
            return args
        elif len(args) == 2:
            if args[0] == args[1]:
                return args
            else:
                return args[:1]

        if args[0] == args[-1]:
            return args[:1] + LPS._answer(args[1:-1]) + args[-1:]

        lps1 = LPS._answer(args[:-1])
        lps2 = LPS._answer(args[1:])
        if len(lps1) >= len(lps2):
            return lps1
        else:
            return lps2","(160, 4)","(163, 49)",N,function_definition,"def answer(args):
        lps = LPS._answer(args)
        return f'{"""".join(lps)};{len(lps)}<STOP>'",,36,50a664b7-f4b9-4417-971a-a9a9f6bf81e0
"@staticmethod
    @lru_cache(30000)
    def _answer(args):
        # Base cases
        if len(args) == 1:
            return args
        elif len(args) == 2:
            if args[0] == args[1]:
                return args
            else:
                return args[:1]

        if args[0] == args[-1]:
            return args[:1] + LPS._answer(args[1:-1]) + args[-1:]

        lps1 = LPS._answer(args[:-1])
        lps2 = LPS._answer(args[1:])
        if len(lps1) >= len(lps2):
            return lps1
        else:
            return lps2",sequence.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sequence.py,module/class_definition-LPS/,LPS,"@staticmethod
    def answer(args):
        lps = LPS._answer(args)
        return f'{"""".join(lps)};{len(lps)}<STOP>'",Next sibling does not exist,"(165, 4)","(185, 23)",N,function_definition,"def _answer(args):
        # Base cases
        if len(args) == 1:
            return args
        elif len(args) == 2:
            if args[0] == args[1]:
                return args
            else:
                return args[:1]

        if args[0] == args[-1]:
            return args[:1] + LPS._answer(args[1:-1]) + args[-1:]

        lps1 = LPS._answer(args[:-1])
        lps2 = LPS._answer(args[1:])
        if len(lps1) >= len(lps2):
            return lps1
        else:
            return lps2",,155,85542f32-0570-4f24-9f2a-b0e20921a03c
"import random
from abc import ABC

from .arithmetic import Compare
from .problem import Problem, T


class Sort(Problem, ABC):
    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )

    @staticmethod
    def answer(args):
        return f'{"","".join([str(arg) for arg in sorted(args)])}<STOP>'


class Min(Problem):
    name = 'Min'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<MIN>', ',']

    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )

    @staticmethod
    def question(args):
        return f'<GO><MIN>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'Min requires at least 2 arguments, but got {len(args)}.')
        if len(args) == 2:
            return [T(Compare, args)]

        return [
            T(Compare, args[:2]),
            T(Min, (min(args[:2]),) + args[2:], 'tail')
        ]

    @staticmethod
    def answer(args):
        return f'{min(args)}<STOP>'


class SelectionSort(Sort):
    name = 'SelectionSort'
    dependencies = {
        Min: lambda config: config
    }
    symbols = ['<SELECTION_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><SELECTION_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'SelectionSort requires at least 2 arguments, '
                f'but got {len(args)}.')

        if len(args) == 2:
            return [T(Min, args)]

        min_idx = args.index(min(args))
        args_list = list(args)
        args_list[min_idx] = args_list[0]
        sub_args = tuple(args_list[1:])
        return [
            T(Min, args),
            T(SelectionSort, sub_args)
        ]


class Merge(Problem):
    name = 'Merge'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits']}
    }
    symbols = ['<MERGE>', ',', '<SEP>']

    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        l_len = (terms + 1) // 2
        l = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(l_len)
        ]))
        r = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms - l_len)
        ]))
        return l, r

    @staticmethod
    def question(args):
        l, r = args
        return f'<GO><MERGE>{"","".join([str(x) for x in l])}' \
               f'<SEP>{"","".join([str(x) for x in r])}='

    @staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Compare, (l[0], r[0]))]
        if l[0] < r[0] and len(l) > 1:
            thoughts.append(T(Merge, (l[1:], r)))
        elif l[0] >= r[0] and len(r) > 1:
            thoughts.append(T(Merge, (l, r[1:])))
        return thoughts

    @staticmethod
    def answer(args):
        l, r = args
        l_i, r_i = 0, 0
        result = []
        while l_i < len(l) and r_i < len(r):
            if l[l_i] < r[r_i]:
                result.append(l[l_i])
                l_i += 1
            else:
                result.append(r[r_i])
                r_i += 1
        if l_i < len(l):
            result.extend(l[l_i:])
        else:
            result.extend(r[r_i:])
        return f'{"","".join([str(x) for x in result])}<STOP>'


class MergeSort(Sort):
    name = 'MergeSort'
    dependencies = {
        Merge: lambda config: config
    }
    symbols = ['<MERGE_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><MERGE_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        l_len = (len(args) + 1) // 2
        l = args[:l_len]
        r = args[l_len:]
        return [
            T(MergeSort, l),
            T(MergeSort, r),
            T(Merge, (tuple(sorted(l)), tuple(sorted(r))), 'tail')
        ]


class Bubble(Problem):
    name = 'Bubble'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<BUBBLE>', ',']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<BUBBLE>{"","".join(str(x) for x in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        thoughts = [(Compare, args[:2])]
        if len(args) > 2:
            thoughts.append(T(Bubble, (max(args[:2]),) + args[2:]))
        return thoughts

    @staticmethod
    def answer(args):
        bubbled = Bubble.bubble(args)
        return f'{"","".join([str(x) for x in bubbled])}<STOP>'

    @staticmethod
    def bubble(args):
        args = list(args)
        for i in range(len(args) - 1):
            if args[i] > args[i + 1]:
                args[i], args[i + 1] = args[i + 1], args[i]
        return tuple(args)


class BubbleSort(Sort):
    name = 'BubbleSort'
    dependencies = {
        Bubble: lambda config: config
    }
    symbols = ['<BUBBLE_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><BUBBLE_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        bubbled = Bubble.bubble(args)
        return [
            T(Bubble, args),
            T(BubbleSort, bubbled[:-1])
        ]
",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,,NA,Previous sibling does not exist,"import random
from abc import ABC
from .arithmetic import Compare
from .problem import Problem, T","(0, 0)","(233, 0)",N,module,module,,1602,0f3da8d0-2202-427d-83e9-4a6783226f7d
"import random
from abc import ABC
from .arithmetic import Compare
from .problem import Problem, T",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/,module,Previous sibling does not exist,"class Sort(Problem, ABC):
    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )

    @staticmethod
    def answer(args):
        return f'{"","".join([str(arg) for arg in sorted(args)])}<STOP>'","(0, 0)","(4, 31)",N,"import_statement,import_from_statement,import_from_statement,import_from_statement",import_statement,,19,ab17e15f-1748-4d60-bded-3869ddf7b4a7
"class Sort(Problem, ABC):
    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )

    @staticmethod
    def answer(args):
        return f'{"","".join([str(arg) for arg in sorted(args)])}<STOP>'",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/,module,"import random
from abc import ABC
from .arithmetic import Compare
from .problem import Problem, T","class Min(Problem):
    name = 'Min'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<MIN>', ',']

    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )

    @staticmethod
    def question(args):
        return f'<GO><MIN>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'Min requires at least 2 arguments, but got {len(args)}.')
        if len(args) == 2:
            return [T(Compare, args)]

        return [
            T(Compare, args[:2]),
            T(Min, (min(args[:2]),) + args[2:], 'tail')
        ]

    @staticmethod
    def answer(args):
        return f'{min(args)}<STOP>'","(7, 0)","(18, 70)",N,class_definition,Sort,,101,896547aa-0cbd-4b36-b293-6c517f141a20
"def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Sort/,Sort,Previous sibling does not exist,"@staticmethod
    def answer(args):
        return f'{"","".join([str(arg) for arg in sorted(args)])}<STOP>'","(8, 4)","(14, 9)",N,function_definition,generate,,64,ae015871-075f-44b3-acf4-db2263e78fa9
"@staticmethod
    def answer(args):
        return f'{"","".join([str(arg) for arg in sorted(args)])}<STOP>'",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Sort/,Sort,"def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )",Next sibling does not exist,"(16, 4)","(18, 70)",N,function_definition,"def answer(args):
        return f'{"","".join([str(arg) for arg in sorted(args)])}<STOP>'",,28,34fe4152-4dd9-45ff-bc91-05c51f84ef43
"class Min(Problem):
    name = 'Min'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<MIN>', ',']

    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )

    @staticmethod
    def question(args):
        return f'<GO><MIN>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'Min requires at least 2 arguments, but got {len(args)}.')
        if len(args) == 2:
            return [T(Compare, args)]

        return [
            T(Compare, args[:2]),
            T(Min, (min(args[:2]),) + args[2:], 'tail')
        ]

    @staticmethod
    def answer(args):
        return f'{min(args)}<STOP>'",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/,module,"class Sort(Problem, ABC):
    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )

    @staticmethod
    def answer(args):
        return f'{"","".join([str(arg) for arg in sorted(args)])}<STOP>'","class SelectionSort(Sort):
    name = 'SelectionSort'
    dependencies = {
        Min: lambda config: config
    }
    symbols = ['<SELECTION_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><SELECTION_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'SelectionSort requires at least 2 arguments, '
                f'but got {len(args)}.')

        if len(args) == 2:
            return [T(Min, args)]

        min_idx = args.index(min(args))
        args_list = list(args)
        args_list[min_idx] = args_list[0]
        sub_args = tuple(args_list[1:])
        return [
            T(Min, args),
            T(SelectionSort, sub_args)
        ]","(21, 0)","(55, 35)",N,class_definition,Min,,246,d8a09d5b-b87f-4d17-9085-54b5c6131262
"def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Min/,Min,"symbols = ['<MIN>', ',']","@staticmethod
    def question(args):
        return f'<GO><MIN>{"","".join([str(arg) for arg in args])}='","(28, 4)","(34, 9)",N,function_definition,generate,,64,0233180d-cdf4-4e38-854a-86252a97f184
"@staticmethod
    def question(args):
        return f'<GO><MIN>{"","".join([str(arg) for arg in args])}='",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Min/,Min,"def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )","@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'Min requires at least 2 arguments, but got {len(args)}.')
        if len(args) == 2:
            return [T(Compare, args)]

        return [
            T(Compare, args[:2]),
            T(Min, (min(args[:2]),) + args[2:], 'tail')
        ]","(36, 4)","(38, 66)",N,function_definition,"def question(args):
        return f'<GO><MIN>{"","".join([str(arg) for arg in args])}='",,30,e1507f52-8513-45c2-ad3e-c52a5c9ce35f
"@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'Min requires at least 2 arguments, but got {len(args)}.')
        if len(args) == 2:
            return [T(Compare, args)]

        return [
            T(Compare, args[:2]),
            T(Min, (min(args[:2]),) + args[2:], 'tail')
        ]",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Min/,Min,"@staticmethod
    def question(args):
        return f'<GO><MIN>{"","".join([str(arg) for arg in args])}='","@staticmethod
    def answer(args):
        return f'{min(args)}<STOP>'","(40, 4)","(51, 9)",N,function_definition,"def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'Min requires at least 2 arguments, but got {len(args)}.')
        if len(args) == 2:
            return [T(Compare, args)]

        return [
            T(Compare, args[:2]),
            T(Min, (min(args[:2]),) + args[2:], 'tail')
        ]",,95,5e329e39-476e-4f1f-98e4-36e0163d9498
"@staticmethod
    def answer(args):
        return f'{min(args)}<STOP>'",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Min/,Min,"@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'Min requires at least 2 arguments, but got {len(args)}.')
        if len(args) == 2:
            return [T(Compare, args)]

        return [
            T(Compare, args[:2]),
            T(Min, (min(args[:2]),) + args[2:], 'tail')
        ]",Next sibling does not exist,"(53, 4)","(55, 35)",N,function_definition,"def answer(args):
        return f'{min(args)}<STOP>'",,18,c3659701-ea01-4ced-83fd-37c5d292f5a5
"class SelectionSort(Sort):
    name = 'SelectionSort'
    dependencies = {
        Min: lambda config: config
    }
    symbols = ['<SELECTION_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><SELECTION_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'SelectionSort requires at least 2 arguments, '
                f'but got {len(args)}.')

        if len(args) == 2:
            return [T(Min, args)]

        min_idx = args.index(min(args))
        args_list = list(args)
        args_list[min_idx] = args_list[0]
        sub_args = tuple(args_list[1:])
        return [
            T(Min, args),
            T(SelectionSort, sub_args)
        ]",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/,module,"class Min(Problem):
    name = 'Min'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<MIN>', ',']

    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        return tuple(
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms)
        )

    @staticmethod
    def question(args):
        return f'<GO><MIN>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'Min requires at least 2 arguments, but got {len(args)}.')
        if len(args) == 2:
            return [T(Compare, args)]

        return [
            T(Compare, args[:2]),
            T(Min, (min(args[:2]),) + args[2:], 'tail')
        ]

    @staticmethod
    def answer(args):
        return f'{min(args)}<STOP>'","class Merge(Problem):
    name = 'Merge'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits']}
    }
    symbols = ['<MERGE>', ',', '<SEP>']

    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        l_len = (terms + 1) // 2
        l = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(l_len)
        ]))
        r = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms - l_len)
        ]))
        return l, r

    @staticmethod
    def question(args):
        l, r = args
        return f'<GO><MERGE>{"","".join([str(x) for x in l])}' \
               f'<SEP>{"","".join([str(x) for x in r])}='

    @staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Compare, (l[0], r[0]))]
        if l[0] < r[0] and len(l) > 1:
            thoughts.append(T(Merge, (l[1:], r)))
        elif l[0] >= r[0] and len(r) > 1:
            thoughts.append(T(Merge, (l, r[1:])))
        return thoughts

    @staticmethod
    def answer(args):
        l, r = args
        l_i, r_i = 0, 0
        result = []
        while l_i < len(l) and r_i < len(r):
            if l[l_i] < r[r_i]:
                result.append(l[l_i])
                l_i += 1
            else:
                result.append(r[r_i])
                r_i += 1
        if l_i < len(l):
            result.extend(l[l_i:])
        else:
            result.extend(r[r_i:])
        return f'{"","".join([str(x) for x in result])}<STOP>'","(58, 0)","(86, 9)",N,class_definition,SelectionSort,,198,d0448b99-c6e6-4146-bb14-77bb206be2c0
"@staticmethod
    def question(args):
        return f'<GO><SELECTION_SORT>{"","".join([str(arg) for arg in args])}='",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-SelectionSort/,SelectionSort,"symbols = ['<SELECTION_SORT>', ',']","@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'SelectionSort requires at least 2 arguments, '
                f'but got {len(args)}.')

        if len(args) == 2:
            return [T(Min, args)]

        min_idx = args.index(min(args))
        args_list = list(args)
        args_list[min_idx] = args_list[0]
        sub_args = tuple(args_list[1:])
        return [
            T(Min, args),
            T(SelectionSort, sub_args)
        ]","(65, 4)","(67, 77)",N,function_definition,"def question(args):
        return f'<GO><SELECTION_SORT>{"","".join([str(arg) for arg in args])}='",,32,fe1818e5-ccf5-4eb9-a5e7-5c6de252985c
"@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'SelectionSort requires at least 2 arguments, '
                f'but got {len(args)}.')

        if len(args) == 2:
            return [T(Min, args)]

        min_idx = args.index(min(args))
        args_list = list(args)
        args_list[min_idx] = args_list[0]
        sub_args = tuple(args_list[1:])
        return [
            T(Min, args),
            T(SelectionSort, sub_args)
        ]",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-SelectionSort/,SelectionSort,"@staticmethod
    def question(args):
        return f'<GO><SELECTION_SORT>{"","".join([str(arg) for arg in args])}='",Next sibling does not exist,"(69, 4)","(86, 9)",N,function_definition,"def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'SelectionSort requires at least 2 arguments, '
                f'but got {len(args)}.')

        if len(args) == 2:
            return [T(Min, args)]

        min_idx = args.index(min(args))
        args_list = list(args)
        args_list[min_idx] = args_list[0]
        sub_args = tuple(args_list[1:])
        return [
            T(Min, args),
            T(SelectionSort, sub_args)
        ]",,125,f4e68c4a-0e63-44da-80c3-e59e21fe290f
"class Merge(Problem):
    name = 'Merge'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits']}
    }
    symbols = ['<MERGE>', ',', '<SEP>']

    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        l_len = (terms + 1) // 2
        l = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(l_len)
        ]))
        r = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms - l_len)
        ]))
        return l, r

    @staticmethod
    def question(args):
        l, r = args
        return f'<GO><MERGE>{"","".join([str(x) for x in l])}' \
               f'<SEP>{"","".join([str(x) for x in r])}='

    @staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Compare, (l[0], r[0]))]
        if l[0] < r[0] and len(l) > 1:
            thoughts.append(T(Merge, (l[1:], r)))
        elif l[0] >= r[0] and len(r) > 1:
            thoughts.append(T(Merge, (l, r[1:])))
        return thoughts

    @staticmethod
    def answer(args):
        l, r = args
        l_i, r_i = 0, 0
        result = []
        while l_i < len(l) and r_i < len(r):
            if l[l_i] < r[r_i]:
                result.append(l[l_i])
                l_i += 1
            else:
                result.append(r[r_i])
                r_i += 1
        if l_i < len(l):
            result.extend(l[l_i:])
        else:
            result.extend(r[r_i:])
        return f'{"","".join([str(x) for x in result])}<STOP>'",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/,module,"class SelectionSort(Sort):
    name = 'SelectionSort'
    dependencies = {
        Min: lambda config: config
    }
    symbols = ['<SELECTION_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><SELECTION_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            raise ValueError(
                f'SelectionSort requires at least 2 arguments, '
                f'but got {len(args)}.')

        if len(args) == 2:
            return [T(Min, args)]

        min_idx = args.index(min(args))
        args_list = list(args)
        args_list[min_idx] = args_list[0]
        sub_args = tuple(args_list[1:])
        return [
            T(Min, args),
            T(SelectionSort, sub_args)
        ]","class MergeSort(Sort):
    name = 'MergeSort'
    dependencies = {
        Merge: lambda config: config
    }
    symbols = ['<MERGE_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><MERGE_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        l_len = (len(args) + 1) // 2
        l = args[:l_len]
        r = args[l_len:]
        return [
            T(MergeSort, l),
            T(MergeSort, r),
            T(Merge, (tuple(sorted(l)), tuple(sorted(r))), 'tail')
        ]","(89, 0)","(145, 60)",N,class_definition,Merge,,489,bb93297c-5c65-4923-ba80-4c216e98bd5d
"def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        l_len = (terms + 1) // 2
        l = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(l_len)
        ]))
        r = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms - l_len)
        ]))
        return l, r",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Merge/,Merge,"symbols = ['<MERGE>', ',', '<SEP>']","@staticmethod
    def question(args):
        l, r = args
        return f'<GO><MERGE>{"","".join([str(x) for x in l])}' \
               f'<SEP>{"","".join([str(x) for x in r])}='","(96, 4)","(108, 19)",N,function_definition,generate,,121,0ae81167-098c-47a5-a22b-d9584565dae0
"@staticmethod
    def question(args):
        l, r = args
        return f'<GO><MERGE>{"","".join([str(x) for x in l])}' \
               f'<SEP>{"","".join([str(x) for x in r])}='",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Merge/,Merge,"def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        l_len = (terms + 1) // 2
        l = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(l_len)
        ]))
        r = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms - l_len)
        ]))
        return l, r","@staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Compare, (l[0], r[0]))]
        if l[0] < r[0] and len(l) > 1:
            thoughts.append(T(Merge, (l[1:], r)))
        elif l[0] >= r[0] and len(r) > 1:
            thoughts.append(T(Merge, (l, r[1:])))
        return thoughts","(110, 4)","(114, 55)",N,function_definition,"def question(args):
        l, r = args
        return f'<GO><MERGE>{"","".join([str(x) for x in l])}' \
               f'<SEP>{"","".join([str(x) for x in r])}='",,57,e8a57afe-2b50-41ef-9ded-2771008c156b
"@staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Compare, (l[0], r[0]))]
        if l[0] < r[0] and len(l) > 1:
            thoughts.append(T(Merge, (l[1:], r)))
        elif l[0] >= r[0] and len(r) > 1:
            thoughts.append(T(Merge, (l, r[1:])))
        return thoughts",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Merge/,Merge,"@staticmethod
    def question(args):
        l, r = args
        return f'<GO><MERGE>{"","".join([str(x) for x in l])}' \
               f'<SEP>{"","".join([str(x) for x in r])}='","@staticmethod
    def answer(args):
        l, r = args
        l_i, r_i = 0, 0
        result = []
        while l_i < len(l) and r_i < len(r):
            if l[l_i] < r[r_i]:
                result.append(l[l_i])
                l_i += 1
            else:
                result.append(r[r_i])
                r_i += 1
        if l_i < len(l):
            result.extend(l[l_i:])
        else:
            result.extend(r[r_i:])
        return f'{"","".join([str(x) for x in result])}<STOP>'","(116, 4)","(127, 23)",N,function_definition,"def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Compare, (l[0], r[0]))]
        if l[0] < r[0] and len(l) > 1:
            thoughts.append(T(Merge, (l[1:], r)))
        elif l[0] >= r[0] and len(r) > 1:
            thoughts.append(T(Merge, (l, r[1:])))
        return thoughts",,126,1210f565-e288-4110-8d12-53f1ea53444a
"@staticmethod
    def answer(args):
        l, r = args
        l_i, r_i = 0, 0
        result = []
        while l_i < len(l) and r_i < len(r):
            if l[l_i] < r[r_i]:
                result.append(l[l_i])
                l_i += 1
            else:
                result.append(r[r_i])
                r_i += 1
        if l_i < len(l):
            result.extend(l[l_i:])
        else:
            result.extend(r[r_i:])
        return f'{"","".join([str(x) for x in result])}<STOP>'",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Merge/,Merge,"@staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Compare, (l[0], r[0]))]
        if l[0] < r[0] and len(l) > 1:
            thoughts.append(T(Merge, (l[1:], r)))
        elif l[0] >= r[0] and len(r) > 1:
            thoughts.append(T(Merge, (l, r[1:])))
        return thoughts",Next sibling does not exist,"(129, 4)","(145, 60)",N,function_definition,"def answer(args):
        l, r = args
        l_i, r_i = 0, 0
        result = []
        while l_i < len(l) and r_i < len(r):
            if l[l_i] < r[r_i]:
                result.append(l[l_i])
                l_i += 1
            else:
                result.append(r[r_i])
                r_i += 1
        if l_i < len(l):
            result.extend(l[l_i:])
        else:
            result.extend(r[r_i:])
        return f'{"","".join([str(x) for x in result])}<STOP>'",,133,af720973-03a7-4b0a-ba3b-8b6238c01820
"class MergeSort(Sort):
    name = 'MergeSort'
    dependencies = {
        Merge: lambda config: config
    }
    symbols = ['<MERGE_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><MERGE_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        l_len = (len(args) + 1) // 2
        l = args[:l_len]
        r = args[l_len:]
        return [
            T(MergeSort, l),
            T(MergeSort, r),
            T(Merge, (tuple(sorted(l)), tuple(sorted(r))), 'tail')
        ]",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/,module,"class Merge(Problem):
    name = 'Merge'
    dependencies = {
        Compare: lambda config: {'max_digits': config['max_digits']}
    }
    symbols = ['<MERGE>', ',', '<SEP>']

    def generate(self):
        terms = random.randrange(2, self.config['max_terms'] + 1)
        max_num = 10 ** self.config['max_digits']
        l_len = (terms + 1) // 2
        l = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(l_len)
        ]))
        r = tuple(sorted([
            self.log_randrange(0, max_num, offset=5)
            for _ in range(terms - l_len)
        ]))
        return l, r

    @staticmethod
    def question(args):
        l, r = args
        return f'<GO><MERGE>{"","".join([str(x) for x in l])}' \
               f'<SEP>{"","".join([str(x) for x in r])}='

    @staticmethod
    def thought(args) -> list[T]:
        l, r = args
        if len(l) == 0 or len(r) == 0:
            return []

        thoughts = [T(Compare, (l[0], r[0]))]
        if l[0] < r[0] and len(l) > 1:
            thoughts.append(T(Merge, (l[1:], r)))
        elif l[0] >= r[0] and len(r) > 1:
            thoughts.append(T(Merge, (l, r[1:])))
        return thoughts

    @staticmethod
    def answer(args):
        l, r = args
        l_i, r_i = 0, 0
        result = []
        while l_i < len(l) and r_i < len(r):
            if l[l_i] < r[r_i]:
                result.append(l[l_i])
                l_i += 1
            else:
                result.append(r[r_i])
                r_i += 1
        if l_i < len(l):
            result.extend(l[l_i:])
        else:
            result.extend(r[r_i:])
        return f'{"","".join([str(x) for x in result])}<STOP>'","class Bubble(Problem):
    name = 'Bubble'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<BUBBLE>', ',']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<BUBBLE>{"","".join(str(x) for x in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        thoughts = [(Compare, args[:2])]
        if len(args) > 2:
            thoughts.append(T(Bubble, (max(args[:2]),) + args[2:]))
        return thoughts

    @staticmethod
    def answer(args):
        bubbled = Bubble.bubble(args)
        return f'{"","".join([str(x) for x in bubbled])}<STOP>'

    @staticmethod
    def bubble(args):
        args = list(args)
        for i in range(len(args) - 1):
            if args[i] > args[i + 1]:
                args[i], args[i + 1] = args[i + 1], args[i]
        return tuple(args)","(148, 0)","(171, 9)",N,class_definition,MergeSort,,166,6479117c-8243-4766-b61d-75fe1f5b05b4
"@staticmethod
    def question(args):
        return f'<GO><MERGE_SORT>{"","".join([str(arg) for arg in args])}='",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-MergeSort/,MergeSort,"symbols = ['<MERGE_SORT>', ',']","@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        l_len = (len(args) + 1) // 2
        l = args[:l_len]
        r = args[l_len:]
        return [
            T(MergeSort, l),
            T(MergeSort, r),
            T(Merge, (tuple(sorted(l)), tuple(sorted(r))), 'tail')
        ]","(155, 4)","(157, 73)",N,function_definition,"def question(args):
        return f'<GO><MERGE_SORT>{"","".join([str(arg) for arg in args])}='",,32,3746db10-5008-4369-b6f7-61c32783948a
"@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        l_len = (len(args) + 1) // 2
        l = args[:l_len]
        r = args[l_len:]
        return [
            T(MergeSort, l),
            T(MergeSort, r),
            T(Merge, (tuple(sorted(l)), tuple(sorted(r))), 'tail')
        ]",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-MergeSort/,MergeSort,"@staticmethod
    def question(args):
        return f'<GO><MERGE_SORT>{"","".join([str(arg) for arg in args])}='",Next sibling does not exist,"(159, 4)","(171, 9)",N,function_definition,"def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        l_len = (len(args) + 1) // 2
        l = args[:l_len]
        r = args[l_len:]
        return [
            T(MergeSort, l),
            T(MergeSort, r),
            T(Merge, (tuple(sorted(l)), tuple(sorted(r))), 'tail')
        ]",,93,57eb8ba8-1d73-40ed-996f-24da3c57225a
"class Bubble(Problem):
    name = 'Bubble'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<BUBBLE>', ',']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<BUBBLE>{"","".join(str(x) for x in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        thoughts = [(Compare, args[:2])]
        if len(args) > 2:
            thoughts.append(T(Bubble, (max(args[:2]),) + args[2:]))
        return thoughts

    @staticmethod
    def answer(args):
        bubbled = Bubble.bubble(args)
        return f'{"","".join([str(x) for x in bubbled])}<STOP>'

    @staticmethod
    def bubble(args):
        args = list(args)
        for i in range(len(args) - 1):
            if args[i] > args[i + 1]:
                args[i], args[i + 1] = args[i + 1], args[i]
        return tuple(args)",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/,module,"class MergeSort(Sort):
    name = 'MergeSort'
    dependencies = {
        Merge: lambda config: config
    }
    symbols = ['<MERGE_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><MERGE_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        l_len = (len(args) + 1) // 2
        l = args[:l_len]
        r = args[l_len:]
        return [
            T(MergeSort, l),
            T(MergeSort, r),
            T(Merge, (tuple(sorted(l)), tuple(sorted(r))), 'tail')
        ]","class BubbleSort(Sort):
    name = 'BubbleSort'
    dependencies = {
        Bubble: lambda config: config
    }
    symbols = ['<BUBBLE_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><BUBBLE_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        bubbled = Bubble.bubble(args)
        return [
            T(Bubble, args),
            T(BubbleSort, bubbled[:-1])
        ]","(174, 0)","(209, 26)",N,class_definition,Bubble,,245,1dae1119-3999-476c-a51c-c84a7afe7a07
"def generate(self):
        pass",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Bubble/,Bubble,"symbols = ['<BUBBLE>', ',']","@staticmethod
    def question(args):
        return f'<BUBBLE>{"","".join(str(x) for x in args)}='","(181, 4)","(182, 12)",N,function_definition,generate,,6,75926cf6-cfbf-4bf0-8cc7-a73c668ac7ac
"@staticmethod
    def question(args):
        return f'<BUBBLE>{"","".join(str(x) for x in args)}='",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Bubble/,Bubble,"def generate(self):
        pass","@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        thoughts = [(Compare, args[:2])]
        if len(args) > 2:
            thoughts.append(T(Bubble, (max(args[:2]),) + args[2:]))
        return thoughts","(184, 4)","(186, 59)",N,function_definition,"def question(args):
        return f'<BUBBLE>{"","".join(str(x) for x in args)}='",,28,24157e35-63cb-4899-a645-16845425649c
"@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        thoughts = [(Compare, args[:2])]
        if len(args) > 2:
            thoughts.append(T(Bubble, (max(args[:2]),) + args[2:]))
        return thoughts",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Bubble/,Bubble,"@staticmethod
    def question(args):
        return f'<BUBBLE>{"","".join(str(x) for x in args)}='","@staticmethod
    def answer(args):
        bubbled = Bubble.bubble(args)
        return f'{"","".join([str(x) for x in bubbled])}<STOP>'","(188, 4)","(196, 23)",N,function_definition,"def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        thoughts = [(Compare, args[:2])]
        if len(args) > 2:
            thoughts.append(T(Bubble, (max(args[:2]),) + args[2:]))
        return thoughts",,66,7eb0968e-a234-453b-b474-28f5d7566fc8
"@staticmethod
    def answer(args):
        bubbled = Bubble.bubble(args)
        return f'{"","".join([str(x) for x in bubbled])}<STOP>'",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Bubble/,Bubble,"@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        thoughts = [(Compare, args[:2])]
        if len(args) > 2:
            thoughts.append(T(Bubble, (max(args[:2]),) + args[2:]))
        return thoughts","@staticmethod
    def bubble(args):
        args = list(args)
        for i in range(len(args) - 1):
            if args[i] > args[i + 1]:
                args[i], args[i + 1] = args[i + 1], args[i]
        return tuple(args)","(198, 4)","(201, 61)",N,function_definition,"def answer(args):
        bubbled = Bubble.bubble(args)
        return f'{"","".join([str(x) for x in bubbled])}<STOP>'",,37,066b1d96-b828-418c-bb8b-6300f8e0e48f
"@staticmethod
    def bubble(args):
        args = list(args)
        for i in range(len(args) - 1):
            if args[i] > args[i + 1]:
                args[i], args[i + 1] = args[i + 1], args[i]
        return tuple(args)",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-Bubble/,Bubble,"@staticmethod
    def answer(args):
        bubbled = Bubble.bubble(args)
        return f'{"","".join([str(x) for x in bubbled])}<STOP>'",Next sibling does not exist,"(203, 4)","(209, 26)",N,function_definition,"def bubble(args):
        args = list(args)
        for i in range(len(args) - 1):
            if args[i] > args[i + 1]:
                args[i], args[i + 1] = args[i + 1], args[i]
        return tuple(args)",,63,548f2ead-e904-4bdd-b245-72128bc379e9
"class BubbleSort(Sort):
    name = 'BubbleSort'
    dependencies = {
        Bubble: lambda config: config
    }
    symbols = ['<BUBBLE_SORT>', ',']

    @staticmethod
    def question(args):
        return f'<GO><BUBBLE_SORT>{"","".join([str(arg) for arg in args])}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        bubbled = Bubble.bubble(args)
        return [
            T(Bubble, args),
            T(BubbleSort, bubbled[:-1])
        ]",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/,module,"class Bubble(Problem):
    name = 'Bubble'
    dependencies = {
        Compare: lambda config: config
    }
    symbols = ['<BUBBLE>', ',']

    def generate(self):
        pass

    @staticmethod
    def question(args):
        return f'<BUBBLE>{"","".join(str(x) for x in args)}='

    @staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        thoughts = [(Compare, args[:2])]
        if len(args) > 2:
            thoughts.append(T(Bubble, (max(args[:2]),) + args[2:]))
        return thoughts

    @staticmethod
    def answer(args):
        bubbled = Bubble.bubble(args)
        return f'{"","".join([str(x) for x in bubbled])}<STOP>'

    @staticmethod
    def bubble(args):
        args = list(args)
        for i in range(len(args) - 1):
            if args[i] > args[i + 1]:
                args[i], args[i + 1] = args[i + 1], args[i]
        return tuple(args)",Next sibling does not exist,"(212, 0)","(232, 9)",N,class_definition,BubbleSort,,131,a930345f-79eb-4806-ba7f-04f41b8dafdc
"@staticmethod
    def question(args):
        return f'<GO><BUBBLE_SORT>{"","".join([str(arg) for arg in args])}='",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-BubbleSort/,BubbleSort,"symbols = ['<BUBBLE_SORT>', ',']","@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        bubbled = Bubble.bubble(args)
        return [
            T(Bubble, args),
            T(BubbleSort, bubbled[:-1])
        ]","(219, 4)","(221, 74)",N,function_definition,"def question(args):
        return f'<GO><BUBBLE_SORT>{"","".join([str(arg) for arg in args])}='",,33,ef6be0fb-1a6d-4459-82b1-9e05ef92f533
"@staticmethod
    def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        bubbled = Bubble.bubble(args)
        return [
            T(Bubble, args),
            T(BubbleSort, bubbled[:-1])
        ]",sort.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\sort.py,module/class_definition-BubbleSort/,BubbleSort,"@staticmethod
    def question(args):
        return f'<GO><BUBBLE_SORT>{"","".join([str(arg) for arg in args])}='",Next sibling does not exist,"(223, 4)","(232, 9)",N,function_definition,"def thought(args) -> list[T]:
        if len(args) < 2:
            return []

        bubbled = Bubble.bubble(args)
        return [
            T(Bubble, args),
            T(BubbleSort, bubbled[:-1])
        ]",,56,6a72fd18-640e-4f14-9e7f-ee83e9c8ac87
"def tokenizer(s: str) -> list[str]:
    state = 'NORM'
    tokens = []
    token = ''
    for c in s:
        if state == 'NORM' and c == '\\':
            state = 'ESCAPE'
        elif state == 'ESCAPE':
            tokens.append(c)
            state = 'NORM'
        elif state == 'SPECIAL':
            if c == '>':
                tokens.append(token + c)
                state = 'NORM'
            else:
                token += c
        elif c == '<':
            state = 'SPECIAL'
            token = c
        else:
            tokens.append(c)
    return tokens


class ST:
    PAD = '<PAD>'
    GO = '<GO>'
    EOS = '<STOP>'
    THINK = '<THINK>'


class Label:
    PAD = 0
    Q = 1
    T = 2
    A = 3
",tokenizer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\tokenizer.py,,NA,Previous sibling does not exist,Next sibling does not exist,"(0, 0)","(36, 0)",N,module,module,,193,fb4840de-2880-461e-8338-34f202cbda82
"def tokenizer(s: str) -> list[str]:
    state = 'NORM'
    tokens = []
    token = ''
    for c in s:
        if state == 'NORM' and c == '\\':
            state = 'ESCAPE'
        elif state == 'ESCAPE':
            tokens.append(c)
            state = 'NORM'
        elif state == 'SPECIAL':
            if c == '>':
                tokens.append(token + c)
                state = 'NORM'
            else:
                token += c
        elif c == '<':
            state = 'SPECIAL'
            token = c
        else:
            tokens.append(c)
    return tokens",tokenizer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\tokenizer.py,module/,module,Previous sibling does not exist,"class ST:
    PAD = '<PAD>'
    GO = '<GO>'
    EOS = '<STOP>'
    THINK = '<THINK>'","(0, 0)","(21, 17)",N,function_definition,tokenizer,,136,c77a1bf8-de1d-4875-9c01-6413f18776e3
"class ST:
    PAD = '<PAD>'
    GO = '<GO>'
    EOS = '<STOP>'
    THINK = '<THINK>'",tokenizer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\tokenizer.py,module/,module,"def tokenizer(s: str) -> list[str]:
    state = 'NORM'
    tokens = []
    token = ''
    for c in s:
        if state == 'NORM' and c == '\\':
            state = 'ESCAPE'
        elif state == 'ESCAPE':
            tokens.append(c)
            state = 'NORM'
        elif state == 'SPECIAL':
            if c == '>':
                tokens.append(token + c)
                state = 'NORM'
            else:
                token += c
        elif c == '<':
            state = 'SPECIAL'
            token = c
        else:
            tokens.append(c)
    return tokens","class Label:
    PAD = 0
    Q = 1
    T = 2
    A = 3","(24, 0)","(28, 21)",N,class_definition,ST,,28,16baae10-1b53-4810-af77-45fd377168b7
"class Label:
    PAD = 0
    Q = 1
    T = 2
    A = 3",tokenizer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\tokenizer.py,module/,module,"class ST:
    PAD = '<PAD>'
    GO = '<GO>'
    EOS = '<STOP>'
    THINK = '<THINK>'",Next sibling does not exist,"(31, 0)","(35, 9)",N,class_definition,Label,,26,58f56a3d-d02e-4775-b215-6d0b5a01f5b4
"from .arithmetic import *
from .equation import *
from .sort import Min, SelectionSort, Merge, MergeSort, BubbleSort
from .sequence import LCS, LPS
from .mcm import MCM
from .knapsack import Knapsack
from .problem import Problem, ProblemSet

PROBLEM = {
    'Compare': Compare,
    'Add': Add,
    'Sub': Sub,
    'Sub_pos_int': Sub_pos_int,
    'Mul': Mul,
    'Div': Div,
    'Gcd': Gcd,
    'Lcm': Lcm,
    'Reduce': Reduce,
    'Add_frac': Add_frac,
    'Sub_frac': Sub_frac,
    'Mul_frac': Mul_frac,
    'Div_frac': Div_frac,
    # 'Add_neg': Add_neg,
    # 'Sub_neg': Sub_neg,
    # 'Mul_neg': Mul_neg,
    # 'Div_neg': Div_neg,
    'Operations': Operations,
    'Linear_1d': Linear_1d,
    'Linear_2d': Linear_2d,
    'Mul_both': Mul_both,
    'Elim': Elim,
    'Substitute': Substitute,
    # 'Quadratic_1d': Quadratic_1d,
    Min.name: Min,
    SelectionSort.name: SelectionSort,
    Merge.name: Merge,
    MergeSort.name: MergeSort,
    BubbleSort.name: BubbleSort,
    LCS.name: LCS,
    LPS.name: LPS,
    MCM.name: MCM,
    Knapsack.name: Knapsack,
}
",__init__.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\__init__.py,,NA,Previous sibling does not exist,"from .arithmetic import *
from .equation import *
from .sort import Min, SelectionSort, Merge, MergeSort, BubbleSort
from .sequence import LCS, LPS
from .mcm import MCM
from .knapsack import Knapsack
from .problem import Problem, ProblemSet
PROBLEM = {
    'Compare': Compare,
    'Add': Add,
    'Sub': Sub,
    'Sub_pos_int': Sub_pos_int,
    'Mul': Mul,
    'Div': Div,
    'Gcd': Gcd,
    'Lcm': Lcm,
    'Reduce': Reduce,
    'Add_frac': Add_frac,
    'Sub_frac': Sub_frac,
    'Mul_frac': Mul_frac,
    'Div_frac': Div_frac,
    # 'Add_neg': Add_neg,
    # 'Sub_neg': Sub_neg,
    # 'Mul_neg': Mul_neg,
    # 'Div_neg': Div_neg,
    'Operations': Operations,
    'Linear_1d': Linear_1d,
    'Linear_2d': Linear_2d,
    'Mul_both': Mul_both,
    'Elim': Elim,
    'Substitute': Substitute,
    # 'Quadratic_1d': Quadratic_1d,
    Min.name: Min,
    SelectionSort.name: SelectionSort,
    Merge.name: Merge,
    MergeSort.name: MergeSort,
    BubbleSort.name: BubbleSort,
    LCS.name: LCS,
    LPS.name: LPS,
    MCM.name: MCM,
    Knapsack.name: Knapsack,
}","(0, 0)","(43, 0)",N,module,module,,334,48bd17dc-16cf-4ad0-8a95-a9b2f77cdd0e
"from .arithmetic import *
from .equation import *
from .sort import Min, SelectionSort, Merge, MergeSort, BubbleSort
from .sequence import LCS, LPS
from .mcm import MCM
from .knapsack import Knapsack
from .problem import Problem, ProblemSet
PROBLEM = {
    'Compare': Compare,
    'Add': Add,
    'Sub': Sub,
    'Sub_pos_int': Sub_pos_int,
    'Mul': Mul,
    'Div': Div,
    'Gcd': Gcd,
    'Lcm': Lcm,
    'Reduce': Reduce,
    'Add_frac': Add_frac,
    'Sub_frac': Sub_frac,
    'Mul_frac': Mul_frac,
    'Div_frac': Div_frac,
    # 'Add_neg': Add_neg,
    # 'Sub_neg': Sub_neg,
    # 'Mul_neg': Mul_neg,
    # 'Div_neg': Div_neg,
    'Operations': Operations,
    'Linear_1d': Linear_1d,
    'Linear_2d': Linear_2d,
    'Mul_both': Mul_both,
    'Elim': Elim,
    'Substitute': Substitute,
    # 'Quadratic_1d': Quadratic_1d,
    Min.name: Min,
    SelectionSort.name: SelectionSort,
    Merge.name: Merge,
    MergeSort.name: MergeSort,
    BubbleSort.name: BubbleSort,
    LCS.name: LCS,
    LPS.name: LPS,
    MCM.name: MCM,
    Knapsack.name: Knapsack,
}",__init__.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\data\__init__.py,module/,module,Previous sibling does not exist,Next sibling does not exist,"(0, 0)","(42, 1)",N,"import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,import_from_statement,expression_statement",import_from_statement,,329,79560ecb-4309-4741-8cab-9834b95782da
"from torch import nn

from .model import Model


class LSTM(Model):
    def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.embedding = nn.Embedding(num_tokens, config['input_size'])
        self.lstm = nn.LSTM(
            input_size=config['input_size'],
            hidden_size=config['hidden_size'],
            num_layers=config['num_layers'],
            proj_size=num_tokens)
        self._build_optimizer()

    def forward(self, x):
        return self.lstm(self.embedding(x))[0]
",lstm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\lstm.py,,NA,Previous sibling does not exist,"from torch import nn
from .model import Model","(0, 0)","(19, 0)",N,module,module,,121,3855b2c8-33eb-46fb-a0e7-88cbfe1bb713
"from torch import nn
from .model import Model",lstm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\lstm.py,module/,module,Previous sibling does not exist,"class LSTM(Model):
    def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.embedding = nn.Embedding(num_tokens, config['input_size'])
        self.lstm = nn.LSTM(
            input_size=config['input_size'],
            hidden_size=config['hidden_size'],
            num_layers=config['num_layers'],
            proj_size=num_tokens)
        self._build_optimizer()

    def forward(self, x):
        return self.lstm(self.embedding(x))[0]","(0, 0)","(2, 24)",N,"import_from_statement,import_from_statement",import_from_statement,,9,f5587ed0-0c11-4507-871e-a7c62d153f23
"class LSTM(Model):
    def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.embedding = nn.Embedding(num_tokens, config['input_size'])
        self.lstm = nn.LSTM(
            input_size=config['input_size'],
            hidden_size=config['hidden_size'],
            num_layers=config['num_layers'],
            proj_size=num_tokens)
        self._build_optimizer()

    def forward(self, x):
        return self.lstm(self.embedding(x))[0]",lstm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\lstm.py,module/,module,"from torch import nn
from .model import Model",Next sibling does not exist,"(5, 0)","(18, 46)",N,class_definition,LSTM,,110,8d7f592a-fc54-49d7-8759-4bad64ef41a2
"def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.embedding = nn.Embedding(num_tokens, config['input_size'])
        self.lstm = nn.LSTM(
            input_size=config['input_size'],
            hidden_size=config['hidden_size'],
            num_layers=config['num_layers'],
            proj_size=num_tokens)
        self._build_optimizer()",lstm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\lstm.py,module/class_definition-LSTM/,LSTM,Previous sibling does not exist,"def forward(self, x):
        return self.lstm(self.embedding(x))[0]","(6, 4)","(15, 31)",N,function_definition,__init__,,87,0f03d3a6-043b-446b-857d-dca55147bb16
"def forward(self, x):
        return self.lstm(self.embedding(x))[0]",lstm.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\lstm.py,module/class_definition-LSTM/,LSTM,"def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.embedding = nn.Embedding(num_tokens, config['input_size'])
        self.lstm = nn.LSTM(
            input_size=config['input_size'],
            hidden_size=config['hidden_size'],
            num_layers=config['num_layers'],
            proj_size=num_tokens)
        self._build_optimizer()",Next sibling does not exist,"(17, 4)","(18, 46)",N,function_definition,forward,,17,8247d8a8-436f-46c3-8e73-ba272556c3a6
"from typing import Union

import torch
import torch.nn as nn
from torch import Tensor


class Model(nn.Module):
    def __init__(self, config, vocab):
        super().__init__()
        self.config = config
        self.device = config['device']
        self.vocab = vocab
        self.itos = vocab.get_itos()
        self.stoi = vocab.get_stoi()
        self.optim: torch.optim.Optimizer = None
        self.lr_sched = None
        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')

    def _build_optimizer(self):
        self.to(self.device)
        self.optim: torch.optim.Optimizer = getattr(
            torch.optim, self.config['optim'])(
            self.parameters(), **self.config['optim_args'])
        self.lr_sched = getattr(
            torch.optim.lr_scheduler, self.config['lr_sched'])(
            self.optim, **self.config['lr_sched_args'])

    def translate(self, x: Union[list[int], Tensor]):
        if isinstance(x, Tensor):
            x = x.view(-1)
        return ''.join([self.itos[token] for token in x])

    def infer(self, x: Tensor, budget: Union[int, list[int]] = 2000,
              max_context=256, decode=True, verbose=False, verbose_indent=0):
        """"""Recursion of Thought inference

        Args:
            x: Input tensor of shape [seq_len, 1]
            budget: Maximum inference length
            max_context: Maximum context length
            decode: Use decode mode for model's forward pass
            verbose: Print each token generation when True
            verbose_indent: Indentation for better readability
        """"""
        if isinstance(budget, int):
            # Wrap in a mutable object to share among recursion
            budget = [budget]
        assert budget[0] > 0, \
            f'budget should be greater than zero. Got {budget[0]}.'

        if verbose:
            print(' ' * verbose_indent, end='')
            print(f'[Q] {self.translate(x)}')
            print(' ' * verbose_indent, end='')
        go = self.stoi['<GO>']
        stop = self.stoi['<STOP>']
        think = self.stoi['<THINK>']
        answer_start = x.shape[0]
        last_go = 0
        with torch.no_grad():
            while budget[0] > 0:
                if x.shape[0] > max_context:
                    return x

                output = self(x, decode=decode)
                if not decode:
                    output = output[-1:].argmax(-1)
                budget[0] -= 1
                token = output.view([]).item()
                if verbose:
                    print(self.itos[token], end='')
                x = torch.concat([x, output], 0)

                if budget[0] == 0 and token != stop:
                    # Out of budget
                    return x

                if token == think:
                    if verbose:
                        print()
                    x = x[:-1]
                    thought_answer = self.infer(
                        x[last_go:], budget=budget, max_context=max_context,
                        decode=decode, verbose=verbose,
                        verbose_indent=verbose_indent + 4)
                    x = torch.concat([x, thought_answer], 0)
                    if verbose:
                        print(' ' * verbose_indent, end='')
                    if budget[0] == 0:
                        # Out of budget (cannot output answer anymore)
                        return x
                    answer_start = x.shape[0]
                elif token == go:
                    last_go = x.shape[0] - 1
                elif token == stop:
                    if verbose:
                        print()
                    return x[answer_start:]

        # Should not reach here
        raise RuntimeError(f'Something went wrong.')
",model.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\model.py,,NA,Previous sibling does not exist,"from typing import Union
import torch
import torch.nn as nn
from torch import Tensor","(0, 0)","(102, 0)",N,module,module,,792,e81c0f7d-4bd7-4412-8c4f-7ea71e13b3c0
"from typing import Union
import torch
import torch.nn as nn
from torch import Tensor",model.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\model.py,module/,module,Previous sibling does not exist,"class Model(nn.Module):
    def __init__(self, config, vocab):
        super().__init__()
        self.config = config
        self.device = config['device']
        self.vocab = vocab
        self.itos = vocab.get_itos()
        self.stoi = vocab.get_stoi()
        self.optim: torch.optim.Optimizer = None
        self.lr_sched = None
        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')

    def _build_optimizer(self):
        self.to(self.device)
        self.optim: torch.optim.Optimizer = getattr(
            torch.optim, self.config['optim'])(
            self.parameters(), **self.config['optim_args'])
        self.lr_sched = getattr(
            torch.optim.lr_scheduler, self.config['lr_sched'])(
            self.optim, **self.config['lr_sched_args'])

    def translate(self, x: Union[list[int], Tensor]):
        if isinstance(x, Tensor):
            x = x.view(-1)
        return ''.join([self.itos[token] for token in x])

    def infer(self, x: Tensor, budget: Union[int, list[int]] = 2000,
              max_context=256, decode=True, verbose=False, verbose_indent=0):
        """"""Recursion of Thought inference

        Args:
            x: Input tensor of shape [seq_len, 1]
            budget: Maximum inference length
            max_context: Maximum context length
            decode: Use decode mode for model's forward pass
            verbose: Print each token generation when True
            verbose_indent: Indentation for better readability
        """"""
        if isinstance(budget, int):
            # Wrap in a mutable object to share among recursion
            budget = [budget]
        assert budget[0] > 0, \
            f'budget should be greater than zero. Got {budget[0]}.'

        if verbose:
            print(' ' * verbose_indent, end='')
            print(f'[Q] {self.translate(x)}')
            print(' ' * verbose_indent, end='')
        go = self.stoi['<GO>']
        stop = self.stoi['<STOP>']
        think = self.stoi['<THINK>']
        answer_start = x.shape[0]
        last_go = 0
        with torch.no_grad():
            while budget[0] > 0:
                if x.shape[0] > max_context:
                    return x

                output = self(x, decode=decode)
                if not decode:
                    output = output[-1:].argmax(-1)
                budget[0] -= 1
                token = output.view([]).item()
                if verbose:
                    print(self.itos[token], end='')
                x = torch.concat([x, output], 0)

                if budget[0] == 0 and token != stop:
                    # Out of budget
                    return x

                if token == think:
                    if verbose:
                        print()
                    x = x[:-1]
                    thought_answer = self.infer(
                        x[last_go:], budget=budget, max_context=max_context,
                        decode=decode, verbose=verbose,
                        verbose_indent=verbose_indent + 4)
                    x = torch.concat([x, thought_answer], 0)
                    if verbose:
                        print(' ' * verbose_indent, end='')
                    if budget[0] == 0:
                        # Out of budget (cannot output answer anymore)
                        return x
                    answer_start = x.shape[0]
                elif token == go:
                    last_go = x.shape[0] - 1
                elif token == stop:
                    if verbose:
                        print()
                    return x[answer_start:]

        # Should not reach here
        raise RuntimeError(f'Something went wrong.')","(0, 0)","(4, 24)",N,"import_from_statement,import_statement,import_statement,import_from_statement",import_from_statement,,15,dc686522-80f0-44d5-8215-b1474f6a659b
"class Model(nn.Module):
    def __init__(self, config, vocab):
        super().__init__()
        self.config = config
        self.device = config['device']
        self.vocab = vocab
        self.itos = vocab.get_itos()
        self.stoi = vocab.get_stoi()
        self.optim: torch.optim.Optimizer = None
        self.lr_sched = None
        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')

    def _build_optimizer(self):
        self.to(self.device)
        self.optim: torch.optim.Optimizer = getattr(
            torch.optim, self.config['optim'])(
            self.parameters(), **self.config['optim_args'])
        self.lr_sched = getattr(
            torch.optim.lr_scheduler, self.config['lr_sched'])(
            self.optim, **self.config['lr_sched_args'])

    def translate(self, x: Union[list[int], Tensor]):
        if isinstance(x, Tensor):
            x = x.view(-1)
        return ''.join([self.itos[token] for token in x])

    def infer(self, x: Tensor, budget: Union[int, list[int]] = 2000,
              max_context=256, decode=True, verbose=False, verbose_indent=0):
        """"""Recursion of Thought inference

        Args:
            x: Input tensor of shape [seq_len, 1]
            budget: Maximum inference length
            max_context: Maximum context length
            decode: Use decode mode for model's forward pass
            verbose: Print each token generation when True
            verbose_indent: Indentation for better readability
        """"""
        if isinstance(budget, int):
            # Wrap in a mutable object to share among recursion
            budget = [budget]
        assert budget[0] > 0, \
            f'budget should be greater than zero. Got {budget[0]}.'

        if verbose:
            print(' ' * verbose_indent, end='')
            print(f'[Q] {self.translate(x)}')
            print(' ' * verbose_indent, end='')
        go = self.stoi['<GO>']
        stop = self.stoi['<STOP>']
        think = self.stoi['<THINK>']
        answer_start = x.shape[0]
        last_go = 0
        with torch.no_grad():
            while budget[0] > 0:
                if x.shape[0] > max_context:
                    return x

                output = self(x, decode=decode)
                if not decode:
                    output = output[-1:].argmax(-1)
                budget[0] -= 1
                token = output.view([]).item()
                if verbose:
                    print(self.itos[token], end='')
                x = torch.concat([x, output], 0)

                if budget[0] == 0 and token != stop:
                    # Out of budget
                    return x

                if token == think:
                    if verbose:
                        print()
                    x = x[:-1]
                    thought_answer = self.infer(
                        x[last_go:], budget=budget, max_context=max_context,
                        decode=decode, verbose=verbose,
                        verbose_indent=verbose_indent + 4)
                    x = torch.concat([x, thought_answer], 0)
                    if verbose:
                        print(' ' * verbose_indent, end='')
                    if budget[0] == 0:
                        # Out of budget (cannot output answer anymore)
                        return x
                    answer_start = x.shape[0]
                elif token == go:
                    last_go = x.shape[0] - 1
                elif token == stop:
                    if verbose:
                        print()
                    return x[answer_start:]

        # Should not reach here
        raise RuntimeError(f'Something went wrong.')",model.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\model.py,module/,module,"from typing import Union
import torch
import torch.nn as nn
from torch import Tensor",Next sibling does not exist,"(7, 0)","(101, 52)",N,class_definition,Model,,773,85f7e8c1-3672-4940-92a6-fa4677f95474
"def __init__(self, config, vocab):
        super().__init__()
        self.config = config
        self.device = config['device']
        self.vocab = vocab
        self.itos = vocab.get_itos()
        self.stoi = vocab.get_stoi()
        self.optim: torch.optim.Optimizer = None
        self.lr_sched = None
        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')",model.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\model.py,module/class_definition-Model/,Model,Previous sibling does not exist,"def _build_optimizer(self):
        self.to(self.device)
        self.optim: torch.optim.Optimizer = getattr(
            torch.optim, self.config['optim'])(
            self.parameters(), **self.config['optim_args'])
        self.lr_sched = getattr(
            torch.optim.lr_scheduler, self.config['lr_sched'])(
            self.optim, **self.config['lr_sched_args'])","(8, 4)","(17, 66)",N,function_definition,__init__,,88,d08332fe-0b35-4e2a-966d-846bd8d0d07c
"def _build_optimizer(self):
        self.to(self.device)
        self.optim: torch.optim.Optimizer = getattr(
            torch.optim, self.config['optim'])(
            self.parameters(), **self.config['optim_args'])
        self.lr_sched = getattr(
            torch.optim.lr_scheduler, self.config['lr_sched'])(
            self.optim, **self.config['lr_sched_args'])",model.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\model.py,module/class_definition-Model/,Model,"def __init__(self, config, vocab):
        super().__init__()
        self.config = config
        self.device = config['device']
        self.vocab = vocab
        self.itos = vocab.get_itos()
        self.stoi = vocab.get_stoi()
        self.optim: torch.optim.Optimizer = None
        self.lr_sched = None
        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')","def translate(self, x: Union[list[int], Tensor]):
        if isinstance(x, Tensor):
            x = x.view(-1)
        return ''.join([self.itos[token] for token in x])","(19, 4)","(26, 55)",N,function_definition,_build_optimizer,,77,7cff6de9-f3ab-4cc5-9091-669263a07fe6
"def translate(self, x: Union[list[int], Tensor]):
        if isinstance(x, Tensor):
            x = x.view(-1)
        return ''.join([self.itos[token] for token in x])",model.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\model.py,module/class_definition-Model/,Model,"def _build_optimizer(self):
        self.to(self.device)
        self.optim: torch.optim.Optimizer = getattr(
            torch.optim, self.config['optim'])(
            self.parameters(), **self.config['optim_args'])
        self.lr_sched = getattr(
            torch.optim.lr_scheduler, self.config['lr_sched'])(
            self.optim, **self.config['lr_sched_args'])","def infer(self, x: Tensor, budget: Union[int, list[int]] = 2000,
              max_context=256, decode=True, verbose=False, verbose_indent=0):
        """"""Recursion of Thought inference

        Args:
            x: Input tensor of shape [seq_len, 1]
            budget: Maximum inference length
            max_context: Maximum context length
            decode: Use decode mode for model's forward pass
            verbose: Print each token generation when True
            verbose_indent: Indentation for better readability
        """"""
        if isinstance(budget, int):
            # Wrap in a mutable object to share among recursion
            budget = [budget]
        assert budget[0] > 0, \
            f'budget should be greater than zero. Got {budget[0]}.'

        if verbose:
            print(' ' * verbose_indent, end='')
            print(f'[Q] {self.translate(x)}')
            print(' ' * verbose_indent, end='')
        go = self.stoi['<GO>']
        stop = self.stoi['<STOP>']
        think = self.stoi['<THINK>']
        answer_start = x.shape[0]
        last_go = 0
        with torch.no_grad():
            while budget[0] > 0:
                if x.shape[0] > max_context:
                    return x

                output = self(x, decode=decode)
                if not decode:
                    output = output[-1:].argmax(-1)
                budget[0] -= 1
                token = output.view([]).item()
                if verbose:
                    print(self.itos[token], end='')
                x = torch.concat([x, output], 0)

                if budget[0] == 0 and token != stop:
                    # Out of budget
                    return x

                if token == think:
                    if verbose:
                        print()
                    x = x[:-1]
                    thought_answer = self.infer(
                        x[last_go:], budget=budget, max_context=max_context,
                        decode=decode, verbose=verbose,
                        verbose_indent=verbose_indent + 4)
                    x = torch.concat([x, thought_answer], 0)
                    if verbose:
                        print(' ' * verbose_indent, end='')
                    if budget[0] == 0:
                        # Out of budget (cannot output answer anymore)
                        return x
                    answer_start = x.shape[0]
                elif token == go:
                    last_go = x.shape[0] - 1
                elif token == stop:
                    if verbose:
                        print()
                    return x[answer_start:]

        # Should not reach here
        raise RuntimeError(f'Something went wrong.')","(28, 4)","(31, 57)",N,function_definition,translate,,42,38b528b8-776d-41a3-a5d7-44d91fdf2bba
"def infer(self, x: Tensor, budget: Union[int, list[int]] = 2000,
              max_context=256, decode=True, verbose=False, verbose_indent=0):
        """"""Recursion of Thought inference

        Args:
            x: Input tensor of shape [seq_len, 1]
            budget: Maximum inference length
            max_context: Maximum context length
            decode: Use decode mode for model's forward pass
            verbose: Print each token generation when True
            verbose_indent: Indentation for better readability
        """"""
        if isinstance(budget, int):
            # Wrap in a mutable object to share among recursion
            budget = [budget]
        assert budget[0] > 0, \
            f'budget should be greater than zero. Got {budget[0]}.'

        if verbose:
            print(' ' * verbose_indent, end='')
            print(f'[Q] {self.translate(x)}')
            print(' ' * verbose_indent, end='')
        go = self.stoi['<GO>']
        stop = self.stoi['<STOP>']
        think = self.stoi['<THINK>']
        answer_start = x.shape[0]
        last_go = 0
        with torch.no_grad():
            while budget[0] > 0:
                if x.shape[0] > max_context:
                    return x

                output = self(x, decode=decode)
                if not decode:
                    output = output[-1:].argmax(-1)
                budget[0] -= 1
                token = output.view([]).item()
                if verbose:
                    print(self.itos[token], end='')
                x = torch.concat([x, output], 0)

                if budget[0] == 0 and token != stop:
                    # Out of budget
                    return x

                if token == think:
                    if verbose:
                        print()
                    x = x[:-1]
                    thought_answer = self.infer(
                        x[last_go:], budget=budget, max_context=max_context,
                        decode=decode, verbose=verbose,
                        verbose_indent=verbose_indent + 4)
                    x = torch.concat([x, thought_answer], 0)
                    if verbose:
                        print(' ' * verbose_indent, end='')
                    if budget[0] == 0:
                        # Out of budget (cannot output answer anymore)
                        return x
                    answer_start = x.shape[0]
                elif token == go:
                    last_go = x.shape[0] - 1
                elif token == stop:
                    if verbose:
                        print()
                    return x[answer_start:]

        # Should not reach here
        raise RuntimeError(f'Something went wrong.')",model.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\model.py,module/class_definition-Model/,Model,"def translate(self, x: Union[list[int], Tensor]):
        if isinstance(x, Tensor):
            x = x.view(-1)
        return ''.join([self.itos[token] for token in x])","""""""Recursion of Thought inference

        Args:
            x: Input tensor of shape [seq_len, 1]
            budget: Maximum inference length
            max_context: Maximum context length
            decode: Use decode mode for model's forward pass
            verbose: Print each token generation when True
            verbose_indent: Indentation for better readability
        """"""
if isinstance(budget, int):
            # Wrap in a mutable object to share among recursion
            budget = [budget]
assert budget[0] > 0, \
            f'budget should be greater than zero. Got {budget[0]}.'
if verbose:
            print(' ' * verbose_indent, end='')
            print(f'[Q] {self.translate(x)}')
            print(' ' * verbose_indent, end='')
go = self.stoi['<GO>']
stop = self.stoi['<STOP>']
think = self.stoi['<THINK>']
answer_start = x.shape[0]
last_go = 0
with torch.no_grad():
            while budget[0] > 0:
                if x.shape[0] > max_context:
                    return x

                output = self(x, decode=decode)
                if not decode:
                    output = output[-1:].argmax(-1)
                budget[0] -= 1
                token = output.view([]).item()
                if verbose:
                    print(self.itos[token], end='')
                x = torch.concat([x, output], 0)

                if budget[0] == 0 and token != stop:
                    # Out of budget
                    return x

                if token == think:
                    if verbose:
                        print()
                    x = x[:-1]
                    thought_answer = self.infer(
                        x[last_go:], budget=budget, max_context=max_context,
                        decode=decode, verbose=verbose,
                        verbose_indent=verbose_indent + 4)
                    x = torch.concat([x, thought_answer], 0)
                    if verbose:
                        print(' ' * verbose_indent, end='')
                    if budget[0] == 0:
                        # Out of budget (cannot output answer anymore)
                        return x
                    answer_start = x.shape[0]
                elif token == go:
                    last_go = x.shape[0] - 1
                elif token == stop:
                    if verbose:
                        print()
                    return x[answer_start:]
# Should not reach here","(33, 4)","(101, 52)",N,function_definition,infer,,557,c59df4c5-7824-48e7-a375-150191965179
"""""""Recursion of Thought inference

        Args:
            x: Input tensor of shape [seq_len, 1]
            budget: Maximum inference length
            max_context: Maximum context length
            decode: Use decode mode for model's forward pass
            verbose: Print each token generation when True
            verbose_indent: Indentation for better readability
        """"""
if isinstance(budget, int):
            # Wrap in a mutable object to share among recursion
            budget = [budget]
assert budget[0] > 0, \
            f'budget should be greater than zero. Got {budget[0]}.'
if verbose:
            print(' ' * verbose_indent, end='')
            print(f'[Q] {self.translate(x)}')
            print(' ' * verbose_indent, end='')
go = self.stoi['<GO>']
stop = self.stoi['<STOP>']
think = self.stoi['<THINK>']
answer_start = x.shape[0]
last_go = 0
with torch.no_grad():
            while budget[0] > 0:
                if x.shape[0] > max_context:
                    return x

                output = self(x, decode=decode)
                if not decode:
                    output = output[-1:].argmax(-1)
                budget[0] -= 1
                token = output.view([]).item()
                if verbose:
                    print(self.itos[token], end='')
                x = torch.concat([x, output], 0)

                if budget[0] == 0 and token != stop:
                    # Out of budget
                    return x

                if token == think:
                    if verbose:
                        print()
                    x = x[:-1]
                    thought_answer = self.infer(
                        x[last_go:], budget=budget, max_context=max_context,
                        decode=decode, verbose=verbose,
                        verbose_indent=verbose_indent + 4)
                    x = torch.concat([x, thought_answer], 0)
                    if verbose:
                        print(' ' * verbose_indent, end='')
                    if budget[0] == 0:
                        # Out of budget (cannot output answer anymore)
                        return x
                    answer_start = x.shape[0]
                elif token == go:
                    last_go = x.shape[0] - 1
                elif token == stop:
                    if verbose:
                        print()
                    return x[answer_start:]
# Should not reach here",model.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\model.py,module/class_definition-Model/function_definition-infer/,infer,Previous sibling does not exist,raise RuntimeError(f'Something went wrong.'),"(35, 8)","(100, 31)",N,"expression_statement,if_statement,assert_statement,if_statement,expression_statement,expression_statement,expression_statement,expression_statement,expression_statement,with_statement,comment",expression_statement,,497,36b45d7e-452b-409b-8d1d-84889217c53e
raise RuntimeError(f'Something went wrong.'),model.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\model.py,module/class_definition-Model/function_definition-infer/,infer,# Should not reach here,Next sibling does not exist,"(101, 8)","(101, 52)",N,raise_statement,raise_statement,,8,d4464e26-575b-4714-b319-240e2304536a
"import math
from typing import Optional, Union

import torch
import torch.nn as nn
from torch import Tensor

from .model import Model


class PositionalEncoding(nn.Module):
    def __init__(self, d_model: int, dropout: float = 0.0, max_len: int = 5000):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(
            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        pe = torch.zeros(max_len, 1, d_model)
        pe[:, 0, 0::2] = torch.sin(position * div_term)
        pe[:, 0, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)

    def forward(self, x: Tensor) -> Tensor:
        """"""
        Args:
            x: Tensor, shape [seq_len, batch_size, embedding_dim]
        """"""
        x = x + self.pe[:x.size(0)]
        return self.dropout(x)


def causal_mask(sz: int) -> Tensor:
    """"""Generates an upper-triangular matrix of -inf, with zeros on diag.""""""
    return torch.triu(torch.ones(sz, sz, device='cuda') * float('-inf'),
                      diagonal=1)


class CausalTransformerEncoderLayer(nn.TransformerEncoderLayer):
    def forward(self, src: Tensor, src_mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                last_only=False) -> Tensor:
        if not last_only:
            return super().forward(src, src_mask, src_key_padding_mask)
        assert not self.training

        x = src
        last = x[-1:]
        if self.norm_first:
            last = self.norm1(last)
            x = torch.cat([x[:-1], last], 0)
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = last + self._ff_block(self.norm2(last))
        else:
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = self.norm1(last)
            last = self.norm2(last + self._ff_block(last))
        return last


class CausalTransformerEncoder(nn.TransformerEncoder):
    def forward(self, src: Tensor,
                mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                decode=False, cache: Optional[list[Tensor]] = None) \
            -> Union[Tensor, tuple[Tensor, list[Tensor]]]:
        output = src

        if not decode:
            return super().forward(src, mask, src_key_padding_mask)

        last_only = cache is not None
        if cache is None:
            cache = [
                torch.empty([0, *src.shape[1:]], device=src.device)
                for _ in self.layers
            ]
        for i, mod in enumerate(self.layers):
            last = mod(
                output, src_mask=mask,
                src_key_padding_mask=src_key_padding_mask,
                last_only=last_only)
            output = torch.cat([cache[i], last], 0)
            cache[i] = output

        if self.norm is not None:
            raise ValueError(
                'CausalTransformer does not support additional norm')

        return output, cache


class Transformer(Model):
    def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.num_tokens = num_tokens
        self.pos_encoder = PositionalEncoding(
            config['d_model'], dropout=config['dropout'])
        encoder_layer = CausalTransformerEncoderLayer(
            d_model=config['d_model'],
            nhead=config['nhead'],
            dim_feedforward=config['dim_feedforward'],
            dropout=config['dropout'])
        self.transformer_encoder = CausalTransformerEncoder(
            encoder_layer, config['num_layers'])
        self.embedding = nn.Embedding(num_tokens, config['d_model'])
        self.output = nn.Linear(config['d_model'], num_tokens)
        self._build_optimizer()
        self.cache_key = None
        self.cache_value = None

    def init_weights(self):
        init_range = 0.1
        self.embedding.weight.data.uniform_(-init_range, init_range)

    def forward(self, x: Tensor, mask='causal_mask', decode=False) -> Tensor:
        embedding = self.pos_encoder(self.embedding(x))
        if not decode:
            mask = causal_mask(x.shape[0]) if mask == 'causal_mask' else mask
            encoded = self.transformer_encoder(embedding, mask)
            return self.output(encoded)
        else:
            # Decoding mode (only outputs the last token)
            mask = causal_mask(x.shape[0])
            assert not self.training
            if self.cache_key is not None and \
                    self.cache_key.shape == x.shape and \
                    (self.cache_key == x).all():
                cache = self.cache_value
            else:
                cache = None
            encoded, cache = self.transformer_encoder(
                embedding, mask, decode=decode, cache=cache)
            output = self.output(encoded[-1:]).argmax(-1)
            self.cache_key = torch.cat([x, output])
            self.cache_value = cache

            return output
",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,,NA,Previous sibling does not exist,"import math
from typing import Optional, Union
import torch
import torch.nn as nn
from torch import Tensor
from .model import Model","(0, 0)","(141, 0)",N,module,module,,1166,25ecd840-c0de-43ed-9a11-4068b881d229
"import math
from typing import Optional, Union
import torch
import torch.nn as nn
from torch import Tensor
from .model import Model",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/,module,Previous sibling does not exist,"class PositionalEncoding(nn.Module):
    def __init__(self, d_model: int, dropout: float = 0.0, max_len: int = 5000):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(
            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        pe = torch.zeros(max_len, 1, d_model)
        pe[:, 0, 0::2] = torch.sin(position * div_term)
        pe[:, 0, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)

    def forward(self, x: Tensor) -> Tensor:
        """"""
        Args:
            x: Tensor, shape [seq_len, batch_size, embedding_dim]
        """"""
        x = x + self.pe[:x.size(0)]
        return self.dropout(x)","(0, 0)","(7, 24)",N,"import_statement,import_from_statement,import_statement,import_statement,import_from_statement,import_from_statement",import_statement,,24,0fd8ecce-fc22-4838-9c34-3b09a2ca5911
"class PositionalEncoding(nn.Module):
    def __init__(self, d_model: int, dropout: float = 0.0, max_len: int = 5000):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(
            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        pe = torch.zeros(max_len, 1, d_model)
        pe[:, 0, 0::2] = torch.sin(position * div_term)
        pe[:, 0, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)

    def forward(self, x: Tensor) -> Tensor:
        """"""
        Args:
            x: Tensor, shape [seq_len, batch_size, embedding_dim]
        """"""
        x = x + self.pe[:x.size(0)]
        return self.dropout(x)",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/,module,"import math
from typing import Optional, Union
import torch
import torch.nn as nn
from torch import Tensor
from .model import Model","def causal_mask(sz: int) -> Tensor:
    """"""Generates an upper-triangular matrix of -inf, with zeros on diag.""""""
    return torch.triu(torch.ones(sz, sz, device='cuda') * float('-inf'),
                      diagonal=1)","(10, 0)","(29, 30)",N,class_definition,PositionalEncoding,,212,3a896083-142d-40cd-ad37-da834501bfbc
"def __init__(self, d_model: int, dropout: float = 0.0, max_len: int = 5000):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(
            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        pe = torch.zeros(max_len, 1, d_model)
        pe[:, 0, 0::2] = torch.sin(position * div_term)
        pe[:, 0, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/class_definition-PositionalEncoding/,PositionalEncoding,Previous sibling does not exist,"def forward(self, x: Tensor) -> Tensor:
        """"""
        Args:
            x: Tensor, shape [seq_len, batch_size, embedding_dim]
        """"""
        x = x + self.pe[:x.size(0)]
        return self.dropout(x)","(11, 4)","(21, 38)",N,function_definition,__init__,,150,8a51646f-41b3-401f-ac8c-1c782127779a
"def forward(self, x: Tensor) -> Tensor:
        """"""
        Args:
            x: Tensor, shape [seq_len, batch_size, embedding_dim]
        """"""
        x = x + self.pe[:x.size(0)]
        return self.dropout(x)",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/class_definition-PositionalEncoding/,PositionalEncoding,"def __init__(self, d_model: int, dropout: float = 0.0, max_len: int = 5000):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(
            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        pe = torch.zeros(max_len, 1, d_model)
        pe[:, 0, 0::2] = torch.sin(position * div_term)
        pe[:, 0, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)",Next sibling does not exist,"(23, 4)","(29, 30)",N,function_definition,forward,,53,450486eb-4818-4fee-99f1-2e043161e3a7
"def causal_mask(sz: int) -> Tensor:
    """"""Generates an upper-triangular matrix of -inf, with zeros on diag.""""""
    return torch.triu(torch.ones(sz, sz, device='cuda') * float('-inf'),
                      diagonal=1)",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/,module,"class PositionalEncoding(nn.Module):
    def __init__(self, d_model: int, dropout: float = 0.0, max_len: int = 5000):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(
            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        pe = torch.zeros(max_len, 1, d_model)
        pe[:, 0, 0::2] = torch.sin(position * div_term)
        pe[:, 0, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)

    def forward(self, x: Tensor) -> Tensor:
        """"""
        Args:
            x: Tensor, shape [seq_len, batch_size, embedding_dim]
        """"""
        x = x + self.pe[:x.size(0)]
        return self.dropout(x)","class CausalTransformerEncoderLayer(nn.TransformerEncoderLayer):
    def forward(self, src: Tensor, src_mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                last_only=False) -> Tensor:
        if not last_only:
            return super().forward(src, src_mask, src_key_padding_mask)
        assert not self.training

        x = src
        last = x[-1:]
        if self.norm_first:
            last = self.norm1(last)
            x = torch.cat([x[:-1], last], 0)
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = last + self._ff_block(self.norm2(last))
        else:
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = self.norm1(last)
            last = self.norm2(last + self._ff_block(last))
        return last","(32, 0)","(35, 33)",N,function_definition,causal_mask,,54,d8a23adf-6aff-4a39-beef-d301f146870a
"class CausalTransformerEncoderLayer(nn.TransformerEncoderLayer):
    def forward(self, src: Tensor, src_mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                last_only=False) -> Tensor:
        if not last_only:
            return super().forward(src, src_mask, src_key_padding_mask)
        assert not self.training

        x = src
        last = x[-1:]
        if self.norm_first:
            last = self.norm1(last)
            x = torch.cat([x[:-1], last], 0)
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = last + self._ff_block(self.norm2(last))
        else:
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = self.norm1(last)
            last = self.norm2(last + self._ff_block(last))
        return last",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/,module,"def causal_mask(sz: int) -> Tensor:
    """"""Generates an upper-triangular matrix of -inf, with zeros on diag.""""""
    return torch.triu(torch.ones(sz, sz, device='cuda') * float('-inf'),
                      diagonal=1)","class CausalTransformerEncoder(nn.TransformerEncoder):
    def forward(self, src: Tensor,
                mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                decode=False, cache: Optional[list[Tensor]] = None) \
            -> Union[Tensor, tuple[Tensor, list[Tensor]]]:
        output = src

        if not decode:
            return super().forward(src, mask, src_key_padding_mask)

        last_only = cache is not None
        if cache is None:
            cache = [
                torch.empty([0, *src.shape[1:]], device=src.device)
                for _ in self.layers
            ]
        for i, mod in enumerate(self.layers):
            last = mod(
                output, src_mask=mask,
                src_key_padding_mask=src_key_padding_mask,
                last_only=last_only)
            output = torch.cat([cache[i], last], 0)
            cache[i] = output

        if self.norm is not None:
            raise ValueError(
                'CausalTransformer does not support additional norm')

        return output, cache","(38, 0)","(59, 19)",N,class_definition,CausalTransformerEncoderLayer,,224,176989e6-5546-4647-8673-28188ec5f2ae
"def forward(self, src: Tensor, src_mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                last_only=False) -> Tensor:
        if not last_only:
            return super().forward(src, src_mask, src_key_padding_mask)
        assert not self.training

        x = src
        last = x[-1:]
        if self.norm_first:
            last = self.norm1(last)
            x = torch.cat([x[:-1], last], 0)
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = last + self._ff_block(self.norm2(last))
        else:
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = self.norm1(last)
            last = self.norm2(last + self._ff_block(last))
        return last",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/class_definition-CausalTransformerEncoderLayer/,CausalTransformerEncoderLayer,Previous sibling does not exist,Next sibling does not exist,"(39, 4)","(59, 19)",N,function_definition,forward,,211,c839bf52-45e6-47ec-a9f7-2dfc4660c302
"class CausalTransformerEncoder(nn.TransformerEncoder):
    def forward(self, src: Tensor,
                mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                decode=False, cache: Optional[list[Tensor]] = None) \
            -> Union[Tensor, tuple[Tensor, list[Tensor]]]:
        output = src

        if not decode:
            return super().forward(src, mask, src_key_padding_mask)

        last_only = cache is not None
        if cache is None:
            cache = [
                torch.empty([0, *src.shape[1:]], device=src.device)
                for _ in self.layers
            ]
        for i, mod in enumerate(self.layers):
            last = mod(
                output, src_mask=mask,
                src_key_padding_mask=src_key_padding_mask,
                last_only=last_only)
            output = torch.cat([cache[i], last], 0)
            cache[i] = output

        if self.norm is not None:
            raise ValueError(
                'CausalTransformer does not support additional norm')

        return output, cache",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/,module,"class CausalTransformerEncoderLayer(nn.TransformerEncoderLayer):
    def forward(self, src: Tensor, src_mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                last_only=False) -> Tensor:
        if not last_only:
            return super().forward(src, src_mask, src_key_padding_mask)
        assert not self.training

        x = src
        last = x[-1:]
        if self.norm_first:
            last = self.norm1(last)
            x = torch.cat([x[:-1], last], 0)
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = last + self._ff_block(self.norm2(last))
        else:
            last = last + self.dropout1(self.self_attn(
                last, x, x, key_padding_mask=src_key_padding_mask)[0])
            last = self.norm1(last)
            last = self.norm2(last + self._ff_block(last))
        return last","class Transformer(Model):
    def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.num_tokens = num_tokens
        self.pos_encoder = PositionalEncoding(
            config['d_model'], dropout=config['dropout'])
        encoder_layer = CausalTransformerEncoderLayer(
            d_model=config['d_model'],
            nhead=config['nhead'],
            dim_feedforward=config['dim_feedforward'],
            dropout=config['dropout'])
        self.transformer_encoder = CausalTransformerEncoder(
            encoder_layer, config['num_layers'])
        self.embedding = nn.Embedding(num_tokens, config['d_model'])
        self.output = nn.Linear(config['d_model'], num_tokens)
        self._build_optimizer()
        self.cache_key = None
        self.cache_value = None

    def init_weights(self):
        init_range = 0.1
        self.embedding.weight.data.uniform_(-init_range, init_range)

    def forward(self, x: Tensor, mask='causal_mask', decode=False) -> Tensor:
        embedding = self.pos_encoder(self.embedding(x))
        if not decode:
            mask = causal_mask(x.shape[0]) if mask == 'causal_mask' else mask
            encoded = self.transformer_encoder(embedding, mask)
            return self.output(encoded)
        else:
            # Decoding mode (only outputs the last token)
            mask = causal_mask(x.shape[0])
            assert not self.training
            if self.cache_key is not None and \
                    self.cache_key.shape == x.shape and \
                    (self.cache_key == x).all():
                cache = self.cache_value
            else:
                cache = None
            encoded, cache = self.transformer_encoder(
                embedding, mask, decode=decode, cache=cache)
            output = self.output(encoded[-1:]).argmax(-1)
            self.cache_key = torch.cat([x, output])
            self.cache_value = cache

            return output","(62, 0)","(91, 28)",N,class_definition,CausalTransformerEncoder,,232,a852af26-7c49-420d-9635-8ed6e28c0961
"def forward(self, src: Tensor,
                mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                decode=False, cache: Optional[list[Tensor]] = None) \
            -> Union[Tensor, tuple[Tensor, list[Tensor]]]:
        output = src

        if not decode:
            return super().forward(src, mask, src_key_padding_mask)

        last_only = cache is not None
        if cache is None:
            cache = [
                torch.empty([0, *src.shape[1:]], device=src.device)
                for _ in self.layers
            ]
        for i, mod in enumerate(self.layers):
            last = mod(
                output, src_mask=mask,
                src_key_padding_mask=src_key_padding_mask,
                last_only=last_only)
            output = torch.cat([cache[i], last], 0)
            cache[i] = output

        if self.norm is not None:
            raise ValueError(
                'CausalTransformer does not support additional norm')

        return output, cache",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/class_definition-CausalTransformerEncoder/,CausalTransformerEncoder,Previous sibling does not exist,Next sibling does not exist,"(63, 4)","(91, 28)",N,function_definition,forward,,221,7b9150b5-5111-49e1-880c-f9f7265afbf0
"class Transformer(Model):
    def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.num_tokens = num_tokens
        self.pos_encoder = PositionalEncoding(
            config['d_model'], dropout=config['dropout'])
        encoder_layer = CausalTransformerEncoderLayer(
            d_model=config['d_model'],
            nhead=config['nhead'],
            dim_feedforward=config['dim_feedforward'],
            dropout=config['dropout'])
        self.transformer_encoder = CausalTransformerEncoder(
            encoder_layer, config['num_layers'])
        self.embedding = nn.Embedding(num_tokens, config['d_model'])
        self.output = nn.Linear(config['d_model'], num_tokens)
        self._build_optimizer()
        self.cache_key = None
        self.cache_value = None

    def init_weights(self):
        init_range = 0.1
        self.embedding.weight.data.uniform_(-init_range, init_range)

    def forward(self, x: Tensor, mask='causal_mask', decode=False) -> Tensor:
        embedding = self.pos_encoder(self.embedding(x))
        if not decode:
            mask = causal_mask(x.shape[0]) if mask == 'causal_mask' else mask
            encoded = self.transformer_encoder(embedding, mask)
            return self.output(encoded)
        else:
            # Decoding mode (only outputs the last token)
            mask = causal_mask(x.shape[0])
            assert not self.training
            if self.cache_key is not None and \
                    self.cache_key.shape == x.shape and \
                    (self.cache_key == x).all():
                cache = self.cache_value
            else:
                cache = None
            encoded, cache = self.transformer_encoder(
                embedding, mask, decode=decode, cache=cache)
            output = self.output(encoded[-1:]).argmax(-1)
            self.cache_key = torch.cat([x, output])
            self.cache_value = cache

            return output",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/,module,"class CausalTransformerEncoder(nn.TransformerEncoder):
    def forward(self, src: Tensor,
                mask: Optional[Tensor] = None,
                src_key_padding_mask: Optional[Tensor] = None,
                decode=False, cache: Optional[list[Tensor]] = None) \
            -> Union[Tensor, tuple[Tensor, list[Tensor]]]:
        output = src

        if not decode:
            return super().forward(src, mask, src_key_padding_mask)

        last_only = cache is not None
        if cache is None:
            cache = [
                torch.empty([0, *src.shape[1:]], device=src.device)
                for _ in self.layers
            ]
        for i, mod in enumerate(self.layers):
            last = mod(
                output, src_mask=mask,
                src_key_padding_mask=src_key_padding_mask,
                last_only=last_only)
            output = torch.cat([cache[i], last], 0)
            cache[i] = output

        if self.norm is not None:
            raise ValueError(
                'CausalTransformer does not support additional norm')

        return output, cache",Next sibling does not exist,"(94, 0)","(140, 25)",N,class_definition,Transformer,,411,812155a2-86d7-479a-8143-23106ca844fd
"def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.num_tokens = num_tokens
        self.pos_encoder = PositionalEncoding(
            config['d_model'], dropout=config['dropout'])
        encoder_layer = CausalTransformerEncoderLayer(
            d_model=config['d_model'],
            nhead=config['nhead'],
            dim_feedforward=config['dim_feedforward'],
            dropout=config['dropout'])
        self.transformer_encoder = CausalTransformerEncoder(
            encoder_layer, config['num_layers'])
        self.embedding = nn.Embedding(num_tokens, config['d_model'])
        self.output = nn.Linear(config['d_model'], num_tokens)
        self._build_optimizer()
        self.cache_key = None
        self.cache_value = None",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/class_definition-Transformer/,Transformer,Previous sibling does not exist,"def init_weights(self):
        init_range = 0.1
        self.embedding.weight.data.uniform_(-init_range, init_range)","(95, 4)","(112, 31)",N,function_definition,__init__,,165,6cce55f3-17c2-4d17-836c-8a6da13b1a11
"def init_weights(self):
        init_range = 0.1
        self.embedding.weight.data.uniform_(-init_range, init_range)",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/class_definition-Transformer/,Transformer,"def __init__(self, config, vocab):
        super().__init__(config, vocab)
        num_tokens = len(vocab)
        self.num_tokens = num_tokens
        self.pos_encoder = PositionalEncoding(
            config['d_model'], dropout=config['dropout'])
        encoder_layer = CausalTransformerEncoderLayer(
            d_model=config['d_model'],
            nhead=config['nhead'],
            dim_feedforward=config['dim_feedforward'],
            dropout=config['dropout'])
        self.transformer_encoder = CausalTransformerEncoder(
            encoder_layer, config['num_layers'])
        self.embedding = nn.Embedding(num_tokens, config['d_model'])
        self.output = nn.Linear(config['d_model'], num_tokens)
        self._build_optimizer()
        self.cache_key = None
        self.cache_value = None","def forward(self, x: Tensor, mask='causal_mask', decode=False) -> Tensor:
        embedding = self.pos_encoder(self.embedding(x))
        if not decode:
            mask = causal_mask(x.shape[0]) if mask == 'causal_mask' else mask
            encoded = self.transformer_encoder(embedding, mask)
            return self.output(encoded)
        else:
            # Decoding mode (only outputs the last token)
            mask = causal_mask(x.shape[0])
            assert not self.training
            if self.cache_key is not None and \
                    self.cache_key.shape == x.shape and \
                    (self.cache_key == x).all():
                cache = self.cache_value
            else:
                cache = None
            encoded, cache = self.transformer_encoder(
                embedding, mask, decode=decode, cache=cache)
            output = self.output(encoded[-1:]).argmax(-1)
            self.cache_key = torch.cat([x, output])
            self.cache_value = cache

            return output","(114, 4)","(116, 68)",N,function_definition,init_weights,,28,4953ad33-63f2-47b1-95b4-a05c96bee8f7
"def forward(self, x: Tensor, mask='causal_mask', decode=False) -> Tensor:
        embedding = self.pos_encoder(self.embedding(x))
        if not decode:
            mask = causal_mask(x.shape[0]) if mask == 'causal_mask' else mask
            encoded = self.transformer_encoder(embedding, mask)
            return self.output(encoded)
        else:
            # Decoding mode (only outputs the last token)
            mask = causal_mask(x.shape[0])
            assert not self.training
            if self.cache_key is not None and \
                    self.cache_key.shape == x.shape and \
                    (self.cache_key == x).all():
                cache = self.cache_value
            else:
                cache = None
            encoded, cache = self.transformer_encoder(
                embedding, mask, decode=decode, cache=cache)
            output = self.output(encoded[-1:]).argmax(-1)
            self.cache_key = torch.cat([x, output])
            self.cache_value = cache

            return output",transformer.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\transformer.py,module/class_definition-Transformer/,Transformer,"def init_weights(self):
        init_range = 0.1
        self.embedding.weight.data.uniform_(-init_range, init_range)",Next sibling does not exist,"(118, 4)","(140, 25)",N,function_definition,forward,,210,8faf22cb-6f8a-4503-aeef-107744aa437a
"from .model import Model
from .transformer import Transformer
from .lstm import LSTM

MODEL = {
    'Transformer': Transformer,
    'LSTM': LSTM,
}
",__init__.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\__init__.py,,NA,Previous sibling does not exist,"from .model import Model
from .transformer import Transformer
from .lstm import LSTM
MODEL = {
    'Transformer': Transformer,
    'LSTM': LSTM,
}","(0, 0)","(8, 0)",N,module,module,,37,d14bc4d6-1e8f-46ea-87fe-87e5e78fa028
"from .model import Model
from .transformer import Transformer
from .lstm import LSTM
MODEL = {
    'Transformer': Transformer,
    'LSTM': LSTM,
}",__init__.py,c:\Users\Tanmay Saini\Desktop\codeconverse\backend\repositories\soochan-lee_RoT\models\__init__.py,module/,module,Previous sibling does not exist,Next sibling does not exist,"(0, 0)","(7, 1)",N,"import_from_statement,import_from_statement,import_from_statement,expression_statement",import_from_statement,,34,41c93135-cba2-4f75-8783-ef43525c9a26
